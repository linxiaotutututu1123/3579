from __future__ import annotations

import uuid
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from pathlib import Path
from typing import TYPE_CHECKING, Any, Protocol, TypeAlias, runtime_checkable

if TYPE_CHECKING:
    from collections.abc import Callable, Sequence


# =============================================================================
# ğŸ†” ç±»å‹åˆ«å
# =============================================================================

AgentId: TypeAlias = str
TaskId: TypeAlias = str
ArtifactId: TypeAlias = str


def generate_id(prefix: str = "") -> str:
    """ç”Ÿæˆå”¯ä¸€ID."""
    uid = str(uuid.uuid4())[:8]
    return f"{prefix}_{uid}" if prefix else uid


# =============================================================================
# ğŸ­ è§’è‰²å®šä¹‰ - ä»11ç§å‡çº§åˆ°18ç§
# =============================================================================


class AgentRole(Enum):
    """æ™ºèƒ½ä½“è§’è‰²æšä¸¾ - ä¸»å¸­çº§18ç§ä¸“å®¶è§’è‰².

    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ç®¡ç†å±‚
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    PROJECT_MANAGER = "project_manager"
    """é¡¹ç›®ç»ç† - éœ€æ±‚åˆ†æã€ä»»åŠ¡æ‹†åˆ†ã€è¿›åº¦ç®¡ç†"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ†• å†³ç­–å±‚
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    TECH_DIRECTOR = "tech_director"
    """æŠ€æœ¯æ€»ç›‘ - æŠ€æœ¯å†³ç­–ã€æ¶æ„æŠŠå…³ã€æŠ€æœ¯æ ‡å‡†åˆ¶å®š"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ¶æ„å±‚
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SYSTEM_ARCHITECT = "system_architect"
    """ç³»ç»Ÿæ¶æ„å¸ˆ - æ•´ä½“æ¶æ„è®¾è®¡ã€æŠ€æœ¯é€‰å‹"""
    
    SOLUTION_ARCHITECT = "solution_architect"  # ğŸ†•
    """è§£å†³æ–¹æ¡ˆæ¶æ„å¸ˆ - å…·ä½“æ–¹æ¡ˆè®¾è®¡ã€é›†æˆæ–¹æ¡ˆ"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å¼€å‘å±‚
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    TECH_LEAD = "tech_lead"  # ğŸ†•
    """æŠ€æœ¯è´Ÿè´£äºº - æŠ€æœ¯æ”»å…³ã€å¼€å‘æŒ‡å¯¼ã€ä»£ç è´¨é‡æŠŠæ§"""
    
    BACKEND_ENGINEER = "backend_engineer"
    """åç«¯å·¥ç¨‹å¸ˆ - åç«¯æœåŠ¡ã€APIã€æ•°æ®åº“"""
    
    FRONTEND_ENGINEER = "frontend_engineer"
    """å‰ç«¯å·¥ç¨‹å¸ˆ - å‰ç«¯ç•Œé¢ã€äº¤äº’ã€ç”¨æˆ·ä½“éªŒ"""
    
    FULLSTACK_ENGINEER = "fullstack_engineer"  # ğŸ†•
    """å…¨æ ˆå·¥ç¨‹å¸ˆ - ç«¯åˆ°ç«¯å¼€å‘ã€å¿«é€ŸåŸå‹"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # è´¨é‡å±‚
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    QA_ENGINEER = "qa_engineer"
    """æµ‹è¯•å·¥ç¨‹å¸ˆ - æµ‹è¯•ç­–ç•¥ã€ç”¨ä¾‹è®¾è®¡ã€è‡ªåŠ¨åŒ–æµ‹è¯•"""
    
    QA_LEAD = "qa_lead"  # ğŸ†•
    """æµ‹è¯•è´Ÿè´£äºº - æµ‹è¯•è§„åˆ’ã€è´¨é‡æ ‡å‡†ã€æµ‹è¯•å›¢é˜Ÿåè°ƒ"""
    
    CODE_REVIEWER = "code_reviewer"
    """ä»£ç å®¡æŸ¥å‘˜ - ä»£ç è´¨é‡ã€æœ€ä½³å®è·µã€è§„èŒƒæ£€æŸ¥"""
    
    PERFORMANCE_ENGINEER = "performance_engineer"  # ğŸ†•
    """æ€§èƒ½å·¥ç¨‹å¸ˆ - æ€§èƒ½ä¼˜åŒ–ã€ç“¶é¢ˆåˆ†æã€è´Ÿè½½æµ‹è¯•"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å®‰å…¨å±‚
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SECURITY_ARCHITECT = "security_architect"
    """å®‰å…¨æ¶æ„å¸ˆ - å®‰å…¨è®¾è®¡ã€æ¼æ´åˆ†æã€å®‰å…¨å®¡è®¡"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # è¿ç»´å±‚
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    DEVOPS_ENGINEER = "devops_engineer"
    """DevOpså·¥ç¨‹å¸ˆ - CI/CDã€éƒ¨ç½²ã€åŸºç¡€è®¾æ–½"""
    
    SRE_ENGINEER = "sre_engineer"  # ğŸ†•
    """SREå·¥ç¨‹å¸ˆ - å¯é æ€§ã€ç›‘æ§ã€æ•…éšœå¤„ç†"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ–‡æ¡£å±‚
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    TECH_WRITER = "tech_writer"
    """æŠ€æœ¯æ–‡æ¡£å·¥ç¨‹å¸ˆ - æ–‡æ¡£ç¼–å†™ã€APIæ–‡æ¡£ã€ç”¨æˆ·æŒ‡å—"""


class ExpertiseLevel(Enum):
    """ä¸“ä¸šç­‰çº§."""
    
    JUNIOR = 1      # åˆçº§
    INTERMEDIATE = 2 # ä¸­çº§
    SENIOR = 3      # é«˜çº§
    STAFF = 4       # èµ„æ·±
    PRINCIPAL = 5   # é¦–å¸­
    FELLOW = 6      # ä¸“å®¶ï¼ˆæœ€é«˜çº§ï¼‰


# =============================================================================
# ğŸ’ª èƒ½åŠ›å®šä¹‰ - ä»14ç§å‡çº§åˆ°35ç§
# =============================================================================


class AgentCapability(Enum):
    """æ™ºèƒ½ä½“èƒ½åŠ›æšä¸¾ - ä¸»å¸­çº§35ç§ç»†åˆ†èƒ½åŠ›.
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # éœ€æ±‚ä¸è§„åˆ’èƒ½åŠ›
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    REQUIREMENT_ANALYSIS = "requirement_analysis"
    """éœ€æ±‚åˆ†æ"""
    
    TASK_DECOMPOSITION = "task_decomposition"
    """ä»»åŠ¡æ‹†åˆ†"""
    
    EFFORT_ESTIMATION = "effort_estimation"  # ğŸ†•
    """å·¥ä½œé‡ä¼°ç®—"""
    
    RISK_ASSESSMENT = "risk_assessment"  # ğŸ†•
    """é£é™©è¯„ä¼°"""
    
    ROADMAP_PLANNING = "roadmap_planning"  # ğŸ†•
    """è·¯çº¿å›¾è§„åˆ’"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ¶æ„è®¾è®¡èƒ½åŠ›
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SYSTEM_DESIGN = "system_design"
    """ç³»ç»Ÿè®¾è®¡"""
    
    API_DESIGN = "api_design"
    """APIè®¾è®¡"""
    
    DATABASE_DESIGN = "database_design"
    """æ•°æ®åº“è®¾è®¡"""
    
    MICROSERVICES_DESIGN = "microservices_design"  # ğŸ†•
    """å¾®æœåŠ¡è®¾è®¡"""
    
    EVENT_DRIVEN_DESIGN = "event_driven_design"  # ğŸ†•
    """äº‹ä»¶é©±åŠ¨è®¾è®¡"""
    
    DISTRIBUTED_SYSTEMS = "distributed_systems"  # ğŸ†•
    """åˆ†å¸ƒå¼ç³»ç»Ÿ"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ç¼–ç èƒ½åŠ›
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    CODE_GENERATION = "code_generation"
    """ä»£ç ç”Ÿæˆ"""
    
    CODE_REVIEW = "code_review"
    """ä»£ç å®¡æŸ¥"""
    
    CODE_REFACTORING = "code_refactoring"
    """ä»£ç é‡æ„"""
    
    CODE_OPTIMIZATION = "code_optimization"  # ğŸ†•
    """ä»£ç ä¼˜åŒ–"""
    
    CODE_DEBUGGING = "code_debugging"  # ğŸ†•
    """ä»£ç è°ƒè¯•"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # è¯­è¨€ä¸æ¡†æ¶èƒ½åŠ›
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    PYTHON_EXPERT = "python_expert"  # ğŸ†•
    """Pythonä¸“å®¶"""
    
    JAVASCRIPT_EXPERT = "javascript_expert"  # ğŸ†•
    """JavaScriptä¸“å®¶"""
    
    TYPESCRIPT_EXPERT = "typescript_expert"  # ğŸ†•
    """TypeScriptä¸“å®¶"""
    
    SQL_EXPERT = "sql_expert"  # ğŸ†•
    """SQLä¸“å®¶"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æµ‹è¯•èƒ½åŠ›
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    TEST_PLANNING = "test_planning"
    """æµ‹è¯•è§„åˆ’"""
    
    TEST_CASE_DESIGN = "test_case_design"
    """æµ‹è¯•ç”¨ä¾‹è®¾è®¡"""
    
    UNIT_TESTING = "unit_testing"  # ğŸ†•
    """å•å…ƒæµ‹è¯•"""
    
    INTEGRATION_TESTING = "integration_testing"  # ğŸ†•
    """é›†æˆæµ‹è¯•"""
    
    E2E_TESTING = "e2e_testing"  # ğŸ†•
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    PERFORMANCE_TESTING = "performance_testing"  # ğŸ†•
    """æ€§èƒ½æµ‹è¯•"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å®‰å…¨èƒ½åŠ›
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SECURITY_ANALYSIS = "security_analysis"
    """å®‰å…¨åˆ†æ"""
    
    VULNERABILITY_ASSESSMENT = "vulnerability_assessment"
    """æ¼æ´è¯„ä¼°"""
    
    SECURITY_AUDIT = "security_audit"  # ğŸ†•
    """å®‰å…¨å®¡è®¡"""
    
    PENETRATION_TESTING = "penetration_testing"  # ğŸ†•
    """æ¸—é€æµ‹è¯•"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # DevOpsèƒ½åŠ›
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    CI_CD_PIPELINE = "ci_cd_pipeline"
    """CI/CDæµæ°´çº¿"""
    
    CONTAINERIZATION = "containerization"  # ğŸ†•
    """å®¹å™¨åŒ–"""
    
    ORCHESTRATION = "orchestration"  # ğŸ†•
    """ç¼–æ’ï¼ˆK8sç­‰ï¼‰"""
    
    INFRASTRUCTURE_AS_CODE = "iac"  # ğŸ†•
    """åŸºç¡€è®¾æ–½å³ä»£ç """
    
    MONITORING = "monitoring"  # ğŸ†•
    """ç›‘æ§å‘Šè­¦"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ–‡æ¡£èƒ½åŠ›
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    DOCUMENTATION = "documentation"
    """æŠ€æœ¯æ–‡æ¡£"""
    
    API_DOCUMENTATION = "api_documentation"
    """APIæ–‡æ¡£"""


# =============================================================================
# ğŸ“Š çŠ¶æ€ä¸ç±»å‹æšä¸¾
# =============================================================================


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€ - æ‰©å±•ç‰ˆ."""
    
    # åˆå§‹çŠ¶æ€
    DRAFT = "draft"
    PENDING = "pending"
    
    # æ‰§è¡ŒçŠ¶æ€
    QUEUED = "queued"
    ASSIGNED = "assigned"
    IN_PROGRESS = "in_progress"
    
    # åä½œçŠ¶æ€
    IN_REVIEW = "in_review"
    IN_DEBATE = "in_debate"  # ğŸ†• è¾©è®ºä¸­
    AWAITING_CONSENSUS = "awaiting_consensus"  # ğŸ†• ç­‰å¾…å…±è¯†
    REVISION_REQUIRED = "revision_required"
    
    # é˜»å¡çŠ¶æ€
    BLOCKED = "blocked"
    WAITING_DEPENDENCY = "waiting_dependency"  # ğŸ†•
    
    # ç»ˆæ€
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§."""
    
    CRITICAL = 1    # ç´§æ€¥ï¼šé˜»å¡æ€§é—®é¢˜
    HIGH = 2        # é«˜ï¼šæ ¸å¿ƒåŠŸèƒ½
    MEDIUM = 3      # ä¸­ï¼šä¸€èˆ¬åŠŸèƒ½
    LOW = 4         # ä½ï¼šä¼˜åŒ–æ”¹è¿›
    BACKLOG = 5     # å¾…å®šï¼šæœªæ¥è€ƒè™‘


class MessageType(Enum):
    """æ¶ˆæ¯ç±»å‹ - æ‰©å±•ç‰ˆ."""
    
    # ä»»åŠ¡ç›¸å…³
    TASK_ASSIGNMENT = "task_assignment"
    TASK_UPDATE = "task_update"
    TASK_COMPLETED = "task_completed"
    TASK_FAILED = "task_failed"
    
    # åä½œç›¸å…³
    REQUEST_REVIEW = "request_review"
    REVIEW_FEEDBACK = "review_feedback"
    REQUEST_HELP = "request_help"
    PROVIDE_HELP = "provide_help"
    
    # ğŸ†• è¾©è®ºç›¸å…³
    DEBATE_START = "debate_start"
    DEBATE_ARGUMENT = "debate_argument"
    DEBATE_REBUTTAL = "debate_rebuttal"
    DEBATE_CONCLUSION = "debate_conclusion"
    
    # ğŸ†• å…±è¯†ç›¸å…³
    CONSENSUS_PROPOSAL = "consensus_proposal"
    CONSENSUS_VOTE = "consensus_vote"
    CONSENSUS_REACHED = "consensus_reached"
    
    # ğŸ†• ç»“å¯¹ç¼–ç¨‹
    PAIR_SESSION_START = "pair_session_start"
    PAIR_SUGGESTION = "pair_suggestion"
    PAIR_SESSION_END = "pair_session_end"
    
    # ç³»ç»Ÿç›¸å…³
    STATUS_UPDATE = "status_update"
    ERROR_REPORT = "error_report"
    NOTIFICATION = "notification"


class ArtifactType(Enum):
    """äº§å‡ºç‰©ç±»å‹ - æ‰©å±•ç‰ˆ."""
    
    # æ–‡æ¡£ç±»
    REQUIREMENT_DOC = "requirement_doc"
    DESIGN_DOC = "design_doc"
    ARCHITECTURE_DOC = "architecture_doc"
    API_SPEC = "api_spec"
    TEST_PLAN = "test_plan"
    RUNBOOK = "runbook"  # ğŸ†•
    
    # ä»£ç ç±»
    SOURCE_CODE = "source_code"
    TEST_CODE = "test_code"
    CONFIG_FILE = "config_file"
    SCRIPT = "script"
    MIGRATION = "migration"  # ğŸ†•
    
    # é…ç½®ç±»
    DOCKERFILE = "dockerfile"  # ğŸ†•
    K8S_MANIFEST = "k8s_manifest"  # ğŸ†•
    CI_CONFIG = "ci_config"  # ğŸ†•
    
    # åˆ†æç±»
    REVIEW_REPORT = "review_report"
    SECURITY_REPORT = "security_report"  # ğŸ†•
    PERFORMANCE_REPORT = "performance_report"  # ğŸ†•
    
    # å…¶ä»–
    DIAGRAM = "diagram"


class ToolType(Enum):
    """å·¥å…·ç±»å‹ - ğŸ†• å…¨æ–°."""
    
    CODE_EXECUTOR = "code_executor"      # ä»£ç æ‰§è¡Œå™¨
    FILE_SYSTEM = "file_system"          # æ–‡ä»¶ç³»ç»Ÿ
    GIT = "git"                          # Gitæ“ä½œ
    TERMINAL = "terminal"                # ç»ˆç«¯å‘½ä»¤
    BROWSER = "browser"                  # æµè§ˆå™¨
    SEARCH = "search"                    # æœç´¢å¼•æ“
    LINTER = "linter"                    # ä»£ç æ£€æŸ¥
    TEST_RUNNER = "test_runner"          # æµ‹è¯•è¿è¡Œ
    DATABASE = "database"                # æ•°æ®åº“æ“ä½œ


# =============================================================================
# ğŸ“¦ æ ¸å¿ƒæ•°æ®ç±»
# =============================================================================


@dataclass
class AgentProfile:
    """æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ - å‡çº§ç‰ˆ.
    
    æ–°å¢ï¼š
    - ä¸“ä¸šç­‰çº§
    - æ€è€ƒé£æ ¼
    - åä½œåå¥½
    - å·¥å…·æƒé™
    """
    
    id: AgentId = field(default_factory=lambda: generate_id("agent"))
    name: str = ""
    role: AgentRole = AgentRole.BACKEND_ENGINEER
    
    # èƒ½åŠ›é…ç½®
    capabilities: list[AgentCapability] = field(default_factory=list)
    capability_levels: dict[AgentCapability, int] = field(default_factory=dict)
    expertise_level: ExpertiseLevel = ExpertiseLevel.SENIOR
    
    # ğŸ†• è®¤çŸ¥é…ç½®
    thinking_style: str = "analytical"  # analytical, creative, balanced
    reflection_enabled: bool = True
    planning_depth: int = 3  # è§„åˆ’æ·±åº¦
    
    # ğŸ†• åä½œé…ç½®
    collaboration_style: str = "cooperative"  # cooperative, assertive, balanced
    debate_skill: int = 7  # 1-10
    consensus_flexibility: float = 0.7  # 0-1
    
    # ğŸ†• å·¥å…·æƒé™
    allowed_tools: list[ToolType] = field(default_factory=list)
    
    # LLMé…ç½®
    system_prompt: str = ""
    temperature: float = 0.7
    max_tokens: int = 4096
    model: str = "gpt-4"
    
    # æ‰§è¡Œé…ç½®
    max_retries: int = 3
    timeout_seconds: int = 300
    
    def has_capability(
        self, 
        capability: AgentCapability, 
        min_level: int = 1,
    ) -> bool:
        """æ£€æŸ¥æ˜¯å¦å…·å¤‡èƒ½åŠ›."""
        if capability not in self.capabilities:
            return False
        return self.capability_levels.get(capability, 0) >= min_level
    
    def can_use_tool(self, tool: ToolType) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·æƒé™."""
        return tool in self.allowed_tools


@dataclass
class Task:
    """ä»»åŠ¡å®šä¹‰ - å‡çº§ç‰ˆ.
    
    æ–°å¢ï¼š
    - å¤æ‚åº¦è¯„ä¼°
    - è´¨é‡è¦æ±‚
    - åä½œéœ€æ±‚
    - å·¥å…·éœ€æ±‚
    """
    
    id: TaskId = field(default_factory=lambda: generate_id("task"))
    title: str = ""
    description: str = ""
    
    # åˆ†ç±»
    type: str = "development"
    priority: TaskPriority = TaskPriority.MEDIUM
    status: TaskStatus = TaskStatus.PENDING
    
    # èƒ½åŠ›è¦æ±‚
    required_capabilities: list[AgentCapability] = field(default_factory=list)
    required_role: AgentRole | None = None
    min_expertise_level: ExpertiseLevel = ExpertiseLevel.INTERMEDIATE
    
    # ğŸ†• å¤æ‚åº¦è¯„ä¼°
    complexity: int = 5  # 1-10
    estimated_hours: float = 4.0
    risk_level: str = "medium"  # low, medium, high, critical
    
    # ğŸ†• è´¨é‡è¦æ±‚
    quality_requirements: QualityRequirements | None = None
    
    # ğŸ†• åä½œéœ€æ±‚
    requires_review: bool = True
    requires_debate: bool = False
    requires_pair_programming: bool = False
    min_reviewers: int = 1
    
    # ğŸ†• å·¥å…·éœ€æ±‚
    required_tools: list[ToolType] = field(default_factory=list)
    
    # ä¾èµ–å…³ç³»
    dependencies: list[TaskId] = field(default_factory=list)
    blocked_by: list[TaskId] = field(default_factory=list)
    subtasks: list[TaskId] = field(default_factory=list)
    parent_task_id: TaskId | None = None
    
    # åˆ†é…
    assigned_to: AgentId | None = None
    reviewers: list[AgentId] = field(default_factory=list)
    
    # æ—¶é—´
    created_at: datetime = field(default_factory=datetime.now)
    started_at: datetime | None = None
    completed_at: datetime | None = None
    deadline: datetime | None = None
    
    # ä¸Šä¸‹æ–‡
    context: dict[str, Any] = field(default_factory=dict)
    
    # ç»“æœ
    result: TaskResult | None = None


@dataclass
class QualityRequirements:
    """è´¨é‡è¦æ±‚ - ğŸ†• å…¨æ–°."""
    
    # ä»£ç è´¨é‡
    min_test_coverage: float = 0.8
    max_complexity: int = 10
    require_type_hints: bool = True
    require_docstrings: bool = True
    
    # å®‰å…¨è¦æ±‚
    security_scan_required: bool = True
    allowed_vulnerabilities: int = 0
    
    # æ€§èƒ½è¦æ±‚
    performance_test_required: bool = False
    max_response_time_ms: int | None = None
    
    # å®¡æŸ¥è¦æ±‚
    require_architecture_review: bool = False
    require_security_review: bool = False


@dataclass
class TaskResult:
    """ä»»åŠ¡ç»“æœ - å‡çº§ç‰ˆ."""
    
    task_id: TaskId = ""
    success: bool = False
    
    # äº§å‡ºç‰©
    artifacts: list[Artifact] = field(default_factory=list)
    
    # ğŸ†• æ€è€ƒè¿‡ç¨‹
    reasoning_trace: list[ReasoningStep] = field(default_factory=list)
    reflections: list[str] = field(default_factory=list)
    
    # è´¨é‡æŒ‡æ ‡
    confidence_score: float = 0.0
    quality_score: float = 0.0
    
    # ğŸ†• è¯¦ç»†æŒ‡æ ‡
    metrics: dict[str, float] = field(default_factory=dict)
    
    # æ‰§è¡Œä¿¡æ¯
    execution_time_seconds: float = 0.0
    token_usage: dict[str, int] = field(default_factory=dict)
    tools_used: list[ToolType] = field(default_factory=list)
    
    # é”™è¯¯ä¿¡æ¯
    error_message: str | None = None
    error_type: str | None = None
    
    # ğŸ†• æ”¹è¿›å»ºè®®
    suggestions: list[str] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)
    learned_lessons: list[str] = field(default_factory=list)


@dataclass
class Artifact:
    """äº§å‡ºç‰© - å‡çº§ç‰ˆ."""
    
    id: ArtifactId = field(default_factory=lambda: generate_id("artifact"))
    type: ArtifactType = ArtifactType.SOURCE_CODE
    name: str = ""
    
    # å†…å®¹
    content: str = ""
    file_path: Path | None = None
    
    # å…ƒæ•°æ®
    language: str | None = None
    framework: str | None = None
    
    # ç‰ˆæœ¬æ§åˆ¶
    version: str = "1.0.0"
    created_at: datetime = field(default_factory=datetime.now)
    created_by: AgentId | None = None
    
    # ğŸ†• è´¨é‡ä¿¡æ¯
    quality_score: float | None = None
    test_coverage: float | None = None
    
    # å®¡æŸ¥ä¿¡æ¯
    reviewed: bool = False
    approved: bool = False
    review_comments: list[ReviewComment] = field(default_factory=list)


@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤ - ğŸ†• å…¨æ–°."""
    
    step_number: int = 0
    thought: str = ""
    action: str | None = None
    observation: str | None = None
    reflection: str | None = None
    confidence: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class ReviewComment:
    """å®¡æŸ¥è¯„è®º - å‡çº§ç‰ˆ."""
    
    id: str = field(default_factory=lambda: generate_id("comment"))
    reviewer_id: AgentId = ""
    
    # ä½ç½®
    file_path: str | None = None
    line_start: int | None = None
    line_end: int | None = None
    
    # å†…å®¹
    comment: str = ""
    severity: str = "info"  # info, suggestion, warning, error, critical
    category: str = ""  # style, logic, security, performance, etc.
    
    # ğŸ†• å»ºè®®
    suggestion: str | None = None
    suggested_code: str | None = None
    auto_fixable: bool = False
    
    # çŠ¶æ€
    resolved: bool = False
    resolution: str | None = None


@dataclass
class AgentMessage:
    """æ™ºèƒ½ä½“æ¶ˆæ¯ - å‡çº§ç‰ˆ."""
    
    id: str = field(default_factory=lambda: generate_id("msg"))
    type: MessageType = MessageType.NOTIFICATION
    
    # å‘é€æ–¹/æ¥æ”¶æ–¹
    sender_id: AgentId = ""
    receiver_id: AgentId | None = None  # None = å¹¿æ’­
    
    # å†…å®¹
    subject: str = ""
    content: str = ""
    data: dict[str, Any] = field(default_factory=dict)
    
    # å…³è”
    task_id: TaskId | None = None
    artifact_id: ArtifactId | None = None
    reply_to: str | None = None
    thread_id: str | None = None
    
    # ğŸ†• ä¼˜å…ˆçº§å’Œè¿‡æœŸ
    priority: int = 3  # 1-5
    expires_at: datetime | None = None
    
    # æ—¶é—´å’ŒçŠ¶æ€
    timestamp: datetime = field(default_factory=datetime.now)
    read: bool = False
    processed: bool = False


@dataclass
class AgentState:
    """æ™ºèƒ½ä½“çŠ¶æ€ - å‡çº§ç‰ˆ."""
    
    agent_id: AgentId = ""
    status: str = "idle"  # idle, working, reviewing, debating, blocked
    
    # å½“å‰å·¥ä½œ
    current_task_id: TaskId | None = None
    current_activity: str | None = None
    
    # ğŸ†• è®¤çŸ¥çŠ¶æ€
    thinking: bool = False
    current_thought: str | None = None
    
    # é˜Ÿåˆ—
    pending_messages: int = 0
    pending_reviews: int = 0
    
    # ç»Ÿè®¡
    tasks_completed: int = 0
    tasks_failed: int = 0
    reviews_completed: int = 0
    
    # ğŸ†• æ€§èƒ½æŒ‡æ ‡
    average_task_time: float = 0.0
    average_quality_score: float = 0.0
    success_rate: float = 1      
    
    # æ—¶é—´
    last_active: datetime = field(default_factory=datetime.now)
    session_start: datetime = field(default_factory=datetime.now)


@dataclass
class TaskContext:
    """ä»»åŠ¡ä¸Šä¸‹æ–‡ - å‡çº§ç‰ˆ."""
    
    # é¡¹ç›®ä¿¡æ¯
    project_name: str = ""
    project_description: str = ""
    project_root: Path | None = None
    
    # æŠ€æœ¯æ ˆ
    tech_stack: dict[str, list[str]] = field(default_factory=dict)
    
    # ç¼–ç è§„èŒƒ
    coding_standards: dict[str, Any] = field(default_factory=dict)
    
    # æ¶æ„å†³ç­–
    architecture_decisions: list[str] = field(default_factory=list)
    design_patterns: list[str] = field(default_factory=list)
    
    # å·²æœ‰èµ„æº
    existing_artifacts: list[Artifact] = field(default_factory=list)
    completed_tasks: list[TaskId] = field(default_factory=list)
    
    # ğŸ†• çŸ¥è¯†åº“
    domain_knowledge: dict[str, Any] = field(default_factory=dict)
    learned_patterns: list[str] = field(default_factory=list)
    
    # ğŸ†• çº¦æŸæ¡ä»¶
    constraints: list[str] = field(default_factory=list)
    non_functional_requirements: dict[str, Any] = field(default_factory=dict)
    
    # ä¼šè¯
    conversation_history: list[dict[str, str]] = field(default_factory=list)
    
    # å˜é‡
    variables: dict[str, Any] = field(default_factory=dict)


# =============================================================================
# ğŸ”— è§’è‰²èƒ½åŠ›æ˜ å°„ - å‡çº§ç‰ˆ
# =============================================================================

ROLE_CAPABILITIES: dict[AgentRole, list[AgentCapability]] = {
    # ç®¡ç†å±‚
    AgentRole.PROJECT_MANAGER: [
        AgentCapability.REQUIREMENT_ANALYSIS,
        AgentCapability.TASK_DECOMPOSITION,
        AgentCapability.EFFORT_ESTIMATION,
        AgentCapability.RISK_ASSESSMENT,
        AgentCapability.ROADMAP_PLANNING,
    ],
    
    # å†³ç­–å±‚
    AgentRole.TECH_DIRECTOR: [
        AgentCapability.SYSTEM_DESIGN,
        AgentCapability.RISK_ASSESSMENT,
        AgentCapability.CODE_REVIEW,
        AgentCapability.DISTRIBUTED_SYSTEMS,
    ],
    
    # æ¶æ„å±‚
    AgentRole.SYSTEM_ARCHITECT: [
        AgentCapability.SYSTEM_DESIGN,
        AgentCapability.API_DESIGN,
        AgentCapability.DATABASE_DESIGN,
        AgentCapability.MICROSERVICES_DESIGN,
        AgentCapability.EVENT_DRIVEN_DESIGN,
        AgentCapability.DISTRIBUTED_SYSTEMS,
    ],
    AgentRole.SOLUTION_ARCHITECT: [
        AgentCapability.SYSTEM_DESIGN,
        AgentCapability.API_DESIGN,
        AgentCapability.MICROSERVICES_DESIGN,
    ],
    
    # å¼€å‘å±‚
    AgentRole.TECH_LEAD: [
        AgentCapability.CODE_GENERATION,
        AgentCapability.CODE_REVIEW,
        AgentCapability.CODE_REFACTORING,
        AgentCapability.CODE_OPTIMIZATION,
        AgentCapability.SYSTEM_DESIGN,
        AgentCapability.PYTHON_EXPERT,
    ],
    AgentRole.BACKEND_ENGINEER: [
        AgentCapability.CODE_GENERATION,
        AgentCapability.CODE_DEBUGGING,
        AgentCapability.API_DESIGN,
        AgentCapability.DATABASE_DESIGN,
        AgentCapability.UNIT_TESTING,
        AgentCapability.PYTHON_EXPERT,
        AgentCapability.SQL_EXPERT,
    ],
    AgentRole.FRONTEND_ENGINEER: [
        AgentCapability.CODE_GENERATION,
        AgentCapability.CODE_DEBUGGING,
        AgentCapability.UNIT_TESTING,
        AgentCapability.JAVASCRIPT_EXPERT,
        AgentCapability.TYPESCRIPT_EXPERT,
    ],
    AgentRole.FULLSTACK_ENGINEER: [
        AgentCapability.CODE_GENERATION,
        AgentCapability.CODE_DEBUGGING,
        AgentCapability.API_DESIGN,
        AgentCapability.UNIT_TESTING,
        AgentCapability.PYTHON_EXPERT,
        AgentCapability.JAVASCRIPT_EXPERT,
        AgentCapability.SQL_EXPERT,
    ],
    
    # è´¨é‡å±‚
    AgentRole.QA_ENGINEER: [
        AgentCapability.TEST_PLANNING,
        AgentCapability.TEST_CASE_DESIGN,
        AgentCapability.UNIT_TESTING,
        AgentCapability.INTEGRATION_TESTING,
        AgentCapability.E2E_TESTING,
    ],
    AgentRole.QA_LEAD: [
        AgentCapability.TEST_PLANNING,
        AgentCapability.TEST_CASE_DESIGN,
        AgentCapability.UNIT_TESTING,
        AgentCapability.INTEGRATION_TESTING,
        AgentCapability.E2E_TESTING,
        AgentCapability.PERFORMANCE_TESTING,
        AgentCapability.RISK_ASSESSMENT,
    ],
    AgentRole.CODE_REVIEWER: [
        AgentCapability.CODE_REVIEW,
        AgentCapability.CODE_REFACTORING,
        AgentCapability.CODE_OPTIMIZATION,
        AgentCapability.SECURITY_ANALYSIS,
    ],
    AgentRole.PERFORMANCE_ENGINEER: [
        AgentCapability.CODE_OPTIMIZATION,
        AgentCapability.PERFORMANCE_TESTING,
        AgentCapability.CODE_DEBUGGING,
    ],
    
    # å®‰å…¨å±‚
    AgentRole.SECURITY_ARCHITECT: [
        AgentCapability.SECURITY_ANALYSIS,
        AgentCapability.VULNERABILITY_ASSESSMENT,
        AgentCapability.SECURITY_AUDIT,
        AgentCapability.PENETRATION_TESTING,
    ],
    
    # è¿ç»´å±‚
    AgentRole.DEVOPS_ENGINEER: [
        AgentCapability.CI_CD_PIPELINE,
        AgentCapability.CONTAINERIZATION,
        AgentCapability.ORCHESTRATION,
        AgentCapability.INFRASTRUCTURE_AS_CODE,
        AgentCapability.MONITORING,
    ],
    AgentRole.SRE_ENGINEER: [
        AgentCapability.MONITORING,
        AgentCapability.CI_CD_PIPELINE,
        AgentCapability.CONTAINERIZATION,
        AgentCapability.ORCHESTRATION,
    ],
    
    # æ–‡æ¡£å±‚
    AgentRole.TECH_WRITER: [
        AgentCapability.DOCUMENTATION,
        AgentCapability.API_DOCUMENTATION,
    ],
}


# =============================================================================
# ğŸ”Œ åè®®æ¥å£
# =============================================================================


@runtime_checkable
class IAgent(Protocol):
    """æ™ºèƒ½ä½“åè®®æ¥å£."""
    
    @property
    def profile(self) -> AgentProfile:
        """è·å–é…ç½®."""
        ...
    
    async def execute(self, task: Task, context: TaskContext) -> TaskResult:
        """æ‰§è¡Œä»»åŠ¡."""
        ...
    
    async def review(self, artifact: Artifact, context: TaskContext) -> ReviewResult:
        """å®¡æŸ¥äº§å‡ºç‰©."""
        ...
    
    async def collaborate(self, message: AgentMessage) -> AgentMessage | None:
        """å¤„ç†åä½œæ¶ˆæ¯."""
        ...


@runtime_checkable
class ICognitive(Protocol):
    """è®¤çŸ¥èƒ½åŠ›åè®® - ğŸ†•."""
    
    async def think(self, problem: str, context: TaskContext) -> list[ReasoningStep]:
        """æ·±åº¦æ€è€ƒ."""
        ...
    
    async def reflect(self, action: str, result: Any) -> str:
        """è‡ªæˆ‘åæ€."""
        ...
    
    async def plan(self, goal: str, context: TaskContext) -> list[Task]:
        """åˆ¶å®šè®¡åˆ’."""
        ...


@runtime_checkable
class ICollaborative(Protocol):
    """åä½œèƒ½åŠ›åè®® - ğŸ†•."""
    
    async def debate(self, topic: str, position: str) -> DebateArgument:
        """å‚ä¸è¾©è®º."""
        ...
    
    async def vote(self, proposal: str) -> Vote:
        """æŠ•ç¥¨è¡¨å†³."""
        ...
    
    async def pair_program(self, partner_id: AgentId, task: Task) -> TaskResult:
        """ç»“å¯¹ç¼–ç¨‹."""
        ...


@dataclass
class ReviewResult:
    """å®¡æŸ¥ç»“æœ."""
    
    approved: bool = False
    reviewer_id: AgentId = ""
    
    # è¯„åˆ†
    overall_score: float = 0.0
    scores: dict[str, float] = field(default_factory=dict)
    
    # åé¦ˆ
    comments: list[ReviewComment] = field(default_factory=list)
    suggestions: list[str] = field(default_factory=list)
    required_changes: list[str] = field(default_factory=list)
    
    # ç»Ÿè®¡
    issues_found: int = 0
    critical_issues: int = 0


@dataclass
class DebateArgument:
    """è¾©è®ºè®ºç‚¹ - ğŸ†•."""
    
    agent_id: AgentId = ""
    position: str = ""  # for, against, neutral
    
    # è®ºç‚¹
    main_argument: str = ""
    supporting_points: list[str] = field(default_factory=list)
    evidence: list[str] = field(default_factory=list)
    
    # åé©³
    rebuttals: list[str] = field(default_factory=list)
    
    # è¯„ä¼°
    confidence: float = 0.0
    strength: float = 0.0


@dataclass
class Vote:
    """æŠ•ç¥¨ - ğŸ†•."""
    
    agent_id: AgentId = ""
    proposal_id: str = ""
    
    # æŠ•ç¥¨
    vote: str = ""  # approve, reject, abstain
    weight: float = 1.0
    
    # ç†ç”±
    rationale: str = ""
    conditions: list[str] = field(default_factory=list)

    1. è®¤çŸ¥æ¨¡å— (cognitive/reasoning.py) - ğŸ†• å…¨æ–° python   """ä¸»å¸­çº§æ™ºèƒ½ä½“ - è®¤çŸ¥æ¨ç†å¼•æ“.

å®ç°ï¼š
- æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰
- æ€ç»´æ ‘ï¼ˆTree of Thoughtï¼‰
- è‡ªæˆ‘åæ€ï¼ˆSelf-Reflectionï¼‰
- è§„åˆ’èƒ½åŠ›ï¼ˆPlanningï¼‰
"""

from __future__ import annotations

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

from ..core.types import (
    AgentId,
    ReasoningStep,
    Task,
    TaskContext,
)

if TYPE_CHECKING:
    from ..integration.llm import LLMClient


logger = logging.getLogger(__name__)


@dataclass
class ThoughtNode:
    """æ€ç»´æ ‘èŠ‚ç‚¹."""
    
    id: str = ""
    thought: str = ""
    evaluation: float = 0.0
    children: list[ThoughtNode] = field(default_factory=list)
    parent_id: str | None = None
    depth: int = 0
    is_terminal: bool = False
    
    # å…ƒæ•°æ®
    created_at: datetime = field(default_factory=datetime.now)
    reasoning_type: str = ""  # deductive, inductive, abductive


@dataclass
class ReasoningResult:
    """æ¨ç†ç»“æœ."""
    
    conclusion: str = ""
    confidence: float = 0.0
    
    # æ¨ç†è¿‡ç¨‹
    steps: list[ReasoningStep] = field(default_factory=list)
    thought_tree: ThoughtNode | None = None
    
    # å…ƒæ•°æ®     
    reasoning_type: str = ""
    time_spent_seconds: float = 0.0
    tokens_used: int = 0
    
    # è‡ªæˆ‘è¯„ä¼°
    self_evaluation: str = ""
    potential_flaws: list[str] = field(default_factory=list)
    alternatives_considered: list[str] = field(default_factory=list)


class ReasoningEngine:
    """æ¨ç†å¼•æ“ - ä¸»å¸­çº§è®¤çŸ¥æ ¸å¿ƒ.
    
    å®ç°å¤šç§æ¨ç†ç­–ç•¥ï¼š
    - æ€ç»´é“¾ï¼šçº¿æ€§é€æ­¥æ¨ç†
    - æ€ç»´æ ‘ï¼šæ¢ç´¢å¤šä¸ªæ¨ç†è·¯å¾„
    - è‡ªæˆ‘ä¸€è‡´æ€§ï¼šå¤šæ¬¡æ¨ç†å–å…±è¯†
    - åæ€æ¨ç†ï¼šå¸¦è‡ªæˆ‘æ£€æŸ¥çš„æ¨ç†
    """
    
    def __init__(
        self,
        llm_client: LLMClient,
        default_strategy: str = "chain_of_thought",
    ) -> None:
        """åˆå§‹åŒ–æ¨ç†å¼•æ“."""
        self._llm = llm_client
        self._default_strategy = default_strategy
        self._reasoning_history: list[ReasoningResult] = []
    
    async def reason(
        self,
        problem: str,
        context: TaskContext,
        strategy: str | None = None,
        max_steps: int = 10,
    ) -> ReasoningResult:
        """æ‰§è¡Œæ¨ç†.
        
        Args:
            problem: è¦è§£å†³çš„é—®é¢˜
            context: ä»»åŠ¡ä¸Šä¸‹æ–‡
            strategy: æ¨ç†ç­–ç•¥
            max_steps: æœ€å¤§æ¨ç†æ­¥æ•°
            
        Returns:
            æ¨ç†ç»“æœ
        """
        strategy = strategy or self._default_strategy
        
        logger.info(f"å¼€å§‹æ¨ç†ï¼Œç­–ç•¥: {strategy}")
        start_time = datetime.now()
        
        if strategy == "chain_of_thought":
            result = await self._chain_of_thought(problem, context, max_steps)
        elif strategy == "tree_of_thought":
            result = await self._tree_of_thought(problem, context, max_steps)
        elif strategy == "self_consistency":
            result = await self._self_consistency(problem, context)
        elif strategy == "reflexion":
            result = await self._reflexion(problem, context, max_steps)
        else:
            result = await self._chain_of_thought(problem, context, max_steps)
        
        result.time_spent_seconds = (datetime.now() - start_time).total_seconds()
        self._reasoning_history.append(result)
        
        return result
    
    async def _chain_of_thought(
        self,
        problem: str,
        context: TaskContext,
        max_steps: int,
    ) -> ReasoningResult:
        """æ€ç»´é“¾æ¨ç†.
        
        é€æ­¥åˆ†è§£é—®é¢˜ï¼Œæ¯æ­¥åŸºäºå‰ä¸€æ­¥çš„ç»“è®ºã€‚
        """
        steps: list[ReasoningStep] = []
        current_thought = problem
        
        cot_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„é—®é¢˜è§£å†³ä¸“å®¶ã€‚è¯·ä½¿ç”¨æ€ç»´é“¾æ–¹æ³•é€æ­¥åˆ†æé—®é¢˜ã€‚

é—®é¢˜ï¼š{problem}

èƒŒæ™¯ä¿¡æ¯ï¼š
{context}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼é€æ­¥æ€è€ƒï¼š

æ­¥éª¤ 1: [åˆ†æé—®é¢˜çš„ç¬¬ä¸€ä¸ªæ–¹é¢]
æ€è€ƒ: [ä½ çš„æ¨ç†è¿‡ç¨‹]
ç»“è®º: [è¿™ä¸€æ­¥çš„ç»“è®º]

æ­¥éª¤ 2: [åŸºäºæ­¥éª¤1ï¼Œåˆ†æä¸‹ä¸€ä¸ªæ–¹é¢]
æ€è€ƒ: [ä½ çš„æ¨ç†è¿‡ç¨‹]
ç»“è®º: [è¿™ä¸€æ­¥çš„ç»“è®º]

...ç»§ç»­ç›´åˆ°å¾—å‡ºæœ€ç»ˆç»“è®º...

æœ€ç»ˆç»“è®º: [ç»¼åˆæ‰€æœ‰æ­¥éª¤çš„æœ€ç»ˆç­”æ¡ˆ]
ç½®ä¿¡åº¦: [0.0-1.0]
"""
        
        response = await self._llm.generate(
            prompt=cot_prompt.format(
                problem=problem,
                context=self._format_context(context),
            ),
            temperature=0.3,  # æ¨ç†æ—¶ä½¿ç”¨è¾ƒä½æ¸©åº¦
        )
        
        # è§£ææ¨ç†æ­¥éª¤
        steps = self._parse_cot_response(response)
        conclusion, confidence = self._extract_conclusion(response)
        
        return ReasoningResult(
            conclusion=conclusion,
            confidence=confidence,
            steps=steps,
            reasoning_type="chain_of_thought",
        )
    
    async def _tree_of_thought(
        self,
        problem: str,
        context: TaskContext,
        max_steps: int,
    ) -> ReasoningResult:
        """æ€ç»´æ ‘æ¨ç†.
        
        æ¢ç´¢å¤šä¸ªæ¨ç†è·¯å¾„ï¼Œè¯„ä¼°å¹¶é€‰æ‹©æœ€ä½³è·¯å¾„ã€‚
        """
        root = ThoughtNode(
            id="root",
            thought=problem,
            depth=0,
        )
        
        # BFSæ¢ç´¢æ€ç»´æ ‘
        best_path: list[ThoughtNode] = []
        best_score = 0.0
        
        queue = [root]
        while queue and len(best_path) < max_steps:
            current = queue.pop(0)
            
            if current.depth >= max_steps:
                continue
            
            # ç”Ÿæˆå­èŠ‚ç‚¹ï¼ˆå¤šä¸ªå¯èƒ½çš„æ€è€ƒæ–¹å‘ï¼‰
            children = await self._generate_thought_branches(
                current, context, num_branches=3
            )
            
            # è¯„ä¼°æ¯ä¸ªåˆ†æ”¯
            for child in children:
                child.evaluation = await self._evaluate_thought(child, context)
                current.children.append(child)
                
                if child.is_terminal and child.evaluation > best_score:
                    best_score = child.evaluation
                    best_path = self._trace_path(child, root)
                elif not child.is_terminal:
                    queue.append(child)
            
            # æŒ‰è¯„ä¼°åˆ†æ•°æ’åº
            queue.sort(key=lambda x: x.evaluation, reverse=True)
            queue = queue[:5]  # ä¿ç•™top-5
        
        # ä»æœ€ä½³è·¯å¾„ç”Ÿæˆç»“è®º
        steps = [
            ReasoningStep(
                step_number=i,
                thought=node.thought,
                confidence=node.evaluation,
            )
            for i, node in enumerate(best_path)
        ]
        
        return ReasoningResult(
            conclusion=best_path[-1].thought if best_path else "",
            confidence=best_score,
            steps=steps,
            thought_tree=root,
            reasoning_type="tree_of_thought",
        )
    
    async def _self_consistency(
        self,
        problem: str,
        context: TaskContext,
        num_samples: int = 5,
    ) -> ReasoningResult:
        """è‡ªæˆ‘ä¸€è‡´æ€§æ¨ç†.
        
        å¤šæ¬¡ç‹¬ç«‹æ¨ç†ï¼Œå–å¤šæ•°å…±è¯†ã€‚
        """
        # å¹¶è¡Œæ‰§è¡Œå¤šæ¬¡æ¨ç†
        tasks = [
            self._chain_of_thought(problem, context, max_steps=5)
            for _ in range(num_samples)
        ]
        results = await asyncio.gather(*tasks)
        
        # æå–æ‰€æœ‰ç»“è®º
        conclusions = [r.conclusion for r in results]
        
        # æ‰¾å‡ºæœ€ä¸€è‡´çš„ç»“è®º
        conclusion_counts: dict[str, int] = {}
        for c in conclusions:
            # ç®€åŒ–ï¼šä½¿ç”¨ç²¾ç¡®åŒ¹é…ï¼Œå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦
            key = c.strip().lower()
            conclusion_counts[key] = conclusion_counts.get(key, 0) + 1
        
        best_conclusion = max(conclusion_counts, key=conclusion_counts.get)
        consistency = conclusion_counts[best_conclusion] / num_samples
        
        # åˆå¹¶æ¨ç†æ­¥éª¤
        all_steps = []
        for i, r in enumerate(results):
            for step in r.steps:
                step.reflection = f"æ ·æœ¬ {i+1}"
                all_steps.append(step)
        
        return ReasoningResult(
            conclusion=best_conclusion,
            confidence=consistency,
            steps=all_steps,
            reasoning_type="self_consistency",
            alternatives_considered=[r.conclusion for r in results if r.conclusion != best_conclusion],
        )
    
    async def _reflexion(
        self,
        problem: str,
        context: TaskContext,
        max_iterations: int = 3,
    ) -> ReasoningResult:
        """åæ€æ¨ç†.
        
        æ¨ç†åè‡ªæˆ‘åæ€ï¼Œè¿­ä»£æ”¹è¿›ã€‚
        """
        current_result = await self._chain_of_thought(problem, context, max_steps=5)
        all_steps = list(current_result.steps)
        
        for iteration in range(max_iterations):
            # è‡ªæˆ‘åæ€
            reflection = await self._reflect_on_reasoning(
                problem, current_result, context
            )
            
            # æ£€æŸ¥æ˜¯å¦æ»¡æ„
            if reflection["satisfied"]:
                break
            
            # æ ¹æ®åæ€æ”¹è¿›
            improved_problem = f"""
åŸé—®é¢˜ï¼š{problem}

ä¹‹å‰çš„æ¨ç†ç»“è®ºï¼š{current_result.conclusion}

åæ€å‘ç°çš„é—®é¢˜ï¼š
{reflection['issues']}

è¯·é‡æ–°æ¨ç†ï¼Œé¿å…ä¸Šè¿°é—®é¢˜ï¼š
"""
            current_result = await self._chain_of_thought(
                improved_problem, context, max_steps=5
            )
            
            # è®°å½•åæ€æ­¥éª¤
            all_steps.append(ReasoningStep(
                step_number=len(all_steps),
                thought=f"åæ€è¿­ä»£ {iteration + 1}",
                reflection=reflection["issues"],
                confidence=current_result.confidence,
            ))
            all_steps.extend(current_result.steps)
        
        return ReasoningResult(
            conclusion=current_result.conclusion,
            confidence=current_result.confidence,
            steps=all_steps,
            reasoning_type="reflexion",
            self_evaluation=reflection.get("evaluation", ""),
            potential_flaws=reflection.get("remaining_concerns", []),
        )
    
    async def _generate_thought_branches(
        self,
        node: ThoughtNode,
        context: TaskContext,
        num_branches: int = 3,
    ) -> list[ThoughtNode]:
        """ç”Ÿæˆæ€ç»´åˆ†æ”¯."""
        prompt = f"""åŸºäºå½“å‰æ€è€ƒï¼Œç”Ÿæˆ{num_branches}ä¸ªä¸åŒçš„æ¨ç†æ–¹å‘ã€‚

å½“å‰æ€è€ƒï¼š{node.thought}
æ·±åº¦ï¼š{node.depth}

è¯·ç”Ÿæˆ{num_branches}ä¸ªä¸åŒçš„ä¸‹ä¸€æ­¥æ€è€ƒæ–¹å‘ï¼Œæ¯ä¸ªæ–¹å‘åº”è¯¥ï¼š
1. é€»è¾‘ä¸Šæ‰¿æ¥å½“å‰æ€è€ƒ
2. æ¢ç´¢ä¸åŒçš„è§’åº¦æˆ–æ–¹æ³•
3. æœç€è§£å†³é—®é¢˜çš„æ–¹å‘å‰è¿›

æ ¼å¼ï¼š
æ–¹å‘1: [æ€è€ƒå†…å®¹]
æ–¹å‘2: [æ€è€ƒå†…å®¹]
æ–¹å‘3: [æ€è€ƒå†…å®¹]
"""
        
        response = await self._llm.generate(prompt, temperature=0.7)
        
        branches = []
        for i, line in enumerate(response.strip().split("\n")):
            if line.startswith(f"æ–¹å‘{i+1}:"):
                thought = line.split(":", 1)[1].strip()
                branches.append(ThoughtNode(
                    id=f"{node.id}_{i}",
                    thought=thought,
                    parent_id=node.id,
                    depth=node.depth + 1,
                    is_terminal=node.depth + 1 >= 5,
                ))
        
        return branches
    
    async def _evaluate_thought(
        self,
        node: ThoughtNode,
        context: TaskContext,
    ) -> float:
        """è¯„ä¼°æ€ç»´èŠ‚ç‚¹è´¨é‡."""
        prompt = f"""è¯„ä¼°ä»¥ä¸‹æ¨ç†æ­¥éª¤çš„è´¨é‡ï¼ˆ0-1åˆ†ï¼‰ï¼š

æ¨ç†å†…å®¹ï¼š{node.thought}
æ¨ç†æ·±åº¦ï¼š{node.depth}

è¯„ä¼°æ ‡å‡†ï¼š
- é€»è¾‘æ€§ï¼šæ¨ç†æ˜¯å¦åˆç†
- ç›¸å…³æ€§ï¼šæ˜¯å¦ä¸é—®é¢˜ç›¸å…³
- è¿›å±•æ€§ï¼šæ˜¯å¦æœç€è§£å†³æ–¹æ¡ˆå‰è¿›
- å¯è¡Œæ€§ï¼šç»“è®ºæ˜¯å¦å¯æ‰§è¡Œ

è¯·åªè¿”å›ä¸€ä¸ª0åˆ°1ä¹‹é—´çš„æ•°å­—ã€‚
"""
        
        response = await self._llm.generate(prompt, temperature=0.1)
        
        try:
            return float(response.strip())
        except ValueError:
            return 0.5
    
    async def _reflect_on_reasoning(
        self,
        problem: str,
        result: ReasoningResult,
        context: TaskContext,
    ) -> dict[str, Any]:
        """åæ€æ¨ç†è¿‡ç¨‹."""
        prompt = f"""è¯·åæ€ä»¥ä¸‹æ¨ç†è¿‡ç¨‹ï¼š

åŸé—®é¢˜ï¼š{problem}

æ¨ç†æ­¥éª¤ï¼š
{self._format_steps(result.steps)}

æœ€ç»ˆç»“è®ºï¼š{result.conclusion}
ç½®ä¿¡åº¦ï¼š{result.confidence}

è¯·è¯„ä¼°ï¼š
1. æ¨ç†è¿‡ç¨‹æ˜¯å¦æœ‰é€»è¾‘æ¼æ´ï¼Ÿ
2. æ˜¯å¦é—æ¼äº†é‡è¦å› ç´ ï¼Ÿ
3. ç»“è®ºæ˜¯å¦åˆç†ï¼Ÿ
4. æ˜¯å¦éœ€è¦æ”¹è¿›ï¼Ÿ

æ ¼å¼ï¼š
æ»¡æ„ï¼š[æ˜¯/å¦]
é—®é¢˜ï¼š[å‘ç°çš„é—®é¢˜ï¼Œå¦‚æœæœ‰]
è¯„ä¼°ï¼š[æ•´ä½“è¯„ä¼°]
å‰©ä½™æ‹…å¿§ï¼š[è¿˜æœ‰å“ªäº›ä¸ç¡®å®šçš„åœ°æ–¹]
"""
        
        response = await self._llm.generate(prompt, temperature=0.3)
        
        # è§£æåæ€ç»“æœ
        satisfied = "æ»¡æ„ï¼šæ˜¯" in response or "æ»¡æ„: æ˜¯" in response
        issues = ""
        if "é—®é¢˜ï¼š" in response:
            issues = response.split("é—®é¢˜ï¼š")[1].split("\n")[0].strip()
        
        return {
            "satisfied": satisfied,
            "issues": issues,
            "evaluation": response,
            "remaining_concerns": [],
        }
    
    def _format_context(self, context: TaskContext) -> str:
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡."""
        parts = []
        if context.project_name:
            parts.append(f"é¡¹ç›®ï¼š{context.project_name}")
        if context.tech_stack:
            parts.append(f"æŠ€æœ¯æ ˆï¼š{context.tech_stack}")
        if context.constraints:
            parts.append(f"çº¦æŸï¼š{context.constraints}")
        return "\n".join(parts) if parts else "æ— é¢å¤–èƒŒæ™¯ä¿¡æ¯"
    
    def _format_steps(self, steps: list[ReasoningStep]) -> str:
        """æ ¼å¼åŒ–æ¨ç†æ­¥éª¤."""
        lines = []
        for step in steps:
            lines.append(f"æ­¥éª¤ {step.step_number}: {step.thought}")
            if step.reflection:
                lines.append(f"  åæ€: {step.reflection}")
        return "\n".join(lines)
    
    def _parse_cot_response(self, response: str) -> list[ReasoningStep]:
        """è§£ææ€ç»´é“¾å“åº”."""
        steps = []
        current_step = 0
        
        for line in response.split("\n"):
            line = line.strip()
            if line.startswith("æ­¥éª¤") and ":" in line:
                current_step += 1
                thought = line.split(":", 1)[1].strip()
                steps.append(ReasoningStep(
                    step_number=current_step,
                    thought=thought,
                ))
            elif line.startswith("æ€è€ƒ:") and steps:
                steps[-1].observation = line.split(":", 1)[1].strip()
            elif line.startswith("ç»“è®º:") and steps:
                steps[-1].action = line.split(":", 1)[1].strip()
        
        return steps
    
    def _extract_conclusion(self, response: str) -> tuple[str, float]:
        """æå–æœ€ç»ˆç»“è®ºå’Œç½®ä¿¡åº¦."""
        conclusion = ""
        confidence = 0.7
        
        for line in response.split("\n"):
            line = line.strip()
            if line.startswith("æœ€ç»ˆç»“è®º"):
                conclusion = line.split(":", 1)[1].strip() if ":" in line else ""
            elif line.startswith("ç½®ä¿¡åº¦"):
                try:
                    confidence = float(line.split(":", 1)[1].strip())
                except (ValueError, IndexError):
                    pass
        
        return conclusion, confidence
    
    def _trace_path(self, node: ThoughtNode, root: ThoughtNode) -> list[ThoughtNode]:
        """è¿½æº¯ä»æ ¹åˆ°èŠ‚ç‚¹çš„è·¯å¾„."""
        path = [node]
        current = node
        
        # ç®€åŒ–å®ç°ï¼šå‡è®¾å¯ä»¥é€šè¿‡parent_idæ‰¾åˆ°çˆ¶èŠ‚ç‚¹
        # å®é™…å®ç°éœ€è¦ç»´æŠ¤èŠ‚ç‚¹ç´¢å¼•
        
        return path
    1. è®°å¿†æ¨¡å— (cognitive/memory.py) - ğŸ†• å…¨æ–° python """ä¸»å¸­çº§æ™ºèƒ½ä½“ - è®°å¿†ç³»ç»Ÿ.

å®ç°ï¼š
- çŸ­æœŸè®°å¿†ï¼ˆå·¥ä½œè®°å¿†ï¼‰
- é•¿æœŸè®°å¿†ï¼ˆæŒä¹…åŒ–ï¼‰
- æƒ…æ™¯è®°å¿†ï¼ˆç»éªŒï¼‰
- è¯­ä¹‰è®°å¿†ï¼ˆçŸ¥è¯†ï¼‰
"""

from __future__ import annotations

import json
import hashlib
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    from ..integration.llm import LLMClient


@dataclass
class MemoryItem:
    """è®°å¿†é¡¹."""
    
    id: str = ""
    content: str = ""
    memory_type: str = "short_term"  # short_term, long_term, episodic, semantic
    
    # å…ƒæ•°æ®
    source: str = ""  # task, conversation, learning, etc.
    tags: list[str] = field(default_factory=list)
    
    # é‡è¦æ€§å’Œç›¸å…³æ€§
    importance: float = 0.5
    relevance_decay: float = 0.1  # æ¯å¤©è¡°å‡
    
    # æ—¶é—´
    created_at: datetime = field(default_factory=datetime.now)
    last_accessed: datetime = field(default_factory=datetime.now)
    access_count: int = 0
    
    # å…³è”
    related_memories: list[str] = field(default_factory=list)
    
    # åµŒå…¥å‘é‡ï¼ˆç”¨äºè¯­ä¹‰æœç´¢ï¼‰
    embedding: list[float] | None = None
    
    def current_relevance(self) -> float:
        """è®¡ç®—å½“å‰ç›¸å…³æ€§ï¼ˆè€ƒè™‘æ—¶é—´è¡°å‡ï¼‰."""
        days_old = (datetime.now() - self.created_at).days
        decay = self.relevance_decay * days_old
        return max(0.0, self.importance - decay)


@dataclass
class MemorySearchResult:
    """è®°å¿†æœç´¢ç»“æœ."""
    
    memory: MemoryItem
    relevance_score: float = 0.0
    match_type: str = ""  #       2 @dataclass
class MemorySearchResult:
    """è®°å¿†æœç´¢ç»“æœ."""
    
    memory: MemoryItem
    relevance_score: float = 0.0
    match_type: str = ""  # exact, semantic, tag, temporal


class MemorySystem:
    """è®°å¿†ç³»ç»Ÿ - ä¸»å¸­çº§æ™ºèƒ½ä½“çš„å¤§è„‘å­˜å‚¨.
    
    åŠŸèƒ½ï¼š
    - çŸ­æœŸè®°å¿†ï¼šå½“å‰ä¼šè¯çš„å·¥ä½œè®°å¿†
    - é•¿æœŸè®°å¿†ï¼šæŒä¹…åŒ–çš„é‡è¦ä¿¡æ¯
    - æƒ…æ™¯è®°å¿†ï¼šè¿‡å»çš„ç»éªŒå’Œæ¡ˆä¾‹
    - è¯­ä¹‰è®°å¿†ï¼šé¢†åŸŸçŸ¥è¯†å’Œæ¦‚å¿µ
    """
    
    def __init__(
        self,
        llm_client: LLMClient | None = None,
        storage_path: Path | None = None,
        max_short_term: int = 100,
        max_long_term: int = 10000,
    ) -> None:
        """åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ."""
        self._llm = llm_client
        self._storage_path = storage_path
        self._max_short_term = max_short_term
        self._max_long_term = max_long_term
        
        # è®°å¿†å­˜å‚¨
        self._short_term: list[MemoryItem] = []
        self._long_term: dict[str, MemoryItem] = {}
        self._episodic: dict[str, MemoryItem] = {}  # æƒ…æ™¯è®°å¿†
        self._semantic: dict[str, MemoryItem] = {}  # è¯­ä¹‰è®°å¿†
        
        # åŠ è½½æŒä¹…åŒ–çš„è®°å¿†
        if storage_path and storage_path.exists():
            self._load_from_disk()
    
    # =========================================================================
    # å­˜å‚¨æ“ä½œ
    # =========================================================================
    
    def store(
        self,
        content: str,
        memory_type: str = "short_term",
        importance: float = 0.5,
        tags: list[str] | None = None,
        source: str = "",
    ) -> MemoryItem:
        """å­˜å‚¨è®°å¿†.
        
        Args:
            content: è®°å¿†å†…å®¹
            memory_type: è®°å¿†ç±»å‹
            importance: é‡è¦æ€§(0-1)
            tags: æ ‡ç­¾
            source: æ¥æº
            
        Returns:
            å­˜å‚¨çš„è®°å¿†é¡¹
        """
        memory = MemoryItem(
            id=self._generate_id(content),
            content=content,
            memory_type=memory_type,
            importance=importance,
            tags=tags or [],
            source=source,
        )
        
        if memory_type == "short_term":
            self._store_short_term(memory)
        elif memory_type == "long_term":
            self._store_long_term(memory)
        elif memory_type == "episodic":
            self._episodic[memory.id] = memory
        elif memory_type == "semantic":
            self._semantic[memory.id] = memory
        
        return memory
    
    def _store_short_term(self, memory: MemoryItem) -> None:
        """å­˜å‚¨çŸ­æœŸè®°å¿†."""
        self._short_term.append(memory)
        
        # è¶…å‡ºå®¹é‡æ—¶ï¼Œå°†é‡è¦çš„è½¬ä¸ºé•¿æœŸè®°å¿†ï¼Œåˆ é™¤ä¸é‡è¦çš„
        if len(self._short_term) > self._max_short_term:
            self._consolidate_short_term()
    
    def _store_long_term(self, memory: MemoryItem) -> None:
        """å­˜å‚¨é•¿æœŸè®°å¿†."""
        self._long_term[memory.id] = memory
        
        # è¶…å‡ºå®¹é‡æ—¶ï¼Œåˆ é™¤æœ€ä¸ç›¸å…³çš„
        if len(self._long_term) > self._max_long_term:
            self._prune_long_term()
    
    def _consolidate_short_term(self) -> None:
        """æ•´åˆçŸ­æœŸè®°å¿†."""
        # æŒ‰é‡è¦æ€§æ’åº
        self._short_term.sort(key=lambda x: x.importance, reverse=True)
        
        # å°†é‡è¦çš„è½¬ä¸ºé•¿æœŸè®°å¿†
        threshold = 0.7
        to_promote = [m for m in self._short_term if m.importance >= threshold]
        for memory in to_promote:
            memory.memory_type = "long_term"
            self._store_long_term(memory)
        
        # ä¿ç•™æœ€è¿‘çš„è®°å¿†
        self._short_term = self._short_term[:self._max_short_term // 2]
    
    def _prune_long_term(self) -> None:
        """ä¿®å‰ªé•¿æœŸè®°å¿†."""
        # æŒ‰å½“å‰ç›¸å…³æ€§æ’åº
        memories = list(self._long_term.values())
        memories.sort(key=lambda x: x.current_relevance())
        
        # åˆ é™¤æœ€ä¸ç›¸å…³çš„20%
        to_remove = memories[:len(memories) // 5]
        for memory in to_remove:
            del self._long_term[memory.id]
    
    # =========================================================================
    # æ£€ç´¢æ“ä½œ
    # =========================================================================
    
    def recall(
        self,
        query: str,
        memory_types: list[str] | None = None,
        tags: list[str] | None = None,
        limit: int = 10,
        min_relevance: float = 0.3,
    ) -> list[MemorySearchResult]:
        """å›å¿†/æ£€ç´¢è®°å¿†.
        
        Args:
            query: æŸ¥è¯¢å†…å®¹
            memory_types: è¦æœç´¢çš„è®°å¿†ç±»å‹
            tags: æŒ‰æ ‡ç­¾è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶
            min_relevance: æœ€å°ç›¸å…³æ€§
            
        Returns:
            ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        memory_types = memory_types or ["short_term", "long_term", "episodic", "semantic"]
        results: list[MemorySearchResult] = []
        
        # æ”¶é›†æ‰€æœ‰å€™é€‰è®°å¿†
        candidates: list[MemoryItem] = []
        if "short_term" in memory_types:
            candidates.extend(self._short_term)
        if "long_term" in memory_types:
            candidates.extend(self._long_term.values())
        if "episodic" in memory_types:
            candidates.extend(self._episodic.values())
        if "semantic" in memory_types:
            candidates.extend(self._semantic.values())
        
        # æŒ‰æ ‡ç­¾è¿‡æ»¤
        if tags:
            candidates = [m for m in candidates if any(t in m.tags for t in tags)]
        
        # è®¡ç®—ç›¸å…³æ€§
        for memory in candidates:
            relevance = self._calculate_relevance(query, memory)
            if relevance >= min_relevance:
                results.append(MemorySearchResult(
                    memory=memory,
                    relevance_score=relevance,
                    match_type=self._determine_match_type(query, memory),
                ))
                
                # æ›´æ–°è®¿é—®ä¿¡æ¯
                memory.last_accessed = datetime.now()
                memory.access_count += 1
        
        # æŒ‰ç›¸å…³æ€§æ’åº
        results.sort(key=lambda x: x.relevance_score, reverse=True)
        
        return results[:limit]
    
    def recall_recent(self, n: int = 10) -> list[MemoryItem]:
        """å›å¿†æœ€è¿‘çš„è®°å¿†."""
        all_memories = (
            self._short_term + 
            list(self._long_term.values())
        )
        all_memories.sort(key=lambda x: x.created_at, reverse=True)
        return all_memories[:n]
    
    def recall_by_tag(self, tag: str) -> list[MemoryItem]:
        """æŒ‰æ ‡ç­¾å›å¿†."""
        results = []
        for memory in self._iterate_all_memories():
            if tag in memory.tags:
                results.append(memory)
        return results
    
    def _calculate_relevance(self, query: str, memory: MemoryItem) -> float:
        """è®¡ç®—æŸ¥è¯¢ä¸è®°å¿†çš„ç›¸å…³æ€§."""
        # ç®€å•å®ç°ï¼šåŸºäºå…³é”®è¯é‡å 
        # å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨åµŒå…¥å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        query_words = set(query.lower().split())
        memory_words = set(memory.content.lower().split())
        
        if not query_words or not memory_words:
            return 0.0
        
        overlap = len(query_words & memory_words)
        max_len = max(len(query_words), len(memory_words))
        
        keyword_score = overlap / max_len if max_len > 0 else 0.0
        
        # ç»“åˆæ—¶é—´è¡°å‡
        relevance_factor = memory.current_relevance()
        
        return keyword_score * 0.7 + relevance_factor * 0.3
    
    def _determine_match_type(self, query: str, memory: MemoryItem) -> str:
        """ç¡®å®šåŒ¹é…ç±»å‹."""
        if query.lower() in memory.content.lower():
            return "exact"
        if any(tag in query.lower() for tag in memory.tags):
            return "tag"
        return "semantic"
    
    def _iterate_all_memories(self):
        """è¿­ä»£æ‰€æœ‰è®°å¿†."""
        yield from self._short_term
        yield from self._long_term.values()
        yield from self._episodic.values()
        yield from self._semantic.values()
    
    # =========================================================================
    # å­¦ä¹ æ“ä½œ
    # =========================================================================
    
    def learn(
        self,
        experience: str,
        lesson: str,
        context: dict[str, Any] | None = None,
    ) -> MemoryItem:
        """ä»ç»éªŒä¸­å­¦ä¹ .
        
        Args:
            experience: ç»éªŒæè¿°
            lesson: å­¦åˆ°çš„æ•™è®­
            context: ç›¸å…³ä¸Šä¸‹æ–‡
            
        Returns:
            åˆ›å»ºçš„æƒ…æ™¯è®°å¿†
        """
        content = f"ç»éªŒï¼š{experience}\næ•™è®­ï¼š{lesson}"
        if context:
            content += f"\nä¸Šä¸‹æ–‡ï¼š{json.dumps(context, ensure_ascii=False)}"
        
        return self.store(
            content=content,
            memory_type="episodic",
            importance=0.8,
            tags=["learned", "experience"],
            source="learning",
        )
    
    def store_knowledge(
        self,
        concept: str,
        definition: str,
        examples: list[str] | None = None,
        related_concepts: list[str] | None = None,
    ) -> MemoryItem:
        """å­˜å‚¨çŸ¥è¯†.
        
        Args:
            concept: æ¦‚å¿µåç§°
            definition: å®šä¹‰
            examples: ç¤ºä¾‹
            related_concepts: ç›¸å…³æ¦‚å¿µ
            
        Returns:
            åˆ›å»ºçš„è¯­ä¹‰è®°å¿†
        """
        content = f"æ¦‚å¿µï¼š{concept}\nå®šä¹‰ï¼š{definition}"
        if examples:
            content += f"\nç¤ºä¾‹ï¼š{'; '.join(examples)}"
        
        memory = self.store(
            content=content,
            memory_type="semantic",
            importance=0.9,
            tags=["knowledge", concept],
            source="knowledge_base",
        )
        
        if related_concepts:
            memory.related_memories = related_concepts
        
        return memory
    
    # =========================================================================
    # æŒä¹…åŒ–
    # =========================================================================
    
    def save_to_disk(self) -> None:
        """ä¿å­˜åˆ°ç£ç›˜."""
        if not self._storage_path:
            return
        
        self._storage_path.mkdir(parents=True, exist_ok=True)
        
        data = {
            "long_term": [self._serialize_memory(m) for m in self._long_term.values()],
            "episodic": [self._serialize_memory(m) for m in self._episodic.values()],
            "semantic": [self._serialize_memory(m) for m in self._semantic.values()],
        }
        
        with open(self._storage_path / "memories.json", "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)
    
    def _load_from_disk(self) -> None:
        """ä»ç£ç›˜åŠ è½½."""
        memory_file = self._storage_path / "memories.json"
        if not memory_file.exists():
            return
        
        with open(memory_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        for item in data.get("long_term", []):
            memory = self._deserialize_memory(item)
            self._long_term[memory.id] = memory
        
        for item in data.get("episodic", []):
            memory = self._deserialize_memory(item)
            self._episodic[memory.id] = memory
        
        for item in data.get("semantic", []):
            memory = self._deserialize_memory(item)
            self._semantic[memory.id] = memory
    
    def _serialize_memory(self, memory: MemoryItem) -> dict:
        """åºåˆ—åŒ–è®°å¿†é¡¹."""
        return {
            "id": memory.id,
            "content": memory.content,
            "memory_type": memory.memory_type,
            "source": memory.source,
            "tags": memory.tags,
            "importance": memory.importance,
            "created_at": memory.created_at.isoformat(),
            "access_count": memory.access_count,
            "related_memories": memory.related_memories,
        }
    
    def _deserialize_memory(self, data: dict) -> MemoryItem:
        """ååºåˆ—åŒ–è®°å¿†é¡¹."""
        return MemoryItem(
            id=data["id"],
            content=data["content"],
            memory_type=data["memory_type"],
            source=data.get("source", ""),
            tags=data.get("tags", []),
            importance=data.get("importance", 0.5),
            created_at=datetime.fromisoformat(data["created_at"]),
            access_count=data.get("access_count", 0),
            related_memories=data.get("related_memories", []),
        )
    
    def _generate_id(self, content: str) -> str:
        """ç”Ÿæˆè®°å¿†ID."""
        hash_input = f"{content}{datetime.now().isoformat()}"
        return hashlib.md5(hash_input.encode()).hexdigest()[:12]
    
    # =========================================================================
    # ç»Ÿè®¡ä¿¡æ¯
    # =========================================================================
    
    def get_stats(self) -> dict[str, Any]:
        """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯."""
        return {
            "short_term_count": len(self._short_term),
            "long_term_count": len(self._long_term),
            "episodic_count": len(self._episodic),
            "semantic_count": len(self._semantic),
            "total_count": (
                len(self._short_term) + 
                len(self._long_term) + 
                len(self._episodic) + 
                len(self._semantic)
            ),
        }
    1. åä½œæ¨¡å— (collaboration/debate.py) - ğŸ†• å…¨æ–°   """ä¸»å¸­çº§æ™ºèƒ½ä½“ - è¾©è®ºç³»ç»Ÿ.

å®ç°å¤šæ™ºèƒ½ä½“è¾©è®ºæœºåˆ¶ï¼Œç”¨äºï¼š
- æŠ€æœ¯æ–¹æ¡ˆè®¨è®º
- æ¶æ„å†³ç­–
- ä»£ç å®¡æŸ¥äº‰è®®è§£å†³
"""

from __future__ import annotations

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

from ..core.types import (
    AgentId,
    AgentMessage,
    DebateArgument,
    MessageType,
    TaskContext,
)

if TYPE_CHECKING:
    from ..agents.base import BaseAgent


logger = logging.getLogger(__name__)


@dataclass
class DebateTopic:
    """è¾©è®ºä¸»é¢˜."""
    
    id: str = ""
    title: str = ""
    description: str = ""
    
    # ç«‹åœº
    positions: list[str] = field(default_factory=list)  # e.g., ["æ–¹æ¡ˆA", "æ–¹æ¡ˆB"]
    
    # ä¸Šä¸‹æ–‡
    context: dict[str, Any] = field(default_factory=dict)
    constraints: list[str] = field(default_factory=list)
    
    # è¯„åˆ¤æ ‡å‡†
    evaluation_criteria: list[str] = field(default_factory=list)


@dataclass
class DebateRound:
    """è¾©è®ºå›åˆ."""
    
    round_number: int = 0
    arguments: list[DebateArgument] = field(default_factory=list)
    rebuttals: list[DebateArgument] = field(default_factory=list)
    
    # è¯„ä¼°
    round_summary: str = ""
    leading_position: str | None = None


@dataclass
class DebateResult:
    """è¾©è®ºç»“æœ."""
    
    topic_id: str = ""
    
    # å‚ä¸è€…
    participants: list[AgentId] = field(default_factory=list)
    moderator_id: AgentId | None = None
    
    # è¿‡ç¨‹
    rounds: list[DebateRound] = field(default_factory=list)
    total_arguments: int = 0
    
    # ç»“è®º
    winning_position: str | None = None
    consensus_reached: bool = False
    final_decision: str = ""
    decision_rationale: str = ""
    
    # æ—¶é—´
    started_at: datetime = field(default_factory=datetime.now)
    ended_at: datetime | None = None
    duration_seconds: float = 0.0
    
    # è´¨é‡
    debate_quality_score: float = 0.0
    argument_diversity: float = 0.0


class DebateSystem:
    """è¾©è®ºç³»ç»Ÿ - å¤šæ™ºèƒ½ä½“è¾©è®ºåè°ƒå™¨.
    
    åŠŸèƒ½ï¼š
    - ç»„ç»‡å¤šæ™ºèƒ½ä½“è¾©è®º
    - ç®¡ç†è¾©è®ºå›åˆ
    - è¯„ä¼°è®ºç‚¹è´¨é‡
    - è¾¾æˆæœ€ç»ˆå†³ç­–
    """
    
    def __init__(
        self,
        max_rounds: int = 5,
        min_arguments_per_round: int = 2,
    ) -> None:
        """åˆå§‹åŒ–è¾©è®ºç³»ç»Ÿ."""
        self._max_rounds = max_rounds
        self._min_arguments_per_round = min_arguments_per_round
        self._active_debates: dict[str, DebateResult] = {}
    
    async def start_debate(
        self,
        topic: DebateTopic,
        participants: list[BaseAgent],
        moderator: BaseAgent | None = None,
        context: TaskContext | None = None,
    ) -> DebateResult:
        """å¼€å§‹è¾©è®º.
        
        Args:
            topic: è¾©è®ºä¸»é¢˜
            participants: å‚ä¸çš„æ™ºèƒ½ä½“
            moderator: ä¸»æŒäººæ™ºèƒ½ä½“
            context: ä¸Šä¸‹æ–‡
            
        Returns:
            è¾©è®ºç»“æœ
        """
        logger.info(f"å¼€å§‹è¾©è®º: {topic.title}")
        
        result = DebateResult(
            topic_id=topic.id,
            participants=[p.profile.id for p in participants],
            moderator_id=moderator.profile.id if moderator else None,
        )
        self._active_debates[topic.id] = result
        
        # åˆ†é…ç«‹åœº
        position_assignments = self._assign_positions(participants, topic.positions)
        
        # è¿›è¡Œå¤šè½®è¾©è®º
        for round_num in range(1, self._max_rounds + 1):
            logger.info(f"è¾©è®ºç¬¬ {round_num} è½®")
            
            debate_round = await self._conduct_round(
                round_num=round_num,
                topic=topic,
                participants=participants,
                position_assignments=position_assignments,
                previous_rounds=result.rounds,
                context=context,
            )
            
            result.rounds.append(debate_round)
            result.total_arguments += len(debate_round.arguments)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†
            if await self._check_consensus(result, participants, topic):
                result.consensus_reached = True
                logger.info("è¾¾æˆå…±è¯†ï¼Œè¾©è®ºç»“æŸ")
                break
            
            # å¦‚æœæœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œå¯ä»¥æå‰ç»“æŸ
            if self._has_clear_winner(result):
                logger.info("å‡ºç°æ˜æ˜¾ä¼˜åŠ¿ï¼Œè¾©è®ºç»“æŸ")
                break
        
        # æœ€ç»ˆå†³ç­–
        result.winning_position, result.final_decision, result.decision_rationale = (
            await self._make_final_decision(topic, result, moderator, context)
        )
        
        result.ended_at = datetime.now()
        result.duration_seconds = (result.ended_at - result.started_at).total_seconds()
        result.debate_quality_score = self._evaluate_debate_quality(result)
        
        logger.info(f"è¾©è®ºç»“æŸï¼Œæœ€ç»ˆå†³ç­–: {result.final_decision}")
        
        return result
    
    def _assign_positions(
        self,
        participants: list[BaseAgent],
        positions: list[str],
    ) -> dict[AgentId, str]:
        """åˆ†é…è¾©è®ºç«‹åœº."""
        assignments = {}
        for i, participant in enumerate(participants):
            # å¾ªç¯åˆ†é…ç«‹åœº
            position = positions[i % len(positions)]
            assignments[participant.profile.id] = position
        return assignments
    
    async def _conduct_round(
        self,
        round_num: int,
        topic: DebateTopic,
        participants: list[BaseAgent],
        position_assignments: dict[AgentId, str],
        previous_rounds: list[DebateRound],
        context: TaskContext | None,
    ) -> DebateRound:
        """è¿›è¡Œä¸€è½®è¾©è®º."""
        debate_round = DebateRound(round_number=round_num)
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯
        round_context = self._build_round_context(topic, previous_rounds)
        
        # æ”¶é›†è®ºç‚¹ï¼ˆå¹¶è¡Œï¼‰
        argument_tasks = []
        for participant in participants:
            position = position_assignments[participant.profile.id]
            task = self._get_argument(
                participant, topic, position, round_context, context
            )
            argument_tasks.append(task)
        
        arguments = await asyncio.gather(*argument_tasks, return_exceptions=True)
        
        for arg in arguments:
            if isinstance(arg, DebateArgument):
                debate_round.arguments.append(arg)
        
        # æ”¶é›†åé©³ï¼ˆé’ˆå¯¹å¯¹æ–¹è®ºç‚¹ï¼‰
        if round_num > 1:
            rebuttal_tasks = []
            for participant in participants:
                position = position_assignments[participant.profile.id]
                opposing_args = [
                    a for a in debate_round.arguments 
                    if a.position != position
                ]
                if opposing_args:
                    task = self._get_rebuttal(
                        participant, topic, opposing_args[0], context
                    )
                    rebuttal_tasks.append(task)
            
            rebuttals = await asyncio.gather(*rebuttal_tasks, return_exceptions=True)
            
            for reb in rebuttals:
                if isinstance(reb, DebateArgument):
                    debate_round.rebuttals.append(reb)
        
        # è¯„ä¼°æœ¬è½®
        debate_round.round_summary = self._summarize_round(debate_round)
        debate_round.leading_position = self._evaluate_round_winner(debate_round)
        
        return debate_round
    
    async def _get_argument(
        self,
        agent: BaseAgent,
        topic: DebateTopic,
        position: str,
        round_context: str,
        context: TaskContext | None,
    ) -> DebateArgument:
        """è·å–æ™ºèƒ½ä½“çš„è®ºç‚¹."""
        prompt = f"""ä½ æ­£åœ¨å‚ä¸ä¸€åœºæŠ€æœ¯è¾©è®ºã€‚

è¾©è®ºä¸»é¢˜ï¼š{topic.title}
ä¸»é¢˜æè¿°ï¼š{topic.description}

ä½ çš„ç«‹åœºï¼š{position}

ä¹‹å‰çš„è¾©è®ºæƒ…å†µï¼š
{round_context}

è¯„åˆ¤æ ‡å‡†ï¼š
{chr(10).join(f'- {c}' for c in topic.evaluation_criteria)}

çº¦æŸæ¡ä»¶ï¼š
{chr(10).join(f'- {c}' for c in topic.constraints)}

è¯·æå‡ºä½ çš„è®ºç‚¹ï¼ŒåŒ…æ‹¬ï¼š
1. ä¸»è¦è®ºç‚¹
2. æ”¯æŒç†ç”±ï¼ˆè‡³å°‘3ç‚¹ï¼‰
3. è¯æ®æˆ–ç¤ºä¾‹
4. å¯¹å¯èƒ½åå¯¹æ„è§çš„é¢„é˜²

æ ¼å¼ï¼š
ä¸»è¦è®ºç‚¹ï¼š[ä½ çš„æ ¸å¿ƒè§‚ç‚¹]
æ”¯æŒç†ç”±ï¼š
- [ç†ç”±1]
- [ç†ç”±2]
- [ç†ç”±3]
è¯æ®ï¼š[å…·ä½“è¯æ®æˆ–ç¤ºä¾‹]
ç½®ä¿¡åº¦ï¼š[0.0-1.0]
"""
        
        # è°ƒç”¨æ™ºèƒ½ä½“æ€è€ƒ
        message = AgentMessage(
            type=MessageType.DEBATE_ARGUMENT,
            sender_id="system",
            receiver_id=agent.profile.id,
            subject=f"è¾©è®ºè®ºç‚¹è¯·æ±‚: {topic.title}",
            content=prompt,
        )
        
        response = await agent.collaborate(message)
        
        # è§£æå“åº”
        return self._parse_argument(
            agent.profile.id,
            position,
            response.content if response else "",
        )
    
    async def _get_rebuttal(
        self,
        agent: BaseAgent,
        topic: DebateTopic,
        opposing_argument: DebateArgument,
        context: TaskContext | None,
    ) -> DebateArgument:
        """è·å–åé©³."""
        prompt = f"""è¯·å¯¹ä»¥ä¸‹è®ºç‚¹è¿›è¡Œåé©³ï¼š

å¯¹æ–¹ç«‹åœºï¼š{opposing_argument.position}
å¯¹æ–¹è®ºç‚¹ï¼š{opposing_argument.main_argument}
å¯¹æ–¹ç†ç”±ï¼š
{chr(10).join(f'- {p}' for p in opposing_argument.supporting_points)}

è¯·æå‡ºæœ‰åŠ›çš„åé©³ï¼ŒæŒ‡å‡ºå¯¹æ–¹è®ºç‚¹çš„ï¼š
1. é€»è¾‘æ¼æ´
2. é—æ¼çš„è€ƒè™‘å› ç´ 
3. å¯èƒ½çš„é£é™©æˆ–é—®é¢˜

æ ¼å¼ï¼š
åé©³è¦ç‚¹ï¼š[æ ¸å¿ƒåé©³]
æ¼æ´åˆ†æï¼š[æŒ‡å‡ºçš„é—®é¢˜]
è¡¥å……è®ºæ®ï¼š[æ”¯æŒä½ åé©³çš„è¯æ®]
"""
        
        message = AgentMessage(
            type=MessageType.DEBATE_REBUTTAL,
            sender_id="system",
            receiver_id=agent.profile.id,
            content=prompt,
        )
        
        response = await agent.collaborate(message)
        
        return DebateArgument(
            agent_id=agent.profile.id,
            position=agent.profile.id,  # åé©³æ—¶è®°å½•åé©³è€…
            main_argument=response.content if response else "",
            rebuttals=[opposing_argument.main_argument],
        )
    
    async def _check_consensus(
        self,
        result: DebateResult,
        participants: list[BaseAgent],
        topic: DebateTopic,
    ) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†."""
        if len(result.rounds) < 2:
            return False
        
        # æ£€æŸ¥æœ€è¿‘ä¸¤è½®æ˜¯å¦å€¾å‘ä¸€è‡´
        recent_winners = [r.leading_position for r in result.rounds[-2:]]
        if recent_winners[0] == recent_winners[1] and recent_winners[0] is not None:
            # æ£€æŸ¥è®ºç‚¹å¼ºåº¦å·®å¼‚
            last_round = result.rounds[-1]
            if last_round.arguments:
                confidences = [a.confidence for a in last_round.arguments]
                if max(confidences) - min(confidences) > 0.3:
                    return True
        
        return False
    
    def _has_clear_winner(self, result: DebateResult) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾èµ¢å®¶."""
        if len(result.rounds) < 3:
            return False
        
        # ç»Ÿè®¡å„ç«‹åœºè·èƒœè½®æ¬¡
        position_wins: dict[str, int] = {}
        for round in result.rounds:
            if round.leading_position:
                position_wins[round.leading_position] = (
                    position_wins.get(round.leading_position, 0) + 1
                )
        
        if not position_wins:
            return False
        
        max_wins = max(position_wins.values())
        total_rounds = len(result.rounds)
        
        # å¦‚æœæŸæ–¹èµ¢å¾—è¶…è¿‡70%çš„è½®æ¬¡
        return max_wins / total_rounds > 0.7
    
    async def _make_final_decision(
        self,
        topic: DebateTopic,
        result: DebateResult,
        moderator: BaseAgent | None,
        context: TaskContext | None,
    ) -> tuple[str, str, str]:
        """åšå‡ºæœ€ç»ˆå†³ç­–."""
        # ç»Ÿè®¡å„ç«‹åœºè¡¨ç°
        position_scores: dict[str, float] = {}
        for round in result.rounds:
            for arg in round.arguments:
                position_scores[arg.position] = (
                    position_scores.get(arg.position, 0) + arg.confidence
                )
        
        # ç¡®å®šè·èƒœç«‹åœº
        if position_scores:
            winning_position = max(position_scores, key=position_scores.get)
        else:
            winning_position = topic.positions[0] if topic.positions else "æœªç¡®å®š"
        
        # ç”Ÿæˆå†³ç­–è¯´æ˜
        decision = f"é‡‡ç”¨{winning_position}æ–¹æ¡ˆ"
        rationale = self._generate_rationale(result, winning_position)
        
        return winning_position, decision, rationale
    
    def _generate_rationale(self, result: DebateResult, winning_position: str) -> str:
        """ç”Ÿæˆå†³ç­–ç†ç”±."""
        reasons = []
        
        for round in result.rounds:
            for arg in round.arguments:
                if arg.position == winning_position:
                    reasons.extend(arg.supporting_points[:2])
        
        return f"åŸºäºä»¥ä¸‹ç†ç”±ï¼š\n" + "\n".join(f"- {r}" for r in reasons[:5])
    
    def _build_round_context(
        self,
        topic: DebateTopic,
        previous_rounds: list[DebateRound],
    ) -> str:
        """æ„å»ºå›åˆä¸Šä¸‹æ–‡."""
        if not previous_rounds:
            return "è¿™æ˜¯ç¬¬ä¸€è½®è¾©è®ºã€‚"
        
        context_parts = []
        for round in previous_rounds[-2:]:  # åªæ˜¾ç¤ºæœ€è¿‘ä¸¤è½®
            context_parts.append(f"ç¬¬{round.round_number}è½®:")
            for arg in round.arguments:
            context_parts.append(f"  [{arg.position}] {arg.main_argument[:100]}...")
            if round.leading_position:
                context_parts.append(f"  æœ¬è½®é¢†å…ˆ: {round.leading_position}")
        
        return "\n".join(context_parts)
    
    def _summarize_round(self, debate_round: DebateRound) -> str:
        """æ€»ç»“å›åˆ."""
        summary_parts = [f"ç¬¬{debate_round.round_number}è½®è¾©è®ºæ€»ç»“:"]
        summary_parts.append(f"- å…±{len(debate_round.arguments)}ä¸ªè®ºç‚¹")
        summary_parts.append(f"- å…±{len(debate_round.rebuttals)}ä¸ªåé©³")
        return "\n".join(summary_parts)
    
    def _evaluate_round_winner(self, debate_round: DebateRound) -> str | None:
        """è¯„ä¼°å›åˆèƒœè€…."""
        if not debate_round.arguments:
            return None
        
        position_scores: dict[str, float] = {}
        for arg in debate_round.arguments:
            score = arg.confidence * arg.strength if arg.strength else arg.confidence
            position_scores[arg.position] = (
                position_scores.get(arg.position, 0) + score
            )
        
        if position_scores:
            return max(position_scores, key=position_scores.get)
        return None
    
    def _evaluate_debate_quality(self, result: DebateResult) -> float:
        """è¯„ä¼°è¾©è®ºè´¨é‡."""
        if not result.rounds:
            return 0.0
        
        # è¯„ä¼°å› ç´ ï¼š
        # 1. è®ºç‚¹æ•°é‡
        # 2. è®ºç‚¹å¹³å‡è´¨é‡
        # 3. åé©³æ·±åº¦
        # 4. æ˜¯å¦è¾¾æˆå…±è¯†
        
        arg_count_score = min(result.total_arguments / 10, 1.0)
        
        avg_confidence = 0.0
        total_args = 0
        for round in result.rounds:
            for arg in round.arguments:
                avg_confidence += arg.confidence
                total_args += 1
        
        if total_args > 0:
            avg_confidence /= total_args
        
        consensus_bonus = 0.2 if result.consensus_reached else 0.0
        
        return (arg_count_score * 0.3 + avg_confidence * 0.5 + consensus_bonus) * 10
    
    def _parse_argument(
        self,
        agent_id: AgentId,
        position: str,
        response: str,
    ) -> DebateArgument:
        """è§£æè®ºç‚¹å“åº”."""
        argument = DebateArgument(
            agent_id=agent_id,
            position=position,
        )
        
        lines = response.strip().split("\n")
        current_section = ""
        
        for line in lines:
            line = line.strip()
            if line.startswith("ä¸»è¦è®ºç‚¹"):
                argument.main_argument = line.split("ï¼š", 1)[-1].strip()
                current_section = "main"
            elif line.startswith("æ”¯æŒç†ç”±"):
                current_section = "supporting"
            elif line.startswith("è¯æ®"):
                current_section = "evidence"
                evidence = line.split("ï¼š", 1)[-1].strip()
                if evidence:
                    argument.evidence.append(evidence)
            elif line.startswith("ç½®ä¿¡åº¦"):
                try:
                    argument.confidence = float(line.split("ï¼š", 1)[-1].strip())
                except ValueError:
                    argument.confidence = 0.7
            elif line.startswith("- ") and current_section == "supporting":
                argument.supporting_points.append(line[2:].strip())
        
        # è®¡ç®—è®ºç‚¹å¼ºåº¦
        argument.strength = len(argument.supporting_points) * 0.2 + len(argument.evidence) * 0.3
        argument.strength = min(argument.strength, 1.0)
        
        return argument
    1. å…±è¯†æœºåˆ¶ (collaboration/consensus.py) - ğŸ†• å…¨æ–°   """ä¸»å¸­çº§æ™ºèƒ½ä½“ - å…±è¯†æœºåˆ¶.

å®ç°å¤šæ™ºèƒ½ä½“å…±è¯†è¾¾æˆï¼š
- æŠ•ç¥¨æœºåˆ¶
- åŠ æƒå…±è¯†
- è¿­ä»£åå•†
"""

from __future__ import annotations

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

from ..core.types import (
    AgentId,
    AgentMessage,
    MessageType,
    TaskContext,
    Vote,
)

if TYPE_CHECKING:
    from ..agents.base import BaseAgent


logger = logging.getLogger(__name__)


@dataclass
class Proposal:
    """ææ¡ˆ."""
    
    id: str = ""
    title: str = ""
    description: str = ""
    proposer_id: AgentId = ""
    
    # é€‰é¡¹
    options: list[str] = field(default_factory=list)
    
    # ä¸Šä¸‹æ–‡
    context: dict[str, Any] = field(default_factory=dict)
    pros: list[str] = field(default_factory=list)
    cons: list[str] = field(default_factory=list)
    
    # æ—¶é—´
    created_at: datetime = field(default_factory=datetime.now)
    deadline: datetime | None = None


@dataclass
class ConsensusResult:
    """å…±è¯†ç»“æœ."""
    
    proposal_id: str = ""
    
    # å‚ä¸è€…
    participants: list[AgentId] = field(default_factory=list)
    
    # æŠ•ç¥¨
    votes: list[Vote] = field(default_factory=list)
    vote_distribution: dict[str, int] = field(default_factory=dict)
    
    # ç»“æœ
    consensus_reached: bool = False
    winning_option: str | None = None
    approval_rate: float = 0.0
    
    # è¯¦æƒ…
    rounds_needed: int = 0
    negotiation_history: list[str] = field(default_factory=list)
    
    # æ—¶é—´
    started_at: datetime = field(default_factory=datetime.now)
    ended_at: datetime | None = None


class ConsensusEngine:
    """å…±è¯†å¼•æ“ - å¤šæ™ºèƒ½ä½“å†³ç­–åè°ƒå™¨.
    
    æ”¯æŒå¤šç§å…±è¯†æœºåˆ¶ï¼š
    - ç®€å•å¤šæ•°æŠ•ç¥¨
    - åŠ æƒæŠ•ç¥¨
    - è¿­ä»£åå•†
    - ä¸€è‡´åŒæ„
    """
    
    def __init__(
        self,
        default_threshold: float = 0.6,
        max_negotiation_rounds: int = 3,
    ) -> None:
        """åˆå§‹åŒ–å…±è¯†å¼•æ“."""
        self._default_threshold = default_threshold
        self._max_negotiation_rounds = max_negotiation_rounds
    
    async def reach_consensus(
        self,
        proposal: Proposal,
        participants: list[BaseAgent],
        mechanism: str = "majority",
        threshold: float | None = None,
        weights: dict[AgentId, float] | None = None,
        context: TaskContext | None = None,
    ) -> ConsensusResult:
        """è¾¾æˆå…±è¯†.
        
        Args:
            proposal: ææ¡ˆ
            participants: å‚ä¸æŠ•ç¥¨çš„æ™ºèƒ½ä½“
            mechanism: å…±è¯†æœºåˆ¶ (majority, weighted, unanimous, iterative)
            threshold: é€šè¿‡é˜ˆå€¼
            weights: æŠ•ç¥¨æƒé‡
            context: ä¸Šä¸‹æ–‡
            
        Returns:
            å…±è¯†ç»“æœ
        """
        threshold = threshold or self._default_threshold
        
        logger.info(f"å¼€å§‹å…±è¯†è¿‡ç¨‹: {proposal.title}, æœºåˆ¶: {mechanism}")
        
        result = ConsensusResult(
            proposal_id=proposal.id,
            participants=[p.profile.id for p in participants],
        )
        
        if mechanism == "majority":
            return await self._majority_vote(
                proposal, participants, threshold, result, context
            )
        elif mechanism == "weighted":
            return await self._weighted_vote(
                proposal, participants, threshold, weights or {}, result, context
            )
        elif mechanism == "unanimous":
            return await self._unanimous_vote(
                proposal, participants, result, context
            )
        elif mechanism == "iterative":
            return await self._iterative_negotiation(
                proposal, participants, threshold, result, context
            )
        else:
            return await self._majority_vote(
                proposal, participants, threshold, result, context
            )
    
    async def _majority_vote(
        self,
        proposal: Proposal,
        participants: list[BaseAgent],
        threshold: float,
        result: ConsensusResult,
        context: TaskContext | None,
    ) -> ConsensusResult:
        """ç®€å•å¤šæ•°æŠ•ç¥¨."""
        result.rounds_needed = 1
        
        # æ”¶é›†æŠ•ç¥¨
        votes = await self._collect_votes(proposal, participants, context)
        result.votes = votes
        
        # ç»Ÿè®¡
        result.vote_distribution = self._count_votes(votes, proposal.options)
        
        # åˆ¤æ–­ç»“æœ
        total_votes = len(votes)
        if total_votes > 0:
            max_option = max(result.vote_distribution, key=result.vote_distribution.get)
            max_count = result.vote_distribution[max_option]
            result.approval_rate = max_count / total_votes
            
            if result.approval_rate >= threshold:
                result.consensus_reached = True
                result.winning_option = max_option
        
        result.ended_at = datetime.now()
        return result
    
    async def _weighted_vote(
        self,
        proposal: Proposal,
        participants: list[BaseAgent],
        threshold: float,
        weights: dict[AgentId, float],
        result: ConsensusResult,
        context: TaskContext | None,
    ) -> ConsensusResult:
        """åŠ æƒæŠ•ç¥¨."""
        result.rounds_needed = 1
        
        # æ”¶é›†æŠ•ç¥¨
        votes = await self._collect_votes(proposal, participants, context)
        result.votes = votes
        
        # ä¸ºæ¯ä¸ªæŠ•ç¥¨åº”ç”¨æƒé‡
        for vote in votes:
            vote.weight = weights.get(vote.agent_id, 1.0)
        
        # åŠ æƒç»Ÿè®¡
        weighted_counts: dict[str, float] = {opt: 0.0 for opt in proposal.options}
        total_weight = 0.0
        
        for vote in votes:
            if vote.vote in weighted_counts:
                weighted_counts[vote.vote] += vote.weight
            total_weight += vote.weight
        
        # åˆ¤æ–­ç»“æœ
        if total_weight > 0:
            max_option = max(weighted_counts, key=weighted_counts.get)
            result.approval_rate = weighted_counts[max_option] / total_weight
            
            if result.approval_rate >= threshold:
                result.consensus_reached = True
                result.winning_option = max_option
        
        result.ended_at = datetime.now()
        return result
    
    async def _unanimous_vote(
        self,
        proposal: Proposal,
        participants: list[BaseAgent],
        result: ConsensusResult,
        context: TaskContext | None,
    ) -> ConsensusResult:
        """ä¸€è‡´åŒæ„æŠ•ç¥¨."""
        result.rounds_needed = 1
        
        votes = await self._collect_votes(proposal, participants, context)
        result.votes = votes
        result.vote_distribution = self._count_votes(votes, proposal.options)
        
        # æ£€æŸ¥æ˜¯å¦ä¸€è‡´
        approve_count = result.vote_distribution.get("approve", 0)
        
        if approve_count == len(participants):
            result.consensus_reached = True
            result.winning_option = "approve"
            result.approval_rate = 1.0
        else:
            result.approval_rate = approve_count / len(participants) if participants else 0
        
        result.ended_at = datetime.now()
        return result
    
    async def _iterative_negotiation(
        self,
        proposal: Proposal,
        participants: list[BaseAgent],
        threshold: float,
        result: ConsensusResult,
        context: TaskContext | None,
    ) -> ConsensusResult:
        """è¿­ä»£åå•†."""
        current_proposal = proposal
        
        for round_num in range(1, self._max_negotiation_rounds + 1):
            result.rounds_needed = round_num
            logger.info(f"åå•†ç¬¬ {round_num} è½®")
            
            # æ”¶é›†æŠ•ç¥¨å’Œåé¦ˆ
            votes = await self._collect_votes_with_feedback(
                current_proposal, participants, context
            )
            result.votes = votes
            result.vote_distribution = self._count_votes(votes, current_proposal.options)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†
            total = len(votes)
            if total > 0:
                max_option = max(result.vote_distribution, key=result.vote_distribution.get)
                max_count = result.vote_distribution[max_option]
                result.approval_rate = max_count / total
                
                if result.approval_rate >= threshold:
                    result.consensus_reached = True
                    result.winning_option = max_option
                    break
            
            # æ”¶é›†åå¯¹æ„è§ï¼Œä¿®æ”¹ææ¡ˆ
            objections = [v for v in votes if v.vote == "reject"]
            if objections:
                modification = await self._negotiate_modification(
                    current_proposal, objections, participants, context
                )
                result.negotiation_history.append(
                    f"ç¬¬{round_num}è½®ä¿®æ”¹: {modification}"
                )
                
                # æ›´æ–°ææ¡ˆ
                current_proposal.description += f"\n\nä¿®æ”¹({round_num}): {modification}"
        
        result.ended_at = datetime.now()
        return result
    
    async def _collect_votes(
        self,
        proposal: Proposal,
        participants: list[BaseAgent],
        context: TaskContext | None,
    ) -> list[Vote]:
        """æ”¶é›†æŠ•ç¥¨."""
        vote_tasks = [
            self._get_vote(participant, proposal, context)
            for participant in participants
        ]
        
        votes = await asyncio.gather(*vote_tasks, return_exceptions=True)
        
        return [v for v in votes if isinstance(v, Vote)]
    
    async def _collect_votes_with_feedback(
        self,
        proposal: Proposal,
        participants: list[BaseAgent],
        context: TaskContext | None,
    ) -> list[Vote]:
        """æ”¶é›†å¸¦åé¦ˆçš„æŠ•ç¥¨."""
        vote_tasks = [
            self._get_vote_with_feedback(participant, proposal, context)
            for participant in participants
        ]
        
        votes = await asyncio.gather(*vote_tasks, return_exceptions=True)
        
        return [v for v in votes if isinstance(v, Vote)]
    
    async def _get_vote(
        self,
        agent: BaseAgent,
        proposal: Proposal,
        context: TaskContext | None,
    ) -> Vote:
        """è·å–æ™ºèƒ½ä½“æŠ•ç¥¨."""
        options_str = "\n".join(f"- {opt}" for opt in proposal.options)
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹ææ¡ˆè¿›è¡ŒæŠ•ç¥¨ï¼š

ææ¡ˆæ ‡é¢˜ï¼š{proposal.title}
ææ¡ˆæè¿°ï¼š{proposal.description}

å¯é€‰é€‰é¡¹ï¼š
{options_str}

ä¼˜ç‚¹ï¼š
{chr(10).join(f'- {p}' for p in proposal.pros)}

ç¼ºç‚¹ï¼š
{chr(10).join(f'- {c}' for c in proposal.cons)}

è¯·é€‰æ‹©ä¸€ä¸ªé€‰é¡¹å¹¶è¯´æ˜ç†ç”±ã€‚
æ ¼å¼ï¼š
é€‰æ‹©ï¼š[é€‰é¡¹åç§°]
ç†ç”±ï¼š[ä½ çš„ç†ç”±]
"""
        
        message = AgentMessage(
            type=MessageType.CONSENSUS_VOTE,
            sender_id="system",
            receiver_id=agent.profile.id,
            content=prompt,
        )
        
        response = await agent.collaborate(message)
        
        return self._parse_vote(agent.profile.id, proposal.id, response)
    
    async def _get_vote_with_feedback(
        self,
        agent: BaseAgent,
        proposal: Proposal,
        context: TaskContext | None,
    ) -> Vote:
        """è·å–å¸¦åé¦ˆçš„æŠ•ç¥¨."""
        vote = await self._get_vote(agent, proposal, context)
        
        # å¦‚æœåå¯¹ï¼Œè¯·æ±‚å…·ä½“çš„ä¿®æ”¹å»ºè®®
        if vote.vote == "reject":
            feedback_prompt = f"""ä½ å¯¹ææ¡ˆ "{proposal.title}" æŠ•äº†åå¯¹ç¥¨ã€‚
ç†ç”±ï¼š{vote.rationale}

è¯·æä¾›å…·ä½“çš„ä¿®æ”¹å»ºè®®ï¼Œè¯´æ˜å¦‚ä½•æ”¹è¿›è¿™ä¸ªææ¡ˆå¯ä»¥è®©ä½ åŒæ„ï¼š
"""
            
            message = AgentMessage(
                type=MessageType.CONSENSUS_VOTE,
                sender_id="system",
                receiver_id=agent.profile.id,
                content=feedback_prompt,
            )
            
            response = await agent.collaborate(message)
            if response:
                vote.conditions = [response.content]
        
        return vote
    
    async def _negotiate_modification(
        self,
        proposal: Proposal,
        objections: list[Vote],
        participants: list[BaseAgent],
        context: TaskContext | None,
    ) -> str:
        """åå•†ä¿®æ”¹."""
        # æ”¶é›†æ‰€æœ‰åå¯¹æ„è§
        all_conditions = []
        for vote in objections:
            all_conditions.extend(vote.conditions)
        
        if not all_conditions:
            return "æ— æ³•è·å–å…·ä½“ä¿®æ”¹å»ºè®®"
        
        # æ‰¾åˆ°ææ¡ˆäººæˆ–éšæœºé€‰æ‹©ä¸€ä¸ªæ”¯æŒè€…æ¥ä¿®æ”¹ææ¡ˆ
        modifier = participants[0]  # ç®€åŒ–ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªå‚ä¸è€…
        
        modify_prompt = f"""ä»¥ä¸‹æ˜¯å¯¹ææ¡ˆ "{proposal.title}" çš„åå¯¹æ„è§å’Œä¿®æ”¹å»ºè®®ï¼š

{chr(10).join(f'- {c}' for c in all_conditions)}

è¯·æ ¹æ®è¿™äº›åé¦ˆï¼Œæå‡ºä¸€ä¸ªæŠ˜ä¸­çš„ä¿®æ”¹æ–¹æ¡ˆï¼Œå°½é‡æ»¡è¶³å„æ–¹éœ€æ±‚ï¼š
"""
        
        message = AgentMessage(
            type=MessageType.CONSENSUS_PROPOSAL,
            sender_id="system",
            receiver_id=modifier.profile.id,
            content=modify_prompt,
        )
        
        response = await modifier.collaborate(message)
        
        return response.content if response else "æ— æ³•ç”Ÿæˆä¿®æ”¹æ–¹æ¡ˆ"
    
    def _count_votes(
        self,
        votes: list[Vote],
        options: list[str],
    ) -> dict[str, int]:
        """ç»Ÿè®¡æŠ•ç¥¨."""
        counts = {opt: 0 for opt in options}
        
        for vote in votes:
            if vote.vote in counts:
                counts[vote.vote] += 1
            elif vote.vote == "approve" and "approve" not in counts:
                counts["approve"] = counts.get("approve", 0) + 1
            elif vote.vote == "reject" and "reject" not in counts:
                counts["reject"] = counts.get("reject", 0) + 1
        
        return counts
    
    def _parse_vote(
        self,
        agent_id: AgentId,
        proposal_id: str,
        response: AgentMessage | None,
    ) -> Vote:
        """è§£ææŠ•ç¥¨å“åº”."""
        vote = Vote(
            agent_id=agent_id,
            proposal_id=proposal_id,
        )
        
        if not response:
            vote.vote = "abstain"
            return vote
        
        content = response.content
        lines = content.strip().split("\n")
        
        for line in lines:
            line = line.strip()
            if line.startswith("é€‰æ‹©") or line.startswith("æŠ•ç¥¨"):
                vote.vote = line.split("ï¼š", 1)[-1].strip().lower()
            elif line.startswith("ç†ç”±"):
                vote.rationale = line.split("ï¼š", 1)[-1].strip()
        
        if not vote.vote:
            # å°è¯•ä»å†…å®¹æ¨æ–­
            if "åŒæ„" in content or "approve" in content.lower() or "èµæˆ" in content:
                vote.vote = "approve"
            elif "åå¯¹" in content or "reject" in content.lower() or "å¦å†³" in content:
                vote.vote = "reject"
            else:
                vote.vote = "abstain"
        
        return vote
    1. åŸºç¡€æ™ºèƒ½ä½“å‡çº§ (agents/base.py)   """ä¸»å¸­çº§æ™ºèƒ½ä½“ - åŸºç¡€æ™ºèƒ½ä½“å®ç°.

å‡çº§å†…å®¹ï¼š
- é›†æˆè®¤çŸ¥èƒ½åŠ›ï¼ˆæ¨ç†ã€åæ€ã€è§„åˆ’ï¼‰
- é›†æˆè®°å¿†ç³»ç»Ÿ
- é›†æˆåä½œèƒ½åŠ›
- é›†æˆå·¥å…·ä½¿ç”¨
"""

from __future__ import annotations

import asyncio
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

from ..core.types import (
    AgentId,
    AgentMessage,
    AgentProfile,
    AgentState,
    Artifact,
    ArtifactType,
    DebateArgument,
    MessageType,
    ReasoningStep,
    ReviewComment,
    ReviewResult,
    Task,
    TaskContext,
    TaskResult,
    TaskStatus,
    ToolType,
    Vote,
)

if TYPE_CHECKING:
    from ..cognitive.memory import MemorySystem
    from ..cognitive.reasoning import ReasoningEngine
    from ..integration.llm import LLMClient
    from ..tools.executor import ToolExecutor


logger = logging.getLogger(__name__)


class BaseAgent(ABC):
    """åŸºç¡€æ™ºèƒ½ä½“ - ä¸»å¸­çº§å‡çº§ç‰ˆ.
    
    æ ¸å¿ƒèƒ½åŠ›ï¼š
    - æ·±åº¦æ¨ç†ï¼šæ€ç»´é“¾ã€æ€ç»´æ ‘ã€è‡ªæˆ‘åæ€
    - è®°å¿†ç³»ç»Ÿï¼šçŸ­æœŸã€é•¿æœŸã€æƒ…æ™¯ã€è¯­ä¹‰è®°å¿†
    - åä½œèƒ½åŠ›ï¼šè¾©è®ºã€æŠ•ç¥¨ã€ç»“å¯¹ç¼–ç¨‹
    - å·¥å…·ä½¿ç”¨ï¼šä»£ç æ‰§è¡Œã€æ–‡ä»¶æ“ä½œã€Gitç­‰
    
    Attributes:
        profile: æ™ºèƒ½ä½“é…ç½®
        state: å½“å‰çŠ¶æ€
        reasoning: æ¨ç†å¼•æ“
        memory: è®°å¿†ç³»ç»Ÿ
        tools: å·¥å…·æ‰§è¡Œå™¨
    """
    
    def __init__(
        self,
        profile: AgentProfile,
        llm_client: LLMClient,
        reasoning_engine: ReasoningEngine | None = None,
        memory_system: MemorySystem | None = None,
        tool_executor: ToolExecutor | None = None,
    ) -> None:
        """åˆå§‹åŒ–æ™ºèƒ½ä½“."""
        self._profile = profile
        self._llm = llm_client
        self._reasoning = reasoning_engine
        self._memory = memory_system
        self._tools = tool_executor
        
        # çŠ¶æ€
        self._state = AgentState(agent_id=profile.id)
        self._current_task: Task | None = None
        
        # ä¼šè¯å†å²
        self._conversation_history: list[dict[str, str]] = []
    
    # =========================================================================
    # å±æ€§
    # =========================================================================
    
    @property
    def profile(self) -> AgentProfile:
        """è·å–é…ç½®."""
        return self._profile
    
    @property
    def id(self) -> AgentId:
        """è·å–ID."""
        return self._profile.id
    
    @property
    def name(self) -> str:
        """è·å–åç§°."""
        return self._profile.name
    
    @property
    def state(self) -> AgentState:
        """è·å–çŠ¶æ€."""
        return self._state
    
    # =========================================================================
    # æ ¸å¿ƒæ–¹æ³•
    # =========================================================================
    
    async def execute(
        self,
        task: Task,
        context: TaskContext,
    ) -> TaskResult:
        """æ‰§è¡Œä»»åŠ¡ - ä¸»å¸­çº§å¢å¼ºç‰ˆ.
        
        æ‰§è¡Œæµç¨‹ï¼š
        1. ç†è§£ä»»åŠ¡ï¼ˆæ¨ç†åˆ†æï¼‰
        2. å›å¿†ç›¸å…³ç»éªŒï¼ˆè®°å¿†æ£€ç´¢ï¼‰
        3. åˆ¶å®šè®¡åˆ’ï¼ˆè§„åˆ’ï¼‰
        4. æ‰§è¡Œä»»åŠ¡ï¼ˆå¯èƒ½ä½¿ç”¨å·¥å…·ï¼‰
        5. è‡ªæˆ‘æ£€æŸ¥ï¼ˆåæ€ï¼‰
        6. å­¦ä¹ æ€»ç»“ï¼ˆè®°å¿†å­˜å‚¨ï¼‰
        
        Args:
            task: è¦æ‰§è¡Œçš„ä»»åŠ¡
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        self._current_task = task
        self._state.status = "working"
        self._state.current_task_id = task.id
        start_time = datetime.now()
        
        logger.info(
            f"[{self.name}] å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.title}",
            extra={"task_id": task.id, "agent_id": self.id},
        )
        
        try:
            # 1. æ·±åº¦ç†è§£ä»»åŠ¡
            understanding = await self._understand_task(task, context)
            
            # 2. å›å¿†ç›¸å…³ç»éªŒ
            relevant_memories = await self._recall_relevant_memories(task, context)
            
            # 3. åˆ¶å®šæ‰§è¡Œè®¡åˆ’
            plan = await self._plan_execution(task, context, understanding, relevant_memories)
            
            # 4. æ‰§è¡Œè®¡åˆ’
            result = await self._execute_plan(task, context, plan)
            
            # 5. è‡ªæˆ‘æ£€æŸ¥å’Œåæ€
            if self._profile.reflection_enabled:
                result = await self._reflect_and_improve(task, context, result)
            
            # 6. å­¦ä¹ æ€»ç»“
            await self._learn_from_execution(task, result)
            
            # æ›´æ–°ç»Ÿè®¡
            self._state.tasks_completed += 1
            
            return result
            
        except Exception as e:
            logger.exception(f"[{self.name}] ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            self._state.tasks_failed += 1
            
            return TaskResult(
                task_id=task.id,
                success=False,
                error_message=str(e),
                error_type=type(e).__name__,
                execution_time_seconds=(datetime.now() - start_time).total_seconds(),
            )
        
        finally:
            self._state.status = "idle"
            self._state.current_task_id = None
            self._current_task = None
    
    async def _understand_task(
        self,
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """æ·±åº¦ç†è§£ä»»åŠ¡."""
        if self._reasoning:
            # ä½¿ç”¨æ¨ç†å¼•æ“æ·±åº¦åˆ†æ
            result = await self._reasoning.reason(
                problem=f"åˆ†æä»»åŠ¡ï¼š{task.title}\næè¿°ï¼š{task.description}",
                context=context,
                strategy="chain_of_thought",
            )
            return {
                "analysis": result.conclusion,
                "key_points": [s.thought for s in result.steps],
                "confidence": result.confidence,
            }
        
        # ç®€å•ç†è§£
        return {
            "analysis": task.description,
            "key_points": [],
            "confidence": 0.7,
        }
    
    async def _recall_relevant_memories(
        self,
        task: Task,
        context: TaskContext,
    ) -> list[str]:
        """å›å¿†ç›¸å…³ç»éªŒ."""
        if not self._memory:
            return []
        
        # æœç´¢ç›¸å…³è®°å¿†
        results = self._memory.recall(
            query=f"{task.title} {task.description}",
            memory_types=["episodic", "semantic"],
            limit=5,
        )
        
        return [r.memory.content for r in results]
    
    async def _plan_execution(
        self,
        task: Task,
        context: TaskContext,
        understanding: dict[str, Any],
        memories: list[str],
    ) -> list[dict[str, Any]]:
        """åˆ¶å®šæ‰§è¡Œè®¡åˆ’."""
        prompt = self._build_planning_prompt(task, context, understanding, memories)
        
        response = await self._call_llm(prompt)
        
        # è§£æè®¡åˆ’
        return self._parse_plan(response)
    
    async def _execute_plan(
        self,
        task: Task,
        context: TaskContext,
        plan: list[dict[str, Any]],
    ) -> TaskResult:
        """æ‰§è¡Œè®¡åˆ’."""
        artifacts: list[Artifact] = []
        reasoning_trace: list[ReasoningStep] = []
        tools_used: list[ToolType] = []
        
        for step_num, step in enumerate(plan, 1):
            logger.debug(f"[{self.name}] æ‰§è¡Œæ­¥éª¤ {step_num}: {step.get('action', 'unknown')}")
            
            # è®°å½•æ¨ç†æ­¥éª¤
            reasoning_trace.append(ReasoningStep(
                step_number=step_num,
                thought=step.get("thought", ""),
                action=step.get("action", ""),
            ))
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
            if step.get("tool") and self._tools:
                tool_type = ToolType(step["tool"])
                if self._profile.can_use_tool(tool_type):
                    tool_result = await self._tools.execute(
                        tool_type=tool_type,
                        action=step.get("tool_action", ""),
                        params=step.get("tool_params", {}),
                    )
                    tools_used.append(tool_type)
                    step["tool_result"] = tool_result
            
            # æ‰§è¡Œæ­¥éª¤æ ¸å¿ƒé€»è¾‘
            step_result = await self._execute_step(step, task, context)
            
            # æ”¶é›†äº§å‡ºç‰©
            if step_result.get("artifact"):
                artifacts.append(step_result["artifact"])
        
        # ç”Ÿæˆæœ€ç»ˆè¾“å‡º
        final_output = await self._generate_final_output(task, context, plan, artifacts)
        
        if final_output:
            artifacts.append(final_output)
        
        return TaskResult(
            task_id=task.id,
            success=True,
            artifacts=artifacts,
            reasoning_trace=reasoning_trace,
            tools_used=tools_used,
            confidence_score=self._calculate_confidence(artifacts),
            quality_score=self._calculate_quality(artifacts),
        )
    
    @abstractmethod
    async def _execute_step(
        self,
        step: dict[str, Any],
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤ - å­ç±»å®ç°."""
        pass
    
    @abstractmethod
    async def _generate_final_output(
        self,
        task: Task,
        context: TaskContext,
        plan: list[dict[str, Any]],
        intermediate_artifacts: list[Artifact],
    ) -> Artifact | None:
        """ç”Ÿæˆæœ€ç»ˆè¾“å‡º - å­ç±»å®ç°."""
        pass **async def _reflect_and_improve(
        self,
        task: Task,
        context: TaskContext,
        result: TaskResult,
    ) -> TaskResult:
        """åæ€å¹¶æ”¹è¿›ç»“æœ."""
        if not result.success or not result.artifacts:
            return result
        
        reflection_prompt = f"""è¯·å¯¹ä»¥ä¸‹ä»»åŠ¡æ‰§è¡Œç»“æœè¿›è¡Œè‡ªæˆ‘åæ€ï¼š

ä»»åŠ¡ï¼š{task.title}
äº§å‡ºç‰©æ•°é‡ï¼š{len(result.artifacts)}

è¯·è¯„ä¼°ï¼š
1. æ˜¯å¦å®Œæ•´è§£å†³äº†é—®é¢˜ï¼Ÿ
2. ä»£ç /æ–‡æ¡£è´¨é‡å¦‚ä½•ï¼Ÿ
3. æœ‰ä»€ä¹ˆå¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Ÿ
4. æ˜¯å¦æœ‰é—æ¼ï¼Ÿ

å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
"""
        
        reflection = await self._call_llm(reflection_prompt)
        result.reflections.append(reflection)
        
        # å¦‚æœåæ€å‘ç°ä¸¥é‡é—®é¢˜ï¼Œå°è¯•ä¿®å¤
        if "ä¸¥é‡é—®é¢˜" in reflection or "é‡å¤§é—æ¼" in reflection:
            logger.info(f"[{self.name}] åæ€å‘ç°é—®é¢˜ï¼Œå°è¯•æ”¹è¿›")
            # è¿™é‡Œå¯ä»¥è§¦å‘é‡æ–°æ‰§è¡Œæˆ–ä¿®å¤é€»è¾‘
            result.warnings.append("è‡ªæˆ‘åæ€å‘ç°æ½œåœ¨é—®é¢˜ï¼Œå»ºè®®äººå·¥å®¡æŸ¥")
        
        return result
    
    async def _learn_from_execution(
        self,
        task: Task,
        result: TaskResult,
    ) -> None:
        """ä»æ‰§è¡Œä¸­å­¦ä¹ ."""
        if not self._memory:
            return
        
        # å­˜å‚¨ç»éªŒ
        experience = f"ä»»åŠ¡ç±»å‹ï¼š{task.type}\nä»»åŠ¡ï¼š{task.title}\nç»“æœï¼š{'æˆåŠŸ' if result.success else 'å¤±è´¥'}"
        
        if result.success:
            lesson = "æˆåŠŸå®Œæˆä»»åŠ¡çš„æ–¹æ³•å’Œè¦ç‚¹"
            if result.reflections:
                lesson += f"\nåæ€ï¼š{result.reflections[-1][:200]}"
        else:
            lesson = f"å¤±è´¥åŸå› ï¼š{result.error_message}"
        
        self._memory.learn(
            experience=experience,
            lesson=lesson,
            context={"task_id": task.id, "task_type": task.type},
        )
    
    # =========================================================================
    # åä½œæ–¹æ³•
    # =========================================================================
    
    async def review(
        self,
        artifact: Artifact,
        context: TaskContext,
    ) -> ReviewResult:
        """å®¡æŸ¥äº§å‡ºç‰©."""
        self._state.status = "reviewing"
        
        logger.info(f"[{self.name}] å®¡æŸ¥äº§å‡ºç‰©: {artifact.name}")
        
        review_prompt = self._build_review_prompt(artifact, context)
        response = await self._call_llm(review_prompt)
        
        result = self._parse_review_response(response, artifact)
        
        self._state.reviews_completed += 1
        self._state.status = "idle"
        
        return result
    
    async def collaborate(
        self,
        message: AgentMessage,
    ) -> AgentMessage | None:
        """å¤„ç†åä½œæ¶ˆæ¯."""
        logger.debug(f"[{self.name}] æ”¶åˆ°æ¶ˆæ¯: {message.type.value}")
        
        # æ ¹æ®æ¶ˆæ¯ç±»å‹å¤„ç†
        if message.type == MessageType.REQUEST_REVIEW:
            return await self._handle_review_request(message)
        elif message.type == MessageType.REQUEST_HELP:
            return await self._handle_help_request(message)
        elif message.type == MessageType.DEBATE_ARGUMENT:
            return await self._handle_debate(message)
        elif message.type == MessageType.CONSENSUS_VOTE:
            return await self._handle_vote_request(message)
        elif message.type == MessageType.PAIR_SESSION_START:
            return await self._handle_pair_programming(message)
        else:
            return await self._handle_generic_message(message)
    
    async def debate(
        self,
        topic: str,
        position: str,
        context: TaskContext | None = None,
    ) -> DebateArgument:
        """å‚ä¸è¾©è®º."""
        prompt = f"""ä½ æ­£åœ¨å‚ä¸æŠ€æœ¯è¾©è®ºã€‚

ä¸»é¢˜ï¼š{topic}
ä½ çš„ç«‹åœºï¼š{position}

è¯·æå‡ºæœ‰åŠ›çš„è®ºç‚¹æ”¯æŒä½ çš„ç«‹åœºï¼ŒåŒ…æ‹¬ï¼š
1. æ ¸å¿ƒè®ºç‚¹
2. æ”¯æŒç†ç”±ï¼ˆè‡³å°‘3ç‚¹ï¼‰
3. å¯èƒ½çš„åå¯¹æ„è§åŠå›åº”

æ ¼å¼ï¼š
æ ¸å¿ƒè®ºç‚¹ï¼š[è®ºç‚¹]
ç†ç”±1ï¼š[ç†ç”±]
ç†ç”±2ï¼š[ç†ç”±]
ç†ç”±3ï¼š[ç†ç”±]
åº”å¯¹åé©³ï¼š[é¢„é˜²æ€§è®ºè¿°]
ç½®ä¿¡åº¦ï¼š[0.0-1.0]
"""
        
        response = await self._call_llm(prompt)
        
        return self._parse_debate_argument(response, position)
    
    async def vote(
        self,
        proposal: str,
        options: list[str],
    ) -> Vote:
        """æŠ•ç¥¨."""
        prompt = f"""è¯·å¯¹ä»¥ä¸‹ææ¡ˆæŠ•ç¥¨ï¼š

ææ¡ˆå†…å®¹ï¼š{proposal}

é€‰é¡¹ï¼š
{chr(10).join(f'- {opt}' for opt in options)}

è¯·é€‰æ‹©ä¸€ä¸ªé€‰é¡¹å¹¶è¯´æ˜ç†ç”±ã€‚
æ ¼å¼ï¼š
é€‰æ‹©ï¼š[é€‰é¡¹]
ç†ç”±ï¼š[ä½ çš„ç†ç”±]
ç½®ä¿¡åº¦ï¼š[0.0-1.0]
"""
        
        response = await self._call_llm(prompt)
        
        return self._parse_vote(response, options)
    
    # =========================================================================
    # è¾…åŠ©æ–¹æ³•
    # =========================================================================
    
    async def _call_llm(
        self,
        prompt: str,
        temperature: float | None = None,
    ) -> str:
        """è°ƒç”¨LLM."""
        messages = [
            {"role": "system", "content": self._profile.system_prompt},
            *self._conversation_history[-10:],  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
            {"role": "user", "content": prompt},
        ]
        
        response = await self._llm.generate(
            messages=messages,
            temperature=temperature or self._profile.temperature,
            max_tokens=self._profile.max_tokens,
        )
        
        # æ›´æ–°å¯¹è¯å†å²
        self._conversation_history.append({"role": "user", "content": prompt})
        self._conversation_history.append({"role": "assistant", "content": response})
        
        return response
    
    def _build_planning_prompt(
        self,
        task: Task,
        context: TaskContext,
        understanding: dict[str, Any],
        memories: list[str],
    ) -> str:
        """æ„å»ºè§„åˆ’æç¤ºè¯."""
        memories_text = "\n".join(f"- {m[:100]}..." for m in memories) if memories else "æ— ç›¸å…³ç»éªŒ"
        
        return f"""è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡åˆ¶å®šæ‰§è¡Œè®¡åˆ’ï¼š

ä»»åŠ¡ï¼š{task.title}
æè¿°ï¼š{task.description}
ç±»å‹ï¼š{task.type}
å¤æ‚åº¦ï¼š{task.complexity}/10

ä»»åŠ¡åˆ†æï¼š
{understanding.get('analysis', '')}

ç›¸å…³ç»éªŒï¼š
{memories_text}

æŠ€æœ¯æ ˆï¼š
{context.tech_stack}

è¯·åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å«ï¼š
1. æ­¥éª¤æè¿°
2. å…·ä½“è¡ŒåŠ¨
3. é¢„æœŸäº§å‡º
4. æ˜¯å¦éœ€è¦å·¥å…·ï¼ˆå¦‚æœéœ€è¦ï¼ŒæŒ‡å®šå·¥å…·ç±»å‹ï¼‰

æ ¼å¼ï¼š
æ­¥éª¤1ï¼š
  æè¿°ï¼š[æè¿°]
  è¡ŒåŠ¨ï¼š[å…·ä½“è¡ŒåŠ¨]
  äº§å‡ºï¼š[é¢„æœŸäº§å‡º]
  å·¥å…·ï¼š[å·¥å…·ç±»å‹æˆ–"æ— "]

æ­¥éª¤2ï¼š
...
"""
    
    def _build_review_prompt(
        self,
        artifact: Artifact,
        context: TaskContext,
    ) -> str:
        """æ„å»ºå®¡æŸ¥æç¤ºè¯."""
        return f"""è¯·å®¡æŸ¥ä»¥ä¸‹{artifact.type.value}ï¼š

æ–‡ä»¶åï¼š{artifact.name}
è¯­è¨€/æ¡†æ¶ï¼š{artifact.language or 'æœªçŸ¥'} / {artifact.framework or 'æœªçŸ¥'}

å†…å®¹ï¼š
{artifact.content[:5000]}



è¯·ä»ä»¥ä¸‹æ–¹é¢è¿›è¡Œå®¡æŸ¥ï¼š
1. æ­£ç¡®æ€§ï¼šé€»è¾‘æ˜¯å¦æ­£ç¡®
2. ä»£ç è´¨é‡ï¼šå¯è¯»æ€§ã€å¯ç»´æŠ¤æ€§
3. æœ€ä½³å®è·µï¼šæ˜¯å¦éµå¾ªæœ€ä½³å®è·µ
4. å®‰å…¨æ€§ï¼šæ˜¯å¦æœ‰å®‰å…¨éšæ‚£
5. æ€§èƒ½ï¼šæ˜¯å¦æœ‰æ€§èƒ½é—®é¢˜

æ ¼å¼ï¼š
æ€»ä½“è¯„åˆ†ï¼š[1-10]
æ˜¯å¦é€šè¿‡ï¼š[æ˜¯/å¦]

é—®é¢˜åˆ—è¡¨ï¼š
- [é—®é¢˜1] (ä¸¥é‡ç¨‹åº¦: é«˜/ä¸­/ä½)
- [é—®é¢˜2] (ä¸¥é‡ç¨‹åº¦: é«˜/ä¸­/ä½)

æ”¹è¿›å»ºè®®ï¼š
- [å»ºè®®1]
- [å»ºè®®2]
"""
    
    def _parse_plan(self, response: str) -> list[dict[str, Any]]:
        """è§£ææ‰§è¡Œè®¡åˆ’."""
        plan = []
        current_step = {}
        
        for line in response.strip().split("\n"):
            line = line.strip()
            
            if line.startswith("æ­¥éª¤") and "ï¼š" in line:
                if current_step:
                    plan.append(current_step)
                current_step = {"step": line}
            elif line.startswith("æè¿°ï¼š"):
                current_step["thought"] = line.split("ï¼š", 1)[-1].strip()
            elif line.startswith("è¡ŒåŠ¨ï¼š"):
                current_step["action"] = line.split("ï¼š", 1)[-1].strip()
            elif line.startswith("äº§å‡ºï¼š"):
                current_step["output"] = line.split("ï¼š", 1)[-1].strip()
            elif line.startswith("å·¥å…·ï¼š"):
                tool = line.split("ï¼š", 1)[-1].strip()
                if tool != "æ— ":
                    current_step["tool"] = tool
        
        if current_step:
            plan.append(current_step)
        
        return plan if plan else [{"thought": "ç›´æ¥æ‰§è¡Œä»»åŠ¡", "action": "æ‰§è¡Œ"}]
    
    def _parse_review_response(
        self,
        response: str,
        artifact: Artifact,
    ) -> ReviewResult:
        """è§£æå®¡æŸ¥å“åº”."""
        result = ReviewResult(reviewer_id=self.id)
        
        lines = response.strip().split("\n")
        current_section = ""
        
        for line in lines:
            line = line.strip()
            
            if line.startswith("æ€»ä½“è¯„åˆ†"):
                try:
                    score = float(line.split("ï¼š", 1)[-1].strip().split("/")[0])
                    result.overall_score = score / 10.0
                except (ValueError, IndexError):
                    result.overall_score = 0.7
            elif line.startswith("æ˜¯å¦é€šè¿‡"):
                result.approved = "æ˜¯" in line
            elif line.startswith("é—®é¢˜åˆ—è¡¨"):
                current_section = "issues"
            elif line.startswith("æ”¹è¿›å»ºè®®"):
                current_section = "suggestions"
            elif line.startswith("- ") and current_section == "issues":
                severity = "medium"
                if "é«˜" in line:
                    severity = "critical"
                elif "ä½" in line:
                    severity = "info"
                
                result.comments.append(ReviewComment(
                    reviewer_id=self.id,
                    comment=line[2:].strip(),
                    severity=severity,
                ))
                result.issues_found += 1
                if severity == "critical":
                    result.critical_issues += 1
            elif line.startswith("- ") and current_section == "suggestions":
                result.suggestions.append(line[2:].strip())
        
        return result
    
    def _parse_debate_argument(
        self,
        response: str,
        position: str,
    ) -> DebateArgument:
        """è§£æè¾©è®ºè®ºç‚¹."""
        argument = DebateArgument(
            agent_id=self.id,
            position=position,
        )
        
        for line in response.strip().split("\n"):
            line = line.strip()
            
            if line.startswith("æ ¸å¿ƒè®ºç‚¹"):
                argument.main_argument = line.split("ï¼š", 1)[-1].strip()
            elif line.startswith("ç†ç”±"):
                reason = line.split("ï¼š", 1)[-1].strip()
                argument.supporting_points.append(reason)
            elif line.startswith("åº”å¯¹åé©³"):
                argument.rebuttals.append(line.split("ï¼š", 1)[-1].strip())
            elif line.startswith("ç½®ä¿¡åº¦"):
                try:
                    argument.confidence = float(line.split("ï¼š", 1)[-1].strip())
                except ValueError:
                    argument.confidence = 0.7
        
        return argument
    
    def _parse_vote(
        self,
        response: str,
        options: list[str],
    ) -> Vote:
        """è§£ææŠ•ç¥¨å“åº”."""
        vote = Vote(agent_id=self.id)
        
        for line in response.strip().split("\n"):
            line = line.strip()
            
            if line.startswith("é€‰æ‹©"):
                vote.vote = line.split("ï¼š", 1)[-1].strip()
            elif line.startswith("ç†ç”±"):
                vote.rationale = line.split("ï¼š", 1)[-1].strip()
        
        return vote
    
    def _calculate_confidence(self, artifacts: list[Artifact]) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦."""
        if not artifacts:
            return 0.0
        
        # åŸºäºäº§å‡ºç‰©æ•°é‡å’Œè´¨é‡è®¡ç®—
        base_score = min(len(artifacts) * 0.2, 0.6)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®¡æŸ¥é€šè¿‡çš„
        reviewed_count = sum(1 for a in artifacts if a.reviewed and a.approved)
        review_bonus = reviewed_count * 0.1
        
        return min(base_score + review_bonus + 0.3, 1.0)
    
    def _calculate_quality(self, artifacts: list[Artifact]) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•°."""
        if not artifacts:
            return 0.0
        
        scores = [a.quality_score for a in artifacts if a.quality_score is not None]
        
        if scores:
            return sum(scores) / len(scores)
        
        return 0.7  # é»˜è®¤åˆ†æ•°
    
    async def _handle_review_request(self, message: AgentMessage) -> AgentMessage:
        """å¤„ç†å®¡æŸ¥è¯·æ±‚."""
        return AgentMessage(
            type=MessageType.REVIEW_FEEDBACK,
            sender_id=self.id,
            receiver_id=message.sender_id,
            content="å®¡æŸ¥è¯·æ±‚å·²æ”¶åˆ°ï¼Œå°†å°½å¿«å¤„ç†ã€‚",
            reply_to=message.id,
        )
    
    async def _handle_help_request(self, message: AgentMessage) -> AgentMessage:
        """å¤„ç†å¸®åŠ©è¯·æ±‚."""
        response = await self._call_llm(f"åŒäº‹è¯·æ±‚å¸®åŠ©ï¼š\n{message.content}\n\nè¯·æä¾›å¸®åŠ©ï¼š")
        
        return AgentMessage(
            type=MessageType.PROVIDE_HELP,
            sender_id=self.id,
            receiver_id=message.sender_id,
            content=response,
            reply_to=message.id,
        )
    
    async def _handle_debate(self, message: AgentMessage) -> AgentMessage:
        """å¤„ç†è¾©è®ºæ¶ˆæ¯."""
        response = await self._call_llm(message.content)
        
        return AgentMessage(
            type=MessageType.DEBATE_ARGUMENT,
            sender_id=self.id,
            receiver_id=message.sender_id,
            content=response,
            reply_to=message.id,
        )
    
    async def _handle_vote_request(self, message: AgentMessage) -> AgentMessage:
        """å¤„ç†æŠ•ç¥¨è¯·æ±‚."""
        response = await self._call_llm(message.content)
        
        return AgentMessage(
            type=MessageType.CONSENSUS_VOTE,
            sender_id=self.id,
            receiver_id=message.sender_id,
            content=response,
            reply_to=message.id,
        )
    
    async def _handle_pair_programming(self, message: AgentMessage) -> AgentMessage:
        """å¤„ç†ç»“å¯¹ç¼–ç¨‹è¯·æ±‚."""
        return AgentMessage(
            type=MessageType.PAIR_SUGGESTION,
            sender_id=self.id,
            receiver_id=message.sender_id,
            content="å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹ç»“å¯¹ç¼–ç¨‹ã€‚",
            reply_to=message.id,
        )
    
    async def _handle_generic_message(self, message: AgentMessage) -> AgentMessage:
        """å¤„ç†é€šç”¨æ¶ˆæ¯."""
        response = await self._call_llm(message.content)
        
        return AgentMessage(
            type=MessageType.NOTIFICATION,
            sender_id=self.id,
            receiver_id=message.sender_id,
            content=response,
            reply_to=message.id,
        )
7. ä¸“ä¸šæ™ºèƒ½ä½“å®ç° (agents/experts/)

# agents/experts/project_manager.py
"""é¡¹ç›®ç»ç†æ™ºèƒ½ä½“."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

from ..base import BaseAgent
from ...core.types import (
    AgentCapability,
    AgentProfile,
    AgentRole,
    Artifact,
    ArtifactType,
    ExpertiseLevel,
    Task,
    TaskContext,
    ToolType,
)

if TYPE_CHECKING:
    from ...cognitive.memory import MemorySystem
    from ...cognitive.reasoning import ReasoningEngine
    from ...integration.llm import LLMClient
    from ...tools.executor import ToolExecutor


class ProjectManagerAgent(BaseAgent):
    """é¡¹ç›®ç»ç†æ™ºèƒ½ä½“.
    
    èŒè´£ï¼š
    - éœ€æ±‚åˆ†æä¸æ¾„æ¸…
    - ä»»åŠ¡æ‹†åˆ†ä¸ä¼°ç®—
    - è¿›åº¦è·Ÿè¸ªä¸åè°ƒ
    - é£é™©è¯†åˆ«ä¸ç®¡ç†
    - å›¢é˜Ÿæ²Ÿé€šä¸åä½œ
    """
    
    def __init__(
        self,
        llm_client: LLMClient,
        reasoning_engine: ReasoningEngine | None = None,
        memory_system: MemorySystem | None = None,
        tool_executor: ToolExecutor | None = None,
    ) -> None:
        """åˆå§‹åŒ–é¡¹ç›®ç»ç†."""
        profile = AgentProfile(
            name="é¡¹ç›®ç»ç† Alex",
            role=AgentRole.PROJECT_MANAGER,
            expertise_level=ExpertiseLevel.SENIOR,
            capabilities=[
                AgentCapability.REQUIREMENT_ANALYSIS,
                AgentCapability.TASK_DECOMPOSITION,
                AgentCapability.EFFORT_ESTIMATION,
                AgentCapability.RISK_ASSESSMENT,
                AgentCapability.ROADMAP_PLANNING,
            ],
            capability_levels={
                AgentCapability.REQUIREMENT_ANALYSIS: 9,
                AgentCapability.TASK_DECOMPOSITION: 9,
                AgentCapability.EFFORT_ESTIMATION: 8,
                AgentCapability.RISK_ASSESSMENT: 8,
                AgentCapability.ROADMAP_PLANNING: 8,
            },
            thinking_style="analytical",
            collaboration_style="cooperative",
            debate_skill=8,
            system_prompt="""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é¡¹ç›®ç»ç†ï¼Œæ‹¥æœ‰10å¹´ä»¥ä¸Šçš„è½¯ä»¶é¡¹ç›®ç®¡ç†ç»éªŒã€‚

ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
1. éœ€æ±‚åˆ†æï¼šèƒ½å¤Ÿå‡†ç¡®ç†è§£å’Œæ¾„æ¸…æ¨¡ç³Šéœ€æ±‚
2. ä»»åŠ¡æ‹†åˆ†ï¼šå°†å¤§é¡¹ç›®åˆ†è§£ä¸ºå¯ç®¡ç†çš„å°ä»»åŠ¡
3. é£é™©ç®¡ç†ï¼šè¯†åˆ«æ½œåœ¨é£é™©å¹¶åˆ¶å®šåº”å¯¹ç­–ç•¥
4. å›¢é˜Ÿåè°ƒï¼šä¿ƒè¿›å›¢é˜Ÿæˆå‘˜ä¹‹é—´çš„æœ‰æ•ˆåä½œ
5. è¿›åº¦æŠŠæ§ï¼šç¡®ä¿é¡¹ç›®æŒ‰æ—¶äº¤ä»˜

å·¥ä½œåŸåˆ™ï¼š
- ä»¥ç”¨æˆ·ä»·å€¼ä¸ºå¯¼å‘
- æ³¨é‡æ²Ÿé€šå’Œé€æ˜åº¦
- æå‰è¯†åˆ«å’Œè§£å†³é—®é¢˜
- å¹³è¡¡è´¨é‡ä¸è¿›åº¦

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- éœ€æ±‚æ–‡æ¡£ä½¿ç”¨æ ‡å‡†æ¨¡æ¿
- ä»»åŠ¡åˆ†è§£è¦æœ‰æ˜ç¡®çš„å®Œæˆæ ‡å‡†
- ä¼°ç®—è¦åŒ…å«é£é™©ç¼“å†²
""",
            temperature=0.6,
            allowed_tools=[ToolType.FILE_SYSTEM, ToolType.SEARCH],
        )
        
        super().__init__(
            profile=profile,
            llm_client=llm_client,
            reasoning_engine=reasoning_engine,
            memory_system=memory_system,
            tool_executor=tool_executor,
        )
    
    async def _execute_step(
        self,
        step: dict[str, Any],
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """æ‰§è¡Œæ­¥éª¤."""
        action = step.get("action", "")
        
        if "éœ€æ±‚åˆ†æ" in action or "åˆ†æ" in action:
            return await self._analyze_requirements(task, context)
        elif "ä»»åŠ¡æ‹†åˆ†" in action or "åˆ†è§£" in action:
            return await self._decompose_tasks(task, context)
        elif "ä¼°ç®—" in action:
            return await self._estimate_effort(task, context)
        elif "é£é™©" in action:
            return await self._assess_risks(task, context)
        else:
            return {"result": "æ­¥éª¤å®Œæˆ"}
    
    async def _generate_final_output(
        self,
        task: Task,
        context: TaskContext,
        plan: list[dict[str, Any]],
        intermediate_artifacts: list[Artifact],
    ) -> Artifact | None:
        """ç”Ÿæˆæœ€ç»ˆè¾“å‡º."""
        if task.type == "requirement_analysis":
            return await self._generate_requirement_doc(task, context)
        elif task.type == "task_decomposition":
            return await self._generate_task_breakdown(task, context)
        elif task.type == "project_planning":
            return await self._generate_project_plan(task, context)
        else:
            return None
    
    async def _analyze_requirements(
        self,
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """åˆ†æéœ€æ±‚."""
        prompt = f"""è¯·åˆ†æä»¥ä¸‹éœ€æ±‚ï¼š

éœ€æ±‚æè¿°ï¼š
{task.description}

è¯·ä»ä»¥ä¸‹æ–¹é¢è¿›è¡Œåˆ†æï¼š
1. åŠŸèƒ½éœ€æ±‚ï¼ˆå¿…é¡»å®ç°çš„åŠŸèƒ½ï¼‰
2. éåŠŸèƒ½éœ€æ±‚ï¼ˆæ€§èƒ½ã€å®‰å…¨ã€å¯ç”¨æ€§ç­‰ï¼‰
3. çº¦æŸæ¡ä»¶
4. å‡è®¾å’Œä¾èµ–
5. éœ€è¦æ¾„æ¸…çš„é—®é¢˜

æ ¼å¼ï¼š
## åŠŸèƒ½éœ€æ±‚
- [éœ€æ±‚1]
- [éœ€æ±‚2]

## éåŠŸèƒ½éœ€æ±‚
- [éœ€æ±‚1]

## çº¦æŸæ¡ä»¶
- [çº¦æŸ1]

## å¾…æ¾„æ¸…é—®é¢˜
- [é—®é¢˜1]
"""
        
        analysis = await self._call_llm(prompt)
        
        return {
            "result": "éœ€æ±‚åˆ†æå®Œæˆ",
            "analysis": analysis,
        }
    
    async def _decompose_tasks(
        self,
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """åˆ†è§£ä»»åŠ¡."""
        prompt = f"""è¯·å°†ä»¥ä¸‹éœ€æ±‚åˆ†è§£ä¸ºå…·ä½“çš„å¼€å‘ä»»åŠ¡ï¼š

éœ€æ±‚ï¼š{task.description}

æŠ€æœ¯æ ˆï¼š{context.tech_stack}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºä»»åŠ¡åˆ—è¡¨ï¼š

## ä»»åŠ¡åˆ—è¡¨

### ä»»åŠ¡1: [ä»»åŠ¡åç§°]
- æè¿°ï¼š[è¯¦ç»†æè¿°]
- ç±»å‹ï¼š[å¼€å‘/æµ‹è¯•/æ–‡æ¡£/éƒ¨ç½²]
- ä¼°ç®—å·¥æ—¶ï¼š[å°æ—¶æ•°]
- æ‰€éœ€è§’è‰²ï¼š[åç«¯/å‰ç«¯/å…¨æ ˆ/æµ‹è¯•]
- ä¾èµ–ä»»åŠ¡ï¼š[ä¾èµ–çš„ä»»åŠ¡IDï¼Œå¦‚æ— åˆ™å¡«"æ— "]
- éªŒæ”¶æ ‡å‡†ï¼š
  - [æ ‡å‡†1]
  - [æ ‡å‡†2]

### ä»»åŠ¡2: ...
"""
        
        decomposition = await self._call_llm(prompt)
        
        return {
            "result": "ä»»åŠ¡åˆ†è§£å®Œæˆ",
            "decomposition": decomposition,
        }
    
    async def _estimate_effort(
        self,
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """ä¼°ç®—å·¥ä½œé‡."""
        prompt = f"""è¯·ä¼°ç®—ä»¥ä¸‹ä»»åŠ¡çš„å·¥ä½œé‡ï¼š

ä»»åŠ¡ï¼š{task.description}
å¤æ‚åº¦ï¼š{task.complexity}/10

è¯·æä¾›ï¼š
1. ä¹è§‚ä¼°ç®—ï¼ˆæœ€å¿«å®Œæˆæ—¶é—´ï¼‰
2. æ­£å¸¸ä¼°ç®—ï¼ˆé¢„æœŸå®Œæˆæ—¶é—´ï¼‰
3. æ‚²è§‚ä¼°ç®—ï¼ˆæœ€æ…¢å®Œæˆæ—¶é—´ï¼‰
4. é£é™©å› ç´ 
5. å»ºè®®çš„ç¼“å†²æ—¶é—´

æ ¼å¼ï¼š
ä¹è§‚ä¼°ç®—ï¼š[Xå°æ—¶/å¤©]
æ­£å¸¸ä¼°ç®—ï¼š[Xå°æ—¶/å¤©]
æ‚²è§‚ä¼°ç®—ï¼š[Xå°æ—¶/å¤©]
é£é™©å› ç´ ï¼š
- [å› ç´ 1]
- [å› ç´ 2]
å»ºè®®ç¼“å†²ï¼š[Xå°æ—¶/å¤©]
æœ€ç»ˆå»ºè®®ï¼š[Xå°æ—¶/å¤©]
"""
        
        estimation = await self._call_llm(prompt)
        
        return {
            "result": "å·¥ä½œé‡ä¼°ç®—å®Œæˆ",
            "estimation": estimation,
        }
    
    async def _assess_risks(
        self,
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """è¯„ä¼°é£é™©."""
        prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹é¡¹ç›®/ä»»åŠ¡çš„é£é™©ï¼š

ä»»åŠ¡ï¼š{task.title}
æè¿°ï¼š{task.description}

è¯·è¯†åˆ«ï¼š
1. æŠ€æœ¯é£é™©
2. èµ„æºé£é™©
3. è¿›åº¦é£é™©
4. å¤–éƒ¨ä¾èµ–é£é™©

å¯¹æ¯ä¸ªé£é™©ï¼Œè¯·æä¾›ï¼š
- é£é™©æè¿°
- å¯èƒ½æ€§ï¼ˆé«˜/ä¸­/ä½ï¼‰
- å½±å“ç¨‹åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰
- åº”å¯¹ç­–ç•¥

æ ¼å¼ï¼š
## é£é™©æ¸…å•

### é£é™©1: [é£é™©åç§°]
- æè¿°ï¼š[æè¿°]
- å¯èƒ½æ€§ï¼š[é«˜/ä¸­/ä½]
- å½±å“ï¼š[é«˜/ä¸­/ä½]
- åº”å¯¹ç­–ç•¥ï¼š[ç­–ç•¥]

### é£é™©2: ...
"""
        
        risks = await self._call_llm(prompt)
        
        return {
            "result": "é£é™©è¯„ä¼°å®Œæˆ",
            "risks": risks,
        }
    
    async def _generate_requirement_doc(
        self,
        task: Task,
        context: TaskContext,
    ) -> Artifact:
        """ç”Ÿæˆéœ€æ±‚æ–‡æ¡£."""
        prompt = f"""è¯·ç”Ÿæˆå®Œæ•´çš„éœ€æ±‚æ–‡æ¡£ï¼š

é¡¹ç›®ï¼š{context.project_name}
éœ€æ±‚æè¿°ï¼š{task.description}

è¯·æŒ‰ä»¥ä¸‹æ¨¡æ¿ç”Ÿæˆæ–‡æ¡£ï¼š

# {context.project_name} - éœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦

## 1. æ–‡æ¡£ä¿¡æ¯
- ç‰ˆæœ¬ï¼š1.0
- æ—¥æœŸï¼š[æ—¥æœŸ]
- ä½œè€…ï¼šé¡¹ç›®ç»ç†

## 2. é¡¹ç›®æ¦‚è¿°
[é¡¹ç›®èƒŒæ™¯å’Œç›®æ ‡]

## 3. åŠŸèƒ½éœ€æ±‚
### 3.1 [åŠŸèƒ½æ¨¡å—1]
[è¯¦ç»†æè¿°]

### 3.2 [åŠŸèƒ½æ¨¡å—2]
[è¯¦ç»†æè¿°]

## 4. éåŠŸèƒ½éœ€æ±‚
### 4.1 æ€§èƒ½éœ€æ±‚
### 4.2 å®‰å…¨éœ€æ±‚
### 4.3 å¯ç”¨æ€§éœ€æ±‚

## 5. çº¦æŸä¸å‡è®¾

## 6. éªŒæ”¶æ ‡å‡†

## 7. é™„å½•
"""
        
        content = await self._call_llm(prompt)
        
        return Artifact(
            type=ArtifactType.REQUIREMENT_DOC,
            name=f"{context.project_name}_éœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦.md",
            content=content,
            language="markdown",
            created_by=self.id,
        )
    
    async def _generate_task_breakdown(
        self,
        task: Task,
        context: TaskContext,
    ) -> Artifact:
        """ç”Ÿæˆä»»åŠ¡åˆ†è§£æ–‡æ¡£."""
        result = await self._decompose_tasks(task, context)
        
        return Artifact(
            type=ArtifactType.DESIGN_DOC,
            name=f"{context.project_name}_ä»»åŠ¡åˆ†è§£.md",
            content=result["decomposition"],
            language="markdown",
            created_by=self.id,
        )
    
    async def _generate_project_plan(
        self,
        task: Task,
        context: TaskContext,
    ) -> Artifact:
        """ç”Ÿæˆé¡¹ç›®è®¡åˆ’."""
        prompt = f"""è¯·ç”Ÿæˆé¡¹ç›®è®¡åˆ’ï¼š

é¡¹ç›®ï¼š{context.project_name}
éœ€æ±‚ï¼š{task.description}

è¯·åŒ…å«ï¼š
1. é¡¹ç›®é‡Œç¨‹ç¢‘
2. é˜¶æ®µåˆ’åˆ†
3. èµ„æºåˆ†é…
4. é£é™©ç®¡ç†è®¡åˆ’
5. æ²Ÿé€šè®¡åˆ’
"""
        
        plan = await self._call_llm(prompt)
        
        return Artifact(
            type=ArtifactType.DESIGN_DOC,
            name=f"{context.project_name}_é¡¹ç›®è®¡åˆ’.md",
            content=plan,
            language="markdown",
            created_by=self.id,
        )

# agents/experts/architect.py
"""ç³»ç»Ÿæ¶æ„å¸ˆæ™ºèƒ½ä½“."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

from ..base import BaseAgent
from ...core.types import (
    AgentCapability,
    AgentProfile,
    AgentRole,
    Artifact,
    ArtifactType,
    ExpertiseLevel,
    Task,
    TaskContext,
    ToolType,
)

if TYPE_CHECKING:
    from ...cognitive.memory import MemorySystem
    from ...cognitive.reasoning import ReasoningEngine
    from ...integration.llm import LLMClient
    from ...tools.executor import ToolExecutor


class SystemArchitectAgent(BaseAgent):
    """ç³»ç»Ÿæ¶æ„å¸ˆæ™ºèƒ½ä½“.
    
    èŒè´£ï¼š
    - ç³»ç»Ÿæ¶æ„è®¾è®¡
    - æŠ€æœ¯é€‰å‹å†³ç­–
    - APIè®¾è®¡è§„èŒƒ
    - æ•°æ®åº“è®¾è®¡
    - æ¶æ„è¯„å®¡
    """
    
    def __init__(
        self,
        llm_client: LLMClient,
        reasoning_engine: ReasoningEngine | None = None,
        memory_system: MemorySystem | None = None,
        tool_executor: ToolExecutor | None = None,
    ) -> None:
        """åˆå§‹åŒ–ç³»ç»Ÿæ¶æ„å¸ˆ."""
        profile = AgentProfile(
            name="é¦–å¸­æ¶æ„å¸ˆ Sarah",
            role=AgentRole.SYSTEM_ARCHITECT,**
            expertise_level=ExpertiseLevel.PRINCIPAL,
            capabilities=[
                AgentCapability.SYSTEM_DESIGN,
                AgentCapability.API_DESIGN,
                AgentCapability.DATABASE_DESIGN,
                AgentCapability.MICROSERVICES_DESIGN,
                AgentCapability.EVENT_DRIVEN_DESIGN,
                AgentCapability.DISTRIBUTED_SYSTEMS,
            ],
            capability_levels={
                AgentCapability.SYSTEM_DESIGN: 10,
                AgentCapability.API_DESIGN: 9,
                AgentCapability.DATABASE_DESIGN: 9,
                AgentCapability.MICROSERVICES_DESIGN: 9,
                AgentCapability.DISTRIBUTED_SYSTEMS: 9,
            },
            thinking_style="analytical",
            collaboration_style="assertive",
            debate_skill=9,
            system_prompt="""ä½ æ˜¯ä¸€ä½é¦–å¸­ç³»ç»Ÿæ¶æ„å¸ˆï¼Œæ‹¥æœ‰15å¹´ä»¥ä¸Šçš„å¤§å‹ç³»ç»Ÿè®¾è®¡ç»éªŒã€‚

ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
1. ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼šèƒ½å¤Ÿè®¾è®¡é«˜å¯ç”¨ã€é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„ç³»ç»Ÿ
2. æŠ€æœ¯é€‰å‹ï¼šåŸºäºéœ€æ±‚é€‰æ‹©æœ€åˆé€‚çš„æŠ€æœ¯æ ˆ
3. APIè®¾è®¡ï¼šè®¾è®¡æ¸…æ™°ã€ä¸€è‡´ã€æ˜“ç”¨çš„API
4. æ•°æ®å»ºæ¨¡ï¼šè®¾è®¡åˆç†çš„æ•°æ®æ¨¡å‹å’Œå­˜å‚¨æ–¹æ¡ˆ
5. æ¶æ„è¯„å®¡ï¼šå‘ç°æ½œåœ¨é—®é¢˜å¹¶æå‡ºæ”¹è¿›å»ºè®®

è®¾è®¡åŸåˆ™ï¼š
- SOLIDåŸåˆ™
- é«˜å†…èšä½è€¦åˆ
- å…³æ³¨ç‚¹åˆ†ç¦»
- é˜²å¾¡æ€§è®¾è®¡
- é¢å‘å¤±è´¥è®¾è®¡

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- æ¶æ„å›¾ä½¿ç”¨Mermaidè¯­æ³•
- è®¾è®¡æ–‡æ¡£ç»“æ„æ¸…æ™°
- æ˜ç¡®è¯´æ˜è®¾è®¡å†³ç­–çš„ç†ç”±
""",
            temperature=0.5,
            allowed_tools=[ToolType.FILE_SYSTEM, ToolType.SEARCH],
        )
        
        super().__init__(
            profile=profile,
            llm_client=llm_client,
            reasoning_engine=reasoning_engine,
            memory_system=memory_system,
            tool_executor=tool_executor,
        )
    
    async def _execute_step(
        self,
        step: dict[str, Any],
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """æ‰§è¡Œæ­¥éª¤."""
        action = step.get("action", "")
        
        if "æ¶æ„è®¾è®¡" in action or "ç³»ç»Ÿè®¾è®¡" in action:
            return await self._design_architecture(task, context)
        elif "APIè®¾è®¡" in action:
            return await self._design_api(task, context)
        elif "æ•°æ®åº“è®¾è®¡" in action or "æ•°æ®å»ºæ¨¡" in action:
            return await self._design_database(task, context)
        elif "æŠ€æœ¯é€‰å‹" in action:
            return await self._select_technology(task, context)
        else:
            return {"result": "æ­¥éª¤å®Œæˆ"}
    
    async def _generate_final_output(
        self,
        task: Task,
        context: TaskContext,
        plan: list[dict[str, Any]],
        intermediate_artifacts: list[Artifact],
    ) -> Artifact | None:
        """ç”Ÿæˆæœ€ç»ˆè¾“å‡º."""
        if task.type == "architecture_design":
            return await self._generate_architecture_doc(task, context)
        elif task.type == "api_design":
            return await self._generate_api_spec(task, context)
        elif task.type == "database_design":
            return await self._generate_database_schema(task, context)
        else:
            return None
    
    async def _design_architecture(
        self,
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """è®¾è®¡ç³»ç»Ÿæ¶æ„."""
        prompt = f"""è¯·ä¸ºä»¥ä¸‹éœ€æ±‚è®¾è®¡ç³»ç»Ÿæ¶æ„ï¼š

éœ€æ±‚ï¼š{task.description}
æŠ€æœ¯æ ˆåå¥½ï¼š{context.tech_stack}
çº¦æŸæ¡ä»¶ï¼š{context.constraints}

è¯·æä¾›ï¼š
1. æ¶æ„æ¦‚è¿°
2. æ ¸å¿ƒç»„ä»¶åŠå…¶èŒè´£
3. ç»„ä»¶é—´çš„äº¤äº’å…³ç³»
4. æ•°æ®æµ
5. å…³é”®è®¾è®¡å†³ç­–åŠç†ç”±
6. æ¶æ„å›¾ï¼ˆä½¿ç”¨Mermaidè¯­æ³•ï¼‰

æ ¼å¼ï¼š
## æ¶æ„æ¦‚è¿°
[æ¦‚è¿°æè¿°]

## æ ¸å¿ƒç»„ä»¶
### ç»„ä»¶1: [åç§°]
- èŒè´£ï¼š[èŒè´£æè¿°]
- æŠ€æœ¯é€‰å‹ï¼š[æŠ€æœ¯]

## ç»„ä»¶äº¤äº’
[äº¤äº’æè¿°]

## æ¶æ„å›¾
```mermaid
[æ¶æ„å›¾]
  è®¾è®¡å†³ç­– [å†³ç­–1]ï¼š[ç†ç”±]
"""  design = await self._call_llm(prompt)
 
 return {
     "result": "æ¶æ„è®¾è®¡å®Œæˆ",
     "design": design,
 }
 async def _design_api(
self,
task: Task,
context: TaskContext,
) -> dict[str, Any]:
"""è®¾è®¡API."""
prompt = f"""è¯·è®¾è®¡ä»¥ä¸‹åŠŸèƒ½çš„APIï¼š   åŠŸèƒ½éœ€æ±‚ï¼š{task.description} è¯·æä¾›RESTful APIè®¾è®¡ï¼ŒåŒ…æ‹¬ï¼š èµ„æºå®šä¹‰ ç«¯ç‚¹åˆ—è¡¨ è¯·æ±‚/å“åº”æ ¼å¼ é”™è¯¯å¤„ç† è®¤è¯æˆæƒ  æ ¼å¼ï¼ˆOpenAPIé£æ ¼ï¼‰ï¼š APIè®¾è®¡ èµ„æº: [èµ„æºåç§°] GET /api/v1/[resource] æè¿°ï¼š[æè¿°]
è¯·æ±‚å‚æ•°ï¼š [å‚æ•°å]: [ç±»å‹] - [æè¿°]  å“åº”ï¼š json å¤åˆ¶ä»£ç   {{
  "code": 0,
  "data": {{}}
}}
  POST /api/v1/[resource] ...
"""     api_design = await self._call_llm(prompt)
    
    return {
        "result": "APIè®¾è®¡å®Œæˆ",
        "api_design": api_design,
    }

async def _design_database(
    self,
    task: Task,
    context: TaskContext,
) -> dict[str, Any]:
    """è®¾è®¡æ•°æ®åº“."""
    prompt = f"""è¯·è®¾è®¡ä»¥ä¸‹éœ€æ±‚çš„æ•°æ®åº“æ¨¡å‹ï¼š
 éœ€æ±‚ï¼š{task.description} è¯·æä¾›ï¼š å®ä½“å®šä¹‰ å…³ç³»è¯´æ˜ ç´¢å¼•è®¾è®¡ ERå›¾ï¼ˆMermaidè¯­æ³•ï¼‰ SQL DDLè¯­å¥  æ ¼å¼ï¼š å®ä½“è®¾è®¡ è¡¨: [è¡¨å] å­—æ®µå ç±»å‹ çº¦æŸ è¯´æ˜   id BIGINT PK ä¸»é”®  ... ... ... ...   ç´¢å¼•ï¼š idx_[name]: [å­—æ®µ] - [ç”¨é€”]  ERå›¾ å¤åˆ¶ä»£ç   erDiagram
    [ERå›¾å®šä¹‰]
  DDL sql å¤åˆ¶ä»£ç   CREATE TABLE ...
  """     db_design = await self._call_llm(prompt)
    
    return {
        "result": "æ•°æ®åº“è®¾è®¡å®Œæˆ",
        "db_design": db_design,
    }

async def _select_technology(
    self,
    task: Task,
    context: TaskContext,
) -> dict[str, Any]:
    """æŠ€æœ¯é€‰å‹."""
    prompt = f"""è¯·ä¸ºä»¥ä¸‹é¡¹ç›®è¿›è¡ŒæŠ€æœ¯é€‰å‹ï¼š
 é¡¹ç›®éœ€æ±‚ï¼š{task.description}
ç°æœ‰æŠ€æœ¯æ ˆï¼š{context.tech_stack}
çº¦æŸæ¡ä»¶ï¼š{context.constraints} è¯·é’ˆå¯¹ä»¥ä¸‹æ–¹é¢è¿›è¡Œé€‰å‹ï¼š ç¼–ç¨‹è¯­è¨€ Webæ¡†æ¶ æ•°æ®åº“ ç¼“å­˜ æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆå¦‚éœ€è¦ï¼‰ éƒ¨ç½²æ–¹æ¡ˆ  å¯¹æ¯ä¸ªé€‰å‹ï¼Œè¯·è¯´æ˜ï¼š é€‰æ‹©çš„æŠ€æœ¯  é€‰æ‹©ç†ç”±  å¯é€‰æ–¹æ¡ˆ  é£é™©å’Œæ³¨æ„äº‹é¡¹
"""   selection = await self._call_llm(prompt)
  
  return {
      "result": "æŠ€æœ¯é€‰å‹å®Œæˆ",
      "selection": selection,
  }
 async def _generate_architecture_doc(
self,
task: Task,
context: TaskContext,
) -> Artifact:
"""ç”Ÿæˆæ¶æ„æ–‡æ¡£."""
design_result = await self._design_architecture(task, context)   return Artifact(
      type=ArtifactType.ARCHITECTURE_DOC,
      name=f"{context.project_name}_æ¶æ„è®¾è®¡æ–‡æ¡£.md",
      content=design_result["design"],
      language="markdown",
      created_by=self.id,
  )
 async def _generate_api_spec(
self,
task: Task,
context: TaskContext,
) -> Artifact:
"""ç”ŸæˆAPIè§„èŒƒ."""
api_result = await self._design_api(task, context)   return Artifact(
      type=ArtifactType.API_SPEC,
      name=f"{context.project_name}_APIè§„èŒƒ.md",
      content=api_result["api_design"],
      language="markdown",
      created_by=self.id,
  )
 async def _generate_database_schema(
self,
task: Task,
context: TaskContext,
) -> Artifact:
"""ç”Ÿæˆæ•°æ®åº“Schema."""
db_result = await self._design_database(task, context)   return Artifact(
      type=ArtifactType.DESIGN_DOC,
      name=f"{context.project_name}_æ•°æ®åº“è®¾è®¡.md",
      content=db_result["db_design"],
      language="markdown",
      created_by=self.id,
  )
 
# agents/experts/backend.py
"""åç«¯å·¥ç¨‹å¸ˆæ™ºèƒ½ä½“."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

from ..base import BaseAgent
from ...core.types import (
    AgentCapability,
    AgentProfile,
    AgentRole,
    Artifact,
    ArtifactType,
    ExpertiseLevel,
    Task,
    TaskContext,
    ToolType,
)

if TYPE_CHECKING:
    from ...cognitive.memory import MemorySystem
    from ...cognitive.reasoning import ReasoningEngine
    from ...integration.llm import LLMClient
    from ...tools.executor import ToolExecutor


class BackendEngineerAgent(BaseAgent):
    """åç«¯å·¥ç¨‹å¸ˆæ™ºèƒ½ä½“.
    
    èŒè´£ï¼š
    - åç«¯æœåŠ¡å¼€å‘
    - APIå®ç°
    - æ•°æ®åº“æ“ä½œ
    - ä¸šåŠ¡é€»è¾‘å®ç°
    - å•å…ƒæµ‹è¯•
    """
    
    def __init__(
        self,
        llm_client: LLMClient,
        reasoning_engine: ReasoningEngine | None = None,
        memory_system: MemorySystem | None = None,
        tool_executor: ToolExecutor | None = None,
    ) -> None:
        """åˆå§‹åŒ–åç«¯å·¥ç¨‹å¸ˆ."""
        profile = AgentProfile(
            name="èµ„æ·±åç«¯å·¥ç¨‹å¸ˆ Michael",
            role=AgentRole.BACKEND_ENGINEER,
            expertise_level=ExpertiseLevel.SENIOR,
            capabilities=[
                AgentCapability.CODE_GENERATION,
                AgentCapability.CODE_DEBUGGING,
                AgentCapability.API_DESIGN,
                AgentCapability.DATABASE_DESIGN,
                AgentCapability.UNIT_TESTING,
                AgentCapability.PYTHON_EXPERT,
                AgentCapability.SQL_EXPERT,
            ],
            capability_levels={
                AgentCapability.CODE_GENERATION: 9,
                AgentCapability.PYTHON_EXPERT: 9,
                AgentCapability.SQL_EXPERT: 8,
                AgentCapability.UNIT_TESTING: 8,
                AgentCapability.API_DESIGN: 8,
            },
            thinking_style="balanced",
            collaboration_style="cooperative",
            debate_skill=7,
            system_prompt="""ä½ æ˜¯ä¸€ä½èµ„æ·±åç«¯å·¥ç¨‹å¸ˆï¼Œç²¾é€šPythonå’Œå¤šç§Webæ¡†æ¶ã€‚

ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
1. Pythonå¼€å‘ï¼šFastAPI, Django, Flaskç­‰æ¡†æ¶
2. æ•°æ®åº“ï¼šPostgreSQL, MySQL, Redis, MongoDB
3. APIå¼€å‘ï¼šRESTful, GraphQL
4. æµ‹è¯•ï¼špytest, å•å…ƒæµ‹è¯•, é›†æˆæµ‹è¯•
5. ä»£ç è´¨é‡ï¼šç±»å‹æ³¨è§£, æ–‡æ¡£å­—ç¬¦ä¸², æœ€ä½³å®è·µ

ç¼–ç è§„èŒƒï¼š
- ä½¿ç”¨ç±»å‹æ³¨è§£
- ç¼–å†™docstring
- éµå¾ªPEP 8
- ç¼–å†™å•å…ƒæµ‹è¯•
- å¤„ç†å¼‚å¸¸æƒ…å†µ
- è€ƒè™‘è¾¹ç•Œæ¡ä»¶

è¾“å‡ºè¦æ±‚ï¼š
- ä»£ç å¿…é¡»å®Œæ•´å¯è¿è¡Œ
- åŒ…å«å¿…è¦çš„å¯¼å…¥è¯­å¥
- æœ‰æ¸…æ™°çš„æ³¨é‡Š
- é™„å¸¦æµ‹è¯•ä»£ç 
""",
            temperature=0.4,
            allowed_tools=[
                ToolType.CODE_EXECUTOR,
                ToolType.FILE_SYSTEM,
                ToolType.TERMINAL,
                ToolType.GIT,
            ],
        )
        
        super().__init__(
            profile=profile,
            llm_client=llm_client,
            reasoning_engine=reasoning_engine,
            memory_system=memory_system,
            tool_executor=tool_executor,
        )
    
    async def _execute_step(
        self,
        step: dict[str, Any],
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """æ‰§è¡Œæ­¥éª¤."""
        action = step.get("action", "")
        
        if "ç¼–å†™" in action or "å®ç°" in action or "å¼€å‘" in action:
            return await self._write_code(step, task, context)
        elif "æµ‹è¯•" in action:
            return await self._write_tests(task, context)
        elif "è°ƒè¯•" in action or "ä¿®å¤" in action:
            return await self._debug_code(step, task, context)
        else:
            return {"result": "æ­¥éª¤å®Œæˆ"}
    
    async def _generate_final_output(
        self,
        task: Task,
        context: TaskContext,
        plan: list[dict[str, Any]],
        intermediate_artifacts: list[Artifact],
    ) -> Artifact | None:
        """ç”Ÿæˆæœ€ç»ˆè¾“å‡º."""
        # åˆå¹¶æ‰€æœ‰ä¸­é—´äº§å‡ºç‰©
        if intermediate_artifacts:
            combined_code = "\n\n".join(
                f"# {a.name}\n{a.content}" 
                for a in intermediate_artifacts 
                if a.type == ArtifactType.SOURCE_CODE
            )
            
            return Artifact(
                type=ArtifactType.SOURCE_CODE,
                name=f"{task.title.replace(' ', '_').lower()}.py",
                content=combined_code,
                language="python",
                framework="fastapi",
                created_by=self.id,
            )
        
        # å¦‚æœæ²¡æœ‰ä¸­é—´äº§å‡ºï¼Œç›´æ¥ç”Ÿæˆ
        return await self._generate_code(task, context)
    
    async def _write_code(
        self,
        step: dict[str, Any],
        task: Task,
        context: TaskContext,
    ) -> dict[str, Any]:
        """ç¼–å†™ä»£ç ."""
        prompt = f"""è¯·ç¼–å†™ä»¥ä¸‹åŠŸèƒ½çš„Pythonä»£ç ï¼š

ä»»åŠ¡ï¼š{task.title}
æè¿°ï¼š{task.description}
å½“å‰æ­¥éª¤ï¼š{step.get('thought', '')}

æŠ€æœ¯è¦æ±‚ï¼š
- æ¡†æ¶ï¼š{context.tech_stack.get('backend', ['FastAPI'])}
- ç¼–ç è§„èŒƒï¼š{context.coding_standards}

è¯·æä¾›ï¼š
1. å®Œæ•´çš„å®ç°ä»£ç 
2. å¿…è¦çš„å¯¼å…¥è¯­å¥
3. ç±»å‹æ³¨è§£
4. docstring
5. é”™è¯¯å¤„ç†

ä»£ç æ ¼å¼ï¼š
```python
# [æ–‡ä»¶å]

[å¯¼å…¥è¯­å¥]

[ä»£ç å®ç°]
  """     code = await self._call_llm(prompt)
    
    # æå–ä»£ç å—
    code_content = self._extract_code_block(code, "python")
    
    artifact = Artifact(
        type=ArtifactType.SOURCE_CODE,
        name=f"{step.get('output', 'module')}.py",
        content=code_content,
        language="python",
        created_by=self.id,
    )
    
    return {
        "result": "ä»£ç ç¼–å†™å®Œæˆ",
        "artifact": artifact,
    }

async def _write_tests(
    self,
    task: Task,
    context: TaskContext,
) -> dict[str, Any]:
    """ç¼–å†™æµ‹è¯•."""
    prompt = f"""è¯·ä¸ºä»¥ä¸‹åŠŸèƒ½ç¼–å†™å•å…ƒæµ‹è¯•ï¼š
 åŠŸèƒ½æè¿°ï¼š{task.description} è¯·ä½¿ç”¨pytestç¼–å†™æµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š æ­£å¸¸æƒ…å†µæµ‹è¯• è¾¹ç•Œæ¡ä»¶æµ‹è¯• å¼‚å¸¸æƒ…å†µæµ‹è¯• Mockå¤–éƒ¨ä¾èµ–  æ ¼å¼ï¼š   # test_[module].py

import pytest
from unittest.mock import Mock, patch

# æµ‹è¯•ä»£ç 
  """     test_code = await self._call_llm(prompt)
    code_content = self._extract_code_block(test_code, "python")
    
    artifact = Artifact(
        type=ArtifactType.TEST_CODE,
        name=f"test_{task.title.replace(' ', '_').lower()}.py",
        content=code_content,
        language="python",
        created_by=self.id,
    )
    
    return {
        "result": "æµ‹è¯•ä»£ç ç¼–å†™å®Œæˆ",
        "artifact": artifact,
    }

async def _debug_code(
    self,
    step: dict[str, Any],
    task: Task,
    context: TaskContext,
) -> dict[str, Any]:
    """è°ƒè¯•ä»£ç ."""
    prompt = f"""è¯·è°ƒè¯•ä»¥ä¸‹é—®é¢˜ï¼š
 é—®é¢˜æè¿°ï¼š{task.description}
é”™è¯¯ä¿¡æ¯ï¼š{step.get('error', 'æœªçŸ¥é”™è¯¯')} è¯·ï¼š åˆ†æé—®é¢˜åŸå›   æä¾›ä¿®å¤æ–¹æ¡ˆ  ç»™å‡ºä¿®å¤åçš„ä»£ç 
"""  fix = await self._call_llm(prompt)
 
 return {
     "result": "è°ƒè¯•å®Œæˆ",
     "fix": fix,
 }
 async def _generate_code(
self,
task: Task,
context: TaskContext,
) -> Artifact:
"""ç”Ÿæˆä»£ç ."""
prompt = f"""è¯·ä¸ºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„Pythonä»£ç ï¼š   éœ€æ±‚ï¼š{task.title}
æè¿°ï¼š{task.description}
æŠ€æœ¯æ ˆï¼š{context.tech_stack} è¯·ç”Ÿæˆï¼š å®Œæ•´å¯è¿è¡Œçš„ä»£ç  åŒ…å«æ‰€æœ‰å¿…è¦çš„å¯¼å…¥ ç±»å‹æ³¨è§£ è¯¦ç»†çš„docstring é”™è¯¯å¤„ç† é…å¥—çš„å•å…ƒæµ‹è¯•  ä»£ç ç»“æ„ï¼š python å¤åˆ¶ä»£ç   \"\"\"
æ¨¡å—è¯´æ˜
\"\"\"

# å¯¼å…¥

# å¸¸é‡

# æ•°æ®ç±»/æ¨¡å‹

# æ ¸å¿ƒé€»è¾‘

# æµ‹è¯•ä»£ç 
  """     code = await self._call_llm(prompt)
    code_content = self._extract_code_block(code, "python")
    
    return Artifact(
        type=ArtifactType.SOURCE_CODE,
        name=f"{task.title.replace(' ', '_').lower()}.py",
        content=code_content,
        language="python",
        framework=context.tech_stack.get("backend", [""])[0] if context.tech_stack.get("backend") else "",
        created_by=self.id,
    )

def _extract_code_block(self, text: str, language: str = "") -> str:
    """æå–ä»£ç å—."""
    import re
    
    pattern = rf"```{language}\n?(.*?)```"
    matches = re.findall(pattern, text, re.DOTALL)
    
    if matches:
        return matches[0].strip()
    
    # å¦‚æœæ²¡æ‰¾åˆ°ä»£ç å—ï¼Œè¿”å›æ•´ä¸ªæ–‡æœ¬
    return text.strip()
 å¤åˆ¶ä»£ç   
---

## 8. å‡çº§ç‰ˆç¼–æ’å™¨ (orchestration/orchestrator.py)

```
"""ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - ç¼–æ’å™¨.

å‡çº§å†…å®¹ï¼š
- æ™ºèƒ½ä»»åŠ¡åˆ†é…
- å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–
- åŠ¨æ€è´Ÿè½½å‡è¡¡
- æ•…éšœæ¢å¤
- å®æ—¶ç›‘æ§
"""

from __future__ import annotations

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

from ..core.types import (
    AgentId,
    AgentRole,
    Artifact,
    ExecutionContext,
    Task,
    TaskContext,
    TaskId,
    TaskPriority,
    TaskResult,
    TaskStatus,
)

if TYPE_CHECKING:
    from ..agents.base import BaseAgent
    from ..workflow.engine import WorkflowEngine


logger = logging.getLogger(__name__)


@dataclass
class ExecutionPlan:
    """æ‰§è¡Œè®¡åˆ’."""
    
    id: str = ""
    name: str = ""
    
    # é˜¶æ®µ
    phases: list[ExecutionPhase] = field(default_factory=list)
    
    # çŠ¶æ€
    current_phase_index: int = 0
    status: str = "pending"
    
    # æ—¶é—´
    created_at: datetime = field(default_factory=datetime.now)
    started_at: datetime | None = None
    completed_at: datetime | None = None
    
    # ç»“æœ
    results: list[TaskResult] = field(default_factory=list)
    artifacts: list[Artifact] = field(default_factory=list)


@dataclass
class ExecutionPhase:
    """æ‰§è¡Œé˜¶æ®µ."""
    
    id: str = ""
    name: str = ""
    description: str = ""
    
    # ä»»åŠ¡
    tasks: list[Task] = field(default_factory=list)
    
    # æ‰§è¡Œæ–¹å¼
    parallel: bool = False
    max_parallel: int = 5
    
    # é—¨ç¦
    entry_condition: str | None = None
    exit_condition: str | None = None
    
    # çŠ¶æ€
    status: str = "pending"
    
    # ç»“æœ
    results: list[TaskResult] = field(default_factory=list)


@dataclass
class OrchestratorConfig:
    """ç¼–æ’å™¨é…ç½®."""
    
    # å¹¶è¡Œé…ç½®
    max_parallel_tasks: int = 5
    max_parallel_phases: int = 2
    
    # é‡è¯•é…ç½®
    max_retries: int = 3
    retry_delay_seconds: float = 1.0
    
    # è¶…æ—¶é…ç½®
    task_timeout_seconds: int = 300
    phase_timeout_seconds: int = 1800
    
    # è´¨é‡é…ç½®
    min_confidence_threshold: float = 0.7
    require_review: bool = True
    
    # ç›‘æ§é…ç½®
    enable_monitoring: bool = True
    log_level: str = "INFO"


class TeamOrchestrator:
    """å›¢é˜Ÿç¼–æ’å™¨ - ä¸»å¸­çº§å‡çº§ç‰ˆ.
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æ™ºèƒ½ä»»åŠ¡åˆ†é…ï¼šåŸºäºèƒ½åŠ›åŒ¹é…å’Œè´Ÿè½½å‡è¡¡
    - å¹¶è¡Œæ‰§è¡Œï¼šæ”¯æŒé˜¶æ®µå†…å’Œé˜¶æ®µé—´å¹¶è¡Œ
    - è´¨é‡é—¨ç¦ï¼šå¤šå±‚è´¨é‡æ£€æŸ¥
    - æ•…éšœæ¢å¤ï¼šè‡ªåŠ¨é‡è¯•å’Œé™çº§
    - å®æ—¶ç›‘æ§ï¼šè¿›åº¦è·Ÿè¸ªå’Œå‘Šè­¦
    
    Attributes:
        agents: å›¢é˜Ÿæˆå‘˜
        config: ç¼–æ’é…ç½®
        workflow_engine: å·¥ä½œæµå¼•æ“
    """
    
    def __init__(
        self,
        agents: list[BaseAgent],
        config: OrchestratorConfig | None = None,
        workflow_engine: WorkflowEngine | None = None,
    ) -> None:
        """åˆå§‹åŒ–ç¼–æ’å™¨."""
        self._agents = {agent.id: agent for agent in agents}
        self._agents_by_role: dict[AgentRole, list[BaseAgent]] = {}
        
        for agent in agents:
            role = agent.profile.role
            if role not in self._agents_by_role:
                self._agents_by_role[role] = []
            self._agents_by_role[role].append(agent)
        
        self._config = config or OrchestratorConfig()
        self._workflow_engine = workflow_engine
        
        # çŠ¶æ€
        self._current_plan: ExecutionPlan | None = None
        self._task_queue: asyncio.Queue[Task] = asyncio.Queue()
        self._running_tasks: dict[TaskId, asyncio.Task] = {}
        
        # ç»Ÿè®¡
        self._stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "total_time": 0.0,
        }
    
    # =========================================================================
    # æ ¸å¿ƒæ–¹æ³•
    # =========================================================================
    
    async def execute_request(
        self,
        request: str,
        context: TaskContext | None = None,
    ) -> ExecutionPlan:
        """æ‰§è¡Œè¯·æ±‚ - ä¸»å…¥å£.
        
        æµç¨‹ï¼š
        1. åˆ†æè¯·æ±‚ï¼Œç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        2. æŒ‰é˜¶æ®µæ‰§è¡Œä»»åŠ¡
        3. è´¨é‡æ£€æŸ¥å’Œå®¡æŸ¥
        4. è¿”å›ç»“æœ
        
        Args:
            request: ç”¨æˆ·è¯·æ±‚
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            æ‰§è¡Œè®¡åˆ’å’Œç»“æœ
        """
        context = context or TaskContext()
        
        logger.info(f"æ”¶åˆ°è¯·æ±‚: {request[:100]}...")
        
        # 1. åˆ†æè¯·æ±‚ï¼Œç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        plan = await self._create_execution_plan(request, context)
        self._current_plan = plan
        
        logger.info(f"ç”Ÿæˆæ‰§è¡Œè®¡åˆ’: {plan.name}, {len(plan.phases)}ä¸ªé˜¶æ®µ")
        
        # 2. æ‰§è¡Œè®¡åˆ’
        plan.started_at = datetime.now()
        plan.status = "running"
        
        try:
            for phase_index, phase in enumerate(plan.phases):
                plan.current_phase_index = phase_index
                
                logger.info(f"å¼€å§‹é˜¶æ®µ {phase_index + 1}/{len(plan.phases)}: {phase.name}")
                
                # æ£€æŸ¥å…¥å£æ¡ä»¶
                if phase.entry_condition:
                    if not await self._check_condition(phase.entry_condition, plan, context):
                        logger.warning(f"é˜¶æ®µ {phase.name} å…¥å£æ¡ä»¶ä¸æ»¡è¶³ï¼Œè·³è¿‡")
                        phase.status = "skipped"
                        continue
                
                # æ‰§è¡Œé˜¶æ®µ
                phase.status = "running"
                phase_results = await self._execute_phase(phase, context)
                phase.results = phase_results
                
                # æ£€æŸ¥å‡ºå£æ¡ä»¶
                if phase.exit_condition:
                    if not await self._check_condition(phase.exit_condition, plan, context):
                        logger.error(f"é˜¶æ®µ {phase.name} å‡ºå£æ¡ä»¶ä¸æ»¡è¶³")
                        phase.status = "failed"
                        plan.status = "failed"
                        break
                
                phase.status = "completed"
                plan.results.extend(phase_results)
                
                # æ”¶é›†äº§å‡ºç‰©
                for result in phase_results:
                    plan.artifacts.extend(result.artifacts)
            
            if plan.status != "failed":
                plan.status = "completed"
                
        except Exception as e:
            logger.exception(f"æ‰§è¡Œè®¡åˆ’å¤±è´¥: {e}")
            plan.status = "failed"
        
        plan.completed_at = datetime.now()
        
        # æ›´æ–°ç»Ÿè®¡
        self._update_stats(plan)
        
        logger.info(f"æ‰§è¡Œè®¡åˆ’å®Œæˆ: {plan.status}, äº§å‡ºç‰©: {len(plan.artifacts)}ä¸ª")
        
        return plan
    
    async def _create_execution_plan(
        self,
        request: str,
        context: TaskContext,
    ) -> ExecutionPlan:
        """åˆ›å»ºæ‰§è¡Œè®¡åˆ’."""
        # ä½¿ç”¨é¡¹ç›®ç»ç†åˆ†æéœ€æ±‚
        pm = self._get_agent_by_role(AgentRole.PROJECT_MANAGER)
        
        if pm:
            # åˆ›å»ºéœ€æ±‚åˆ†æä»»åŠ¡
            analysis_task = Task(
                title="éœ€æ±‚åˆ†æ",
                description=request,
                type="requirement_analysis",
                priority=TaskPriority.HIGH,
                required_role=AgentRole.PROJECT_MANAGER,
            )
            
            analysis_result = await pm.execute(analysis_task, context)
            
            # åˆ›å»ºä»»åŠ¡åˆ†è§£ä»»åŠ¡
            decomposition_task = Task(
                title="ä»»åŠ¡åˆ†è§£",
                description=request,
                type="task_decomposition",
                priority=TaskPriority.HIGH,
                required_role=AgentRole.PROJECT_MANAGER,
            )
            
            decomposition_result = await pm.execute(decomposition_task, context)
        
        # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        plan = ExecutionPlan(
            id=f"plan_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            name=f"æ‰§è¡Œè®¡åˆ’: {request[:50]}...",
        )
        
        # åˆ›å»ºæ ‡å‡†é˜¶æ®µ
        plan.phases = self._create_standard_phases(request, context)
        
        return plan
    
    def _create_standard_phases(
        self,
        request: str,
        context: TaskContext,
    ) -> list[ExecutionPhase]:
        """åˆ›å»ºæ ‡å‡†æ‰§è¡Œé˜¶æ®µ."""
        phases = []
        
        # é˜¶æ®µ1: è®¾è®¡é˜¶æ®µ
        design_phase = ExecutionPhase(
            id="phase_design",
            name="è®¾è®¡é˜¶æ®µ",
            description="ç³»ç»Ÿè®¾è®¡å’Œæ¶æ„",
            tasks=[
                Task(
                    title="ç³»ç»Ÿæ¶æ„è®¾è®¡",
                    description=request,
                    type="architecture_design",
                    required_role=AgentRole.SYSTEM_ARCHITECT,
                    priority=TaskPriority.HIGH,
                ),
            ],
            parallel=False,
        )
        phases.append(design_phase)
        
        # é˜¶æ®µ2: å¼€å‘é˜¶æ®µ
        dev_phase = ExecutionPhase(
            id="phase_development",
            name="å¼€å‘é˜¶æ®µ",
            description="æ ¸å¿ƒåŠŸèƒ½å¼€å‘",
            tasks=[
                Task(
                    title="åç«¯å¼€å‘",
                    description=request,
                    type="backend_development",
                    required_role=AgentRole.BACKEND_ENGINEER,
                    priority=Task
                    priority=TaskPriority.HIGH,
                ),
                Task(
                    title="å‰ç«¯å¼€å‘",
                    description=request,
                    type="frontend_development",
                    required_role=AgentRole.FRONTEND_ENGINEER,
                    priority=TaskPriority.HIGH,
                ),
            ],
            parallel=True,  # å‰åç«¯å¯ä»¥å¹¶è¡Œ
            max_parallel=2,
        )
        phases.append(dev_phase)
        
        # é˜¶æ®µ3: æµ‹è¯•é˜¶æ®µ
        test_phase = ExecutionPhase(
            id="phase_testing",
            name="æµ‹è¯•é˜¶æ®µ",
            description="è´¨é‡ä¿è¯å’Œæµ‹è¯•",
            tasks=[
                Task(
                    title="å•å…ƒæµ‹è¯•",
                    description="ç¼–å†™å’Œæ‰§è¡Œå•å…ƒæµ‹è¯•",
                    type="unit_testing",
                    required_role=AgentRole.QA_ENGINEER,
                    priority=TaskPriority.HIGH,
                ),
                Task(
                    title="ä»£ç å®¡æŸ¥",
                    description="ä»£ç è´¨é‡å®¡æŸ¥",
                    type="code_review",
                    required_role=AgentRole.CODE_REVIEWER,
                    priority=TaskPriority.HIGH,
                ),
            ],
            parallel=True,
            entry_condition="development_completed",
        )
        phases.append(test_phase)
        
        # é˜¶æ®µ4: å®‰å…¨å®¡è®¡
        security_phase = ExecutionPhase(
            id="phase_security",
            name="å®‰å…¨å®¡è®¡é˜¶æ®µ",
            description="å®‰å…¨æ£€æŸ¥å’Œæ¼æ´æ‰«æ",
            tasks=[
                Task(
                    title="å®‰å…¨å®¡è®¡",
                    description="å®‰å…¨æ¼æ´æ£€æŸ¥",
                    type="security_audit",
                    required_role=AgentRole.SECURITY_ARCHITECT,
                    priority=TaskPriority.HIGH,
                ),
            ],
            parallel=False,
            entry_condition="testing_completed",
        )
        phases.append(security_phase)
        
        # é˜¶æ®µ5: éƒ¨ç½²é˜¶æ®µ
        deploy_phase = ExecutionPhase(
            id="phase_deployment",
            name="éƒ¨ç½²é˜¶æ®µ",
            description="CI/CDé…ç½®å’Œéƒ¨ç½²",
            tasks=[
                Task(
                    title="éƒ¨ç½²é…ç½®",
                    description="CI/CDå’Œéƒ¨ç½²é…ç½®",
                    type="deployment",
                    required_role=AgentRole.DEVOPS_ENGINEER,
                    priority=TaskPriority.MEDIUM,
                ),
            ],
            parallel=False,
            entry_condition="security_passed",
        )
        phases.append(deploy_phase)
        
        # é˜¶æ®µ6: æ–‡æ¡£é˜¶æ®µ
        doc_phase = ExecutionPhase(
            id="phase_documentation",
            name="æ–‡æ¡£é˜¶æ®µ",
            description="æŠ€æœ¯æ–‡æ¡£ç¼–å†™",
            tasks=[
                Task(
                    title="æŠ€æœ¯æ–‡æ¡£",
                    description="ç¼–å†™æŠ€æœ¯æ–‡æ¡£",
                    type="documentation",
                    required_role=AgentRole.TECH_WRITER,
                    priority=TaskPriority.LOW,
                ),
            ],
            parallel=False,
        )
        phases.append(doc_phase)
        
        return phases
    
    async def _execute_phase(
        self,
        phase: ExecutionPhase,
        context: TaskContext,
    ) -> list[TaskResult]:
        """æ‰§è¡Œé˜¶æ®µ."""
        results: list[TaskResult] = []
        
        if phase.parallel and len(phase.tasks) > 1:
            # å¹¶è¡Œæ‰§è¡Œ
            results = await self._execute_tasks_parallel(
                phase.tasks, 
                context,
                max_parallel=phase.max_parallel,
            )
        else:
            # ä¸²è¡Œæ‰§è¡Œ
            for task in phase.tasks:
                result = await self._execute_task(task, context)
                results.append(result)
                
                # å¦‚æœä»»åŠ¡å¤±è´¥ä¸”æ˜¯å…³é”®ä»»åŠ¡ï¼Œåœæ­¢æ‰§è¡Œ
                if not result.success and task.priority == TaskPriority.CRITICAL:
                    logger.error(f"å…³é”®ä»»åŠ¡å¤±è´¥: {task.title}")
                    break
        
        return results
    
    async def _execute_tasks_parallel(
        self,
        tasks: list[Task],
        context: TaskContext,
        max_parallel: int = 5,
    ) -> list[TaskResult]:
        """å¹¶è¡Œæ‰§è¡Œä»»åŠ¡."""
        semaphore = asyncio.Semaphore(max_parallel)
        
        async def execute_with_semaphore(task: Task) -> TaskResult:
            async with semaphore:
                return await self._execute_task(task, context)
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡çš„åç¨‹
        coroutines = [execute_with_semaphore(task) for task in tasks]
        
        # å¹¶è¡Œæ‰§è¡Œ
        results = await asyncio.gather(*coroutines, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        final_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                final_results.append(TaskResult(
                    task_id=tasks[i].id,
                    success=False,
                    error_message=str(result),
                ))
            else:
                final_results.append(result)
        
        return final_results
    
    async def _execute_task(
        self,
        task: Task,
        context: TaskContext,
    ) -> TaskResult:
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡."""
        logger.info(f"æ‰§è¡Œä»»åŠ¡: {task.title}")
        
        # åˆ†é…æ™ºèƒ½ä½“
        agent = await self._assign_agent(task)
        
        if not agent:
            logger.error(f"æ— æ³•ä¸ºä»»åŠ¡ {task.title} åˆ†é…æ™ºèƒ½ä½“")
            return TaskResult(
                task_id=task.id,
                success=False,
                error_message="æ— å¯ç”¨æ™ºèƒ½ä½“",
            )
        
        task.assigned_to = agent.id
        task.status = TaskStatus.IN_PROGRESS
        task.started_at = datetime.now()
        
        # æ‰§è¡Œä»»åŠ¡ï¼ˆå¸¦é‡è¯•ï¼‰
        result = await self._execute_with_retry(agent, task, context)
        
        task.completed_at = datetime.now()
        task.status = TaskStatus.COMPLETED if result.success else TaskStatus.FAILED
        task.result = result
        
        # å¦‚æœéœ€è¦å®¡æŸ¥
        if self._config.require_review and result.success:
            result = await self._request_review(result, context)
        
        return result
    
    async def _assign_agent(self, task: Task) -> BaseAgent | None:
        """åˆ†é…æ™ºèƒ½ä½“."""
        # ä¼˜å…ˆæŒ‰è§’è‰²åˆ†é…
        if task.required_role:
            agents = self._agents_by_role.get(task.required_role, [])
            if agents:
                # é€‰æ‹©è´Ÿè½½æœ€ä½çš„æ™ºèƒ½ä½“
                return self._select_least_loaded_agent(agents)
        
        # æŒ‰èƒ½åŠ›åŒ¹é…
        if task.required_capabilities:
            for agent in self._agents.values():
                if all(
                    agent.profile.has_capability(cap)
                    for cap in task.required_capabilities
                ):
                    return agent
        
        # è¿”å›ä»»æ„å¯ç”¨æ™ºèƒ½ä½“
        available_agents = [
            a for a in self._agents.values()
            if a.state.status == "idle"
        ]
        
        if available_agents:
            return available_agents[0]
        
        return None
    
    def _select_least_loaded_agent(
        self,
        agents: list[BaseAgent],
    ) -> BaseAgent:
        """é€‰æ‹©è´Ÿè½½æœ€ä½çš„æ™ºèƒ½ä½“."""
        # æŒ‰å½“å‰ä»»åŠ¡æ•°æ’åº
        sorted_agents = sorted(
            agents,
            key=lambda a: (
                a.state.current_task_id is not None,
                a.state.tasks_completed,
            ),
        )
        return sorted_agents[0]
    
    async def _execute_with_retry(
        self,
        agent: BaseAgent,
        task: Task,
        context: TaskContext,
    ) -> TaskResult:
        """å¸¦é‡è¯•çš„ä»»åŠ¡æ‰§è¡Œ."""
        last_error = None
        
        for attempt in range(self._config.max_retries):
            try:
                result = await asyncio.wait_for(
                    agent.execute(task, context),
                    timeout=self._config.task_timeout_seconds,
                )
                
                # æ£€æŸ¥ç½®ä¿¡åº¦
                if result.confidence_score >= self._config.min_confidence_threshold:
                    return result
                
                logger.warning(
                    f"ä»»åŠ¡ {task.title} ç½®ä¿¡åº¦ä¸è¶³: {result.confidence_score:.2f}, "
                    f"é‡è¯• {attempt + 1}/{self._config.max_retries}"
                )
                
            except asyncio.TimeoutError:
                last_error = "ä»»åŠ¡æ‰§è¡Œè¶…æ—¶"
                logger.warning(f"ä»»åŠ¡ {task.title} è¶…æ—¶, é‡è¯• {attempt + 1}/{self._config.max_retries}")
            
            except Exception as e:
                last_error = str(e)
                logger.warning(f"ä»»åŠ¡ {task.title} å¤±è´¥: {e}, é‡è¯• {attempt + 1}/{self._config.max_retries}")
            
            # ç­‰å¾…åé‡è¯•
            await asyncio.sleep(self._config.retry_delay_seconds * (attempt + 1))
        
        return TaskResult(
            task_id=task.id,
            success=False,
            error_message=f"é‡è¯•{self._config.max_retries}æ¬¡åä»å¤±è´¥: {last_error}",
        )
    
    async def _request_review(
        self,
        result: TaskResult,
        context: TaskContext,
    ) -> TaskResult:
        """è¯·æ±‚ä»£ç å®¡æŸ¥."""
        reviewer = self._get_agent_by_role(AgentRole.CODE_REVIEWER)
        
        if not reviewer or not result.artifacts:
            return result
        
        for artifact in result.artifacts:
            review_result = await reviewer.review(artifact, context)
            
            artifact.reviewed = True
            artifact.approved = review_result.approved
            artifact.review_comments = review_result.comments
            
            if not review_result.approved:
                result.warnings.append(f"å®¡æŸ¥æœªé€šè¿‡: {artifact.name}")
        
        return result
    
    async def _check_condition(
        self,
        condition: str,
        plan: ExecutionPlan,
        context: TaskContext,
    ) -> bool:
        """æ£€æŸ¥æ¡ä»¶."""
        # ç®€å•çš„æ¡ä»¶æ£€æŸ¥
        if condition == "development_completed":
            dev_phase = next(
                (p for p in plan.phases if p.id == "phase_development"),
                None,
            )
            return dev_phase is not None and dev_phase.status == "completed"
        
        elif condition == "testing_completed":
            test_phase = next(
                (p for p in plan.phases if p.id == "phase_testing"),
                None,
            )
            return test_phase is not None and test_phase.status == "completed"
        
        elif condition == "security_passed":
            security_phase = next(
                (p for p in plan.phases if p.id == "phase_security"),
                None,
            )
            if security_phase and security_phase.results:
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡å®‰å…¨é—®é¢˜
                for result in security_phase.results:
                    if result.success and not any("critical" in w.lower() for w in result.warnings):
                        return True
            return False
        
        return True
    
    def _get_agent_by_role(self, role: AgentRole) -> BaseAgent | None:
        """æŒ‰è§’è‰²è·å–æ™ºèƒ½ä½“."""
        agents = self._agents_by_role.get(role, [])
        return agents[0] if agents else None
    
    def _update_stats(self, plan: ExecutionPlan) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯."""
        for result in plan.results:
            self._stats["total_tasks"] += 1
            if result.success:
                self._stats["completed_tasks"] += 1
            else:
                self._stats["failed_tasks"] += 1
            self._stats["total_time"] += result.execution_time_seconds
    
    def get_stats(self) -> dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯."""
        return dict(self._stats)
    
    def get_status(self) -> dict[str, Any]:
        """è·å–å½“å‰çŠ¶æ€."""
        return {
            "current_plan": self._current_plan.id if self._current_plan else None,
            "plan_status": self._current_plan.status if self._current_plan else None,
            "agents": {
                agent_id: {
                    "name": agent.name,
                    "role": agent.profile.role.value,
                    "status": agent.state.status,
                    "current_task": agent.state.current_task_id,
                }
                for agent_id, agent in self._agents.items()
            },
            "stats": self._stats,
        }
    9. å›¢é˜Ÿæ¨¡å— (team.py) python å¤åˆ¶ä»£ç   """ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - å›¢é˜Ÿç»„è£…ä¸ç®¡ç†.

æä¾›å›¢é˜Ÿåˆ›å»ºå·¥å‚å’Œç®¡ç†åŠŸèƒ½ã€‚
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any

from .agents.base import BaseAgent
from .agents.experts.project_manager import ProjectManagerAgent
from .agents.experts.architect import SystemArchitectAgent
from .agents.experts.backend import BackendEngineerAgent
from .core.types import (
    AgentProfile,
    AgentRole,
    TaskContext,
)
from .orchestration.orchestrator import OrchestratorConfig, TeamOrchestrator

if TYPE_CHECKING:
    from .cognitive.memory import MemorySystem
    from .cognitive.reasoning import ReasoningEngine
    from .integration.llm import LLMClient
    from .tools.executor import ToolExecutor


logger = logging.getLogger(__name__)


@dataclass
class TeamConfig:
    """å›¢é˜Ÿé…ç½®."""
    
    # å›¢é˜Ÿç»„æˆ
    include_pm: bool = True
    include_architect: bool = True
    include_backend: bool = True
    include_frontend: bool = True
    include_fullstack: bool = False
    include_qa: bool = True
    include_security: bool = True
    include_devops: bool = True
    include_reviewer: bool = True
    include_tech_writer: bool = True
    
    # äººæ•°é…ç½®
    num_backend: int = 1
    num_frontend: int = 1
    num_qa: int = 1
    
    # ç¼–æ’é…ç½®
    orchestrator_config: OrchestratorConfig = field(
        default_factory=OrchestratorConfig
    )


class AgentTeam:
    """æ™ºèƒ½ä½“å›¢é˜Ÿ - ä¸»å¸­çº§å›¢é˜Ÿç®¡ç†.
    
    åŠŸèƒ½ï¼š
    - å›¢é˜Ÿç»„å»º
    - ä»»åŠ¡æ‰§è¡Œ
    - å›¢é˜Ÿåä½œ
    - çŠ¶æ€ç›‘æ§
    """
    
    def __init__(
        self,
        agents: list[BaseAgent],
        orchestrator: TeamOrchestrator,
        config: TeamConfig | None = None,
    ) -> None:
        """åˆå§‹åŒ–å›¢é˜Ÿ."""
        self._agents = {agent.id: agent for agent in agents}
        self._orchestrator = orchestrator
        self._config = config or TeamConfig()
        
        # æŒ‰è§’è‰²ç´¢å¼•
        self._agents_by_role: dict[AgentRole, list[BaseAgent]] = {}
        for agent in agents:
            role = agent.profile.role
            if role not in self._agents_by_role:
                self._agents_by_role[role] = []
            self._agents_by_role[role].append(agent)
        
        logger.info(f"å›¢é˜Ÿåˆå§‹åŒ–å®Œæˆï¼Œå…±{len(agents)}åæˆå‘˜")
    
    @property
    def members(self) -> list[BaseAgent]:
        """è·å–æ‰€æœ‰æˆå‘˜."""
        return list(self._agents.values())
    
    @property
    def size(self) -> int:
        """è·å–å›¢é˜Ÿå¤§å°."""
        return len(self._agents)
    
    def get_member(self, agent_id: str) -> BaseAgent | None:
        """è·å–æˆå‘˜."""
        return self._agents.get(agent_id)
    
    def get_members_by_role(self, role: AgentRole) -> list[BaseAgent]:
        """æŒ‰è§’è‰²è·å–æˆå‘˜."""
        return self._agents_by_role.get(role, [])
    
    async def execute(
        self,
        request: str,
        context: TaskContext | None = None,
    ) -> dict[str, Any]:
        """æ‰§è¡Œè¯·æ±‚.
        
        Args:
            request: ç”¨æˆ·è¯·æ±‚
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        logger.info(f"å›¢é˜Ÿå¼€å§‹æ‰§è¡Œè¯·æ±‚: {request[:100]}...")
        
        context = context or TaskContext()
        
        # é€šè¿‡ç¼–æ’å™¨æ‰§è¡Œ
        plan = await self._orchestrator.execute_request(request, context)
        
        return {
            "success": plan.status == "completed",
            "plan_id": plan.id,
            "status": plan.status,
            "phases_completed": sum(1 for p in plan.phases if p.status == "completed"),
            "total_phases": len(plan.phases),
            "artifacts": [
                {
                    "name": a.name,
                    "type": a.type.value,
                    "language": a.language,
                    "reviewed": a.reviewed,
                    "approved": a.approved,
                }
                for a in plan.artifacts
            ],
            "results_summary": {
                "total": len(plan.results),
                "success": sum(1 for r in plan.results if r.success),
                "failed": sum(1 for r in plan.results if not r.success),
            },
        }
    
    def get_status(self) -> dict[str, Any]:
        """è·å–å›¢é˜ŸçŠ¶æ€."""
        return {
            "team_size": self.size,
            "members": [
                {
                    "id": agent.id,
                    "name": agent.name,
                    "role": agent.profile.role.value,
                    "status": agent.state.status,
                    "tasks_completed": agent.state.tasks_completed,
                    "success_rate": agent.state.success_rate,
                }
                for agent in self.members
            ],
            "orchestrator": self._orchestrator.get_status(),
        }
    
    def print_team_info(self) -> None:
        """æ‰“å°å›¢é˜Ÿä¿¡æ¯."""
        print("\n" + "=" * 60)
        print("ğŸ† ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ")
        print("=" * 60)
        print(f"å›¢é˜Ÿè§„æ¨¡: {self.size} åæˆå‘˜\n")
        
        for role in AgentRole:
            members = self.get_members_by_role(role)
            if members:
                print(f"ğŸ“Œ {role.value}:")
                for member in members:
                    print(f"   - {member.name} (ä¸“ä¸šç­‰çº§: {member.profile.expertise_level.name})")
        
        print("=" * 60 + "\n")


def create_world_class_team(
    llm_client: LLMClient,
    reasoning_engine: ReasoningEngine | None = None,
    memory_system: MemorySystem | None = None,
    tool_executor: ToolExecutor | None = None,
    config: TeamConfig | None = None,
) -> AgentTeam:
    """åˆ›å»ºä¸–ç•Œçº§å›¢é˜Ÿ - å·¥å‚å‡½æ•°.
    
    åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„è§’è‰²ã€‚
    
    Args:
        llm_client: LLMå®¢æˆ·ç«¯
        reasoning_engine: æ¨ç†å¼•æ“ï¼ˆå¯é€‰ï¼‰
        memory_system: è®°å¿†ç³»ç»Ÿï¼ˆå¯é€‰ï¼‰
        tool_executor: å·¥å…·æ‰§è¡Œå™¨ï¼ˆå¯é€‰ï¼‰
        config: å›¢é˜Ÿé…ç½®ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        é…ç½®å®Œæˆçš„AgentTeamå®ä¾‹
    """
    config = config or TeamConfig()
    agents: list[BaseAgent] = []
    
    # åˆ›å»ºé¡¹ç›®ç»ç†
    if config.include_pm:
        pm = ProjectManagerAgent(
            llm_client=llm_client,
            reasoning_engine=reasoning_engine,
            memory_system=memory_system,
            tool_executor=tool_executor,
        )
        agents.append(pm)
        logger.info(f"åˆ›å»ºé¡¹ç›®ç»ç†: {pm.name}")
    
    # åˆ›å»ºç³»ç»Ÿæ¶æ„å¸ˆ
    if config.include_architect:
        architect = SystemArchitectAgent(
            llm_client=llm_client,
            reasoning_engine=reasoning_engine,
            memory_system=memory_system,
            tool_executor=tool_executor,
        )
        agents.append(architect)
        logger.info(f"åˆ›å»ºç³»ç»Ÿæ¶æ„å¸ˆ: {architect.name}")
    
    # åˆ›å»ºåç«¯å·¥ç¨‹å¸ˆ
    if config.include_backend:
        for i in range(config.num_backend):
            backend = BackendEngineerAgent(
                llm_client=llm_client,
                reasoning_engine=reasoning_engine,
                memory_system=memory_system,
                tool_executor=tool_executor,
            )
            # å¦‚æœæœ‰å¤šä¸ªï¼Œæ·»åŠ ç¼–å·
            if config.num_backend > 1:
                backend._profile.name = f"{backend._profile.name} #{i+1}"
            agents.append(backend)
            logger.info(f"åˆ›å»ºåç«¯å·¥ç¨‹å¸ˆ: {backend.name}")
    
    # åˆ›å»ºå‰ç«¯å·¥ç¨‹å¸ˆ
    if config.include_frontend:
        for i in range(config.num_frontend):
            frontend = create_frontend_engineer(
                llm_client, reasoning_engine, memory_system, tool_executor
            )
            if config.num_frontend > 1:
                frontend._profile.name = f"{frontend._profile.name} #{i+1}"
            agents.append(frontend)
            logger.info(f"åˆ›å»ºå‰ç«¯å·¥ç¨‹å¸ˆ: {frontend.name}")
    
    # åˆ›å»ºå…¨æ ˆå·¥ç¨‹å¸ˆ
    if config.include_fullstack:
        fullstack = create_fullstack_engineer(
            llm_client, reasoning_engine, memory_system, tool_executor
        )
        agents.append(fullstack)
        logger.info(f"åˆ›å»ºå…¨æ ˆå·¥ç¨‹å¸ˆ: {fullstack.name}")
    
    # åˆ›å»ºæµ‹è¯•å·¥ç¨‹å¸ˆ
    if config.include_qa:
        for i in range(config.num_qa):
            qa = create_qa_engineer(
                llm_client, reasoning_engine, memory_system, tool_executor
            )
            if config.num_qa > 1:
                qa._profile.name = f"{qa._profile.name} #{i+1}"
            agents.append(qa)
            logger.info(f"åˆ›å»ºæµ‹è¯•å·¥ç¨‹å¸ˆ: {qa.name}")
    
    # åˆ›å»ºå®‰å…¨æ¶æ„å¸ˆ
    if config.include_security:
        security = create_security_architect(
            llm_client, reasoning_engine, memory_system, tool_executor
        )
        agents.append(security)
        logger.info(f"åˆ›å»ºå®‰å…¨æ¶æ„å¸ˆ: {security.name}")
    
    # åˆ›å»ºDevOpså·¥ç¨‹å¸ˆ
    if config.include_devops:
        devops = create_devops_engineer(
            llm_client, reasoning_engine, memory_system, tool_executor
        )
        agents.append(devops)
        logger.info(f"åˆ›å»ºDevOpså·¥ç¨‹å¸ˆ: {devops.name}")
    
    # åˆ›å»ºä»£ç å®¡æŸ¥å‘˜
    if config.include_reviewer:
        reviewer = create_code_reviewer(
            llm_client, reasoning_engine, memory_system, tool_executor
        )
        agents.append(reviewer)
        logger.info(f"åˆ›å»ºä»£ç å®¡æŸ¥å‘˜: {reviewer.name}")
    
    # åˆ›å»ºæŠ€æœ¯æ–‡æ¡£å·¥ç¨‹å¸ˆ
    if config.include_tech_writer:
        writer = create_tech_writer(
            llm_client, reasoning_engine, memory_system, tool_executor
        )
        agents.append(writer)
        logger.info(f"åˆ›å»ºæŠ€æœ¯æ–‡æ¡£å·¥ç¨‹å¸ˆ: {writer.name}")
    
    # åˆ›å»ºç¼–æ’å™¨
    orchestrator = TeamOrchestrator(
        agents=agents,
        config=config.orchestrator_config,
    )
    
    # åˆ›å»ºå›¢é˜Ÿ
    team = AgentTeam(
        agents=agents,
        orchestrator=orchestrator,
        config=config,
    )
    
    logger.info(f"ä¸–ç•Œçº§å›¢é˜Ÿåˆ›å»ºå®Œæˆï¼Œå…± {team.size} åæˆå‘˜")
    
    return team


# =============================================================================
# è¾…åŠ©å·¥å‚å‡½æ•°
# =============================================================================

def create_frontend_engineer(
    llm_client: LLMClient,
    reasoning_engine: ReasoningEngine | None = None,
    memory_system: MemorySystem | None = None,
    tool_executor: ToolExecutor | None = None,
) -> BaseAgent:
    """åˆ›å»ºå‰ç«¯å·¥ç¨‹å¸ˆ."""
    from .core.types import (
        AgentCapability,
        AgentProfile,
        AgentRole,
        ExpertiseLevel,
        ToolType,
    )
    
    class FrontendEngineerAgent(BaseAgent):
        async def _execute_step(self, step, task, context):
            return {"result": "æ­¥éª¤å®Œæˆ"}
        
        async def _generate_final_output(self, task, context, plan, artifacts):
            return None
    
    profile = AgentProfile(
        name="èµ„æ·±å‰ç«¯å·¥ç¨‹å¸ˆ Emma",
        role=AgentRole.FRONTEND_ENGINEER,
        expertise_level=ExpertiseLevel.SENIOR,
        capabilities=[
            AgentCapability.CODE_GENERATION,
            AgentCapability.CODE_DEBUGGING,
            AgentCapability.UNIT_TESTING,
            AgentCapability.JAVASCRIPT_EXPERT,
            AgentCapability.TYPESCRIPT_EXPERT,
        ],
        system_prompt="""ä½ æ˜¯ä¸€ä½èµ„æ·±å‰ç«¯å·¥ç¨‹å¸ˆï¼Œç²¾é€šReactã€Vueç­‰ç°ä»£å‰ç«¯æ¡†æ¶ã€‚""",
        temperature=0.4,
        allowed_tools=[ToolType.CODE_EXECUTOR, ToolType.FILE_SYSTEM],
    )
    
    return FrontendEngineerAgent(
        profile=profile,
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        tool_executor=tool_executor,
    )


def create_fullstack_engineer(
    llm_client: LLMClient,
    reasoning_engine: ReasoningEngine | None = None,
    memory_system: MemorySystem | None = None,
    tool_executor: ToolExecutor | None = None,
) -> BaseAgent:
    """åˆ›å»ºå…¨æ ˆå·¥ç¨‹å¸ˆ."""
    from .core.types import AgentCapability, AgentProfile, AgentRole, ExpertiseLevel, ToolType
    
    class FullstackEngineerAgent(BaseAgent):
        async def _execute_step(self, step, task, context):
            return {"result": "æ­¥éª¤å®Œæˆ"}
        
        async def _generate_final_output(self, task, context, plan, artifacts):
            return None
    
    profile = AgentProfile(
        name="èµ„æ·±å…¨æ ˆå·¥ç¨‹å¸ˆ David",
        role=AgentRole.FULLSTACK_ENGINEER,
        expertise_level=ExpertiseLevel.SENIOR,
        capabilities=[
            AgentCapability.CODE_GENERATION,
            AgentCapability.API_DESIGN,
            AgentCapability.DATABASE_DESIGN,
            AgentCapability.PYTHON_EXPERT,
            AgentCapability.JAVASCRIPT_EXPERT,
        ],
        system_prompt="""ä½ æ˜¯ä¸€ä½èµ„æ·±å…¨æ ˆå·¥ç¨‹å¸ˆï¼Œèƒ½å¤Ÿç‹¬ç«‹å®Œæˆå‰åç«¯å¼€å‘ã€‚""",
        temperature=0.4,
    )
    
    return FullstackEngineerAgent(
        profile=profile,
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        tool_executor=tool_executor,
    )


def create_qa_engineer(
    llm_client: LLMClient,
    reasoning_engine: ReasoningEngine | None = None,
    memory_system: MemorySystem | None = None,
    tool_executor: ToolExecutor | None = None,
) -> BaseAgent:
    """åˆ›å»ºæµ‹è¯•å·¥ç¨‹å¸ˆ."""
    from .core.types import AgentCapability, AgentProfile, AgentRole, ExpertiseLevel, ToolType
    
    class QAEngineerAgent(BaseAgent):
        async def _execute_step(self, step, task, context):
            return {"result": "æ­¥éª¤å®Œæˆ"}
        
        async def _generate_final_output(self, task, context, plan, artifacts):
            return None
    
    profile = AgentProfile(
        name="æµ‹è¯•è´Ÿè´£äºº Lisa",
        role=AgentRole.QA_ENGINEER,
        expertise_level=ExpertiseLevel.SENIOR,
        capabilities=[
            AgentCapability.TEST_PLANNING,
            AgentCapability.TEST_CASE_DESIGN,
            AgentCapability.UNIT_TESTING,
            AgentCapability.INTEGRATION_TESTING,
            AgentCapability.E2E_TESTING,
            AgentCapability.PERFORMANCE_TESTING,
        ],
        system_prompt="""ä½ æ˜¯ä¸€ä½èµ„æ·±æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£åˆ¶å®šæµ‹è¯•ç­–ç•¥å’Œç¼–å†™è‡ªåŠ¨åŒ–æµ‹è¯•ã€‚""",
        temperature=0.3,
    )
    
    return QAEngineerAgent(
        profile=profile,
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        tool_executor=tool_executor,
    )


def create_security_architect(
    llm_client: LLMClient,
    reasoning_engine: ReasoningEngine | None = None,
    memory_system: MemorySystem | None = None,
    tool_executor: ToolExecutor | None = None,
) -> BaseAgent:
    """åˆ›å»ºå®‰å…¨æ¶æ„å¸ˆ."""
    from .core.types import AgentCapability, AgentProfile, AgentRole, ExpertiseLevel
    
    class SecurityArchitectAgent(BaseAgent):
        async def _execute_step(self, step, task, context):
            return {"result": "æ­¥éª¤å®Œæˆ"}
        
        async def _generate_final_output(self, task, context, plan, artifacts):
            return None
    
    profile = AgentProfile(
        name="å®‰å…¨æ¶æ„å¸ˆ James",
        role=AgentRole.SECURITY_ARCHITECT,
        expertise_level=ExpertiseLevel.PRINCIPAL,
        capabilities=[
            AgentCapability.SECURITY_ANALYSIS,
            AgentCapability.VULNERABILITY_ASSESSMENT,
            AgentCapability.SECURITY_AUDIT,
            AgentCapability.PENETRATION_TESTING,
        ],
        system_prompt="""ä½ æ˜¯ä¸€ä½èµ„æ·±å®‰å…¨æ¶æ„å¸ˆï¼Œè´Ÿè´£ç³»ç»Ÿå®‰å…¨è®¾è®¡å’Œæ¼æ´åˆ†æã€‚""",
        temperature=0.3,
    )
    
    return SecurityArchitectAgent(profile=profile,
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        tool_executor=tool_executor,
    )


def create_devops_engineer(
    llm_client: LLMClient,
    reasoning_engine: ReasoningEngine | None = None,
    memory_system: MemorySystem | None = None,
    tool_executor: ToolExecutor | None = None,
) -> BaseAgent:
    """åˆ›å»ºDevOpså·¥ç¨‹å¸ˆ."""
    from .core.types import AgentCapability, AgentProfile, AgentRole, ExpertiseLevel, ToolType
    
    class DevOpsEngineerAgent(BaseAgent):
        async def _execute_step(self, step, task, context):
            return {"result": "æ­¥éª¤å®Œæˆ"}
        
        async def _generate_final_output(self, task, context, plan, artifacts):
            return None
    
    profile = AgentProfile(
        name="DevOpsä¸“å®¶ Kevin",
        role=AgentRole.DEVOPS_ENGINEER,
        expertise_level=ExpertiseLevel.SENIOR,
        capabilities=[
            AgentCapability.CI_CD_PIPELINE,
            AgentCapability.CONTAINERIZATION,
            AgentCapability.ORCHESTRATION,
            AgentCapability.INFRASTRUCTURE_AS_CODE,
            AgentCapability.MONITORING,
        ],
        system_prompt="""ä½ æ˜¯ä¸€ä½èµ„æ·±DevOpså·¥ç¨‹å¸ˆï¼Œè´Ÿè´£CI/CDæµæ°´çº¿ã€å®¹å™¨åŒ–å’ŒåŸºç¡€è®¾æ–½ç®¡ç†ã€‚

ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
1. CI/CDï¼šGitHub Actions, GitLab CI, Jenkins
2. å®¹å™¨åŒ–ï¼šDocker, Docker Compose
3. ç¼–æ’ï¼šKubernetes, Helm
4. IaCï¼šTerraform, Ansible
5. ç›‘æ§ï¼šPrometheus, Grafana, ELK

å·¥ä½œåŸåˆ™ï¼š
- è‡ªåŠ¨åŒ–ä¸€åˆ‡å¯è‡ªåŠ¨åŒ–çš„æµç¨‹
- åŸºç¡€è®¾æ–½å³ä»£ç 
- å¯è§‚æµ‹æ€§ä¼˜å…ˆ
- å®‰å…¨å·¦ç§»
""",
        temperature=0.4,
        allowed_tools=[ToolType.TERMINAL, ToolType.FILE_SYSTEM, ToolType.GIT],
    )
    
    return DevOpsEngineerAgent(
        profile=profile,
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        tool_executor=tool_executor,
    )


def create_code_reviewer(
    llm_client: LLMClient,
    reasoning_engine: ReasoningEngine | None = None,
    memory_system: MemorySystem | None = None,
    tool_executor: ToolExecutor | None = None,
) -> BaseAgent:
    """åˆ›å»ºä»£ç å®¡æŸ¥å‘˜."""
    from .core.types import AgentCapability, AgentProfile, AgentRole, ExpertiseLevel
    
    class CodeReviewerAgent(BaseAgent):
        async def _execute_step(self, step, task, context):
            return {"result": "æ­¥éª¤å®Œæˆ"}
        
        async def _generate_final_output(self, task, context, plan, artifacts):
            return None
    
    profile = AgentProfile(
        name="ä»£ç å®¡æŸ¥ä¸“å®¶ Rachel",
        role=AgentRole.CODE_REVIEWER,
        expertise_level=ExpertiseLevel.STAFF,
        capabilities=[
            AgentCapability.CODE_REVIEW,
            AgentCapability.CODE_REFACTORING,
            AgentCapability.CODE_OPTIMIZATION,
            AgentCapability.SECURITY_ANALYSIS,
        ],
        system_prompt="""ä½ æ˜¯ä¸€ä½ä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œè´Ÿè´£ç¡®ä¿ä»£ç è´¨é‡å’Œæœ€ä½³å®è·µã€‚

å®¡æŸ¥æ ‡å‡†ï¼š
1. æ­£ç¡®æ€§ï¼šé€»è¾‘æ˜¯å¦æ­£ç¡®ï¼Œè¾¹ç•Œæ¡ä»¶æ˜¯å¦å¤„ç†
2. å¯è¯»æ€§ï¼šå‘½åæ˜¯å¦æ¸…æ™°ï¼Œç»“æ„æ˜¯å¦åˆç†
3. å¯ç»´æŠ¤æ€§ï¼šæ˜¯å¦æ˜“äºä¿®æ”¹å’Œæ‰©å±•
4. æ€§èƒ½ï¼šæ˜¯å¦æœ‰æ˜æ˜¾çš„æ€§èƒ½é—®é¢˜
5. å®‰å…¨ï¼šæ˜¯å¦æœ‰å®‰å…¨æ¼æ´
6. æµ‹è¯•ï¼šæ˜¯å¦æœ‰è¶³å¤Ÿçš„æµ‹è¯•è¦†ç›–

å®¡æŸ¥åŸåˆ™ï¼š
- å»ºè®¾æ€§åé¦ˆï¼Œè€Œéæ‰¹è¯„
- æŒ‡å‡ºé—®é¢˜çš„åŒæ—¶æä¾›è§£å†³æ–¹æ¡ˆ
- åŒºåˆ†å¿…é¡»ä¿®æ”¹å’Œå»ºè®®ä¿®æ”¹
- å¯¹å¥½çš„ä»£ç ç»™äºˆè‚¯å®š
""",
        temperature=0.3,
        collaboration_style="assertive",
        debate_skill=9,
    )
    
    return CodeReviewerAgent(
        profile=profile,
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        tool_executor=tool_executor,
    )


def create_tech_writer(
    llm_client: LLMClient,
    reasoning_engine: ReasoningEngine | None = None,
    memory_system: MemorySystem | None = None,
    tool_executor: ToolExecutor | None = None,
) -> BaseAgent:
    """åˆ›å»ºæŠ€æœ¯æ–‡æ¡£å·¥ç¨‹å¸ˆ."""
    from .core.types import AgentCapability, AgentProfile, AgentRole, ExpertiseLevel
    
    class TechWriterAgent(BaseAgent):
        async def _execute_step(self, step, task, context):
            return {"result": "æ­¥éª¤å®Œæˆ"}
        
        async def _generate_final_output(self, task, context, plan, artifacts):
            return None
    
    profile = AgentProfile(
        name="æŠ€æœ¯æ–‡æ¡£ä¸“å®¶ Nancy",
        role=AgentRole.TECH_WRITER,
        expertise_level=ExpertiseLevel.SENIOR,
        capabilities=[
            AgentCapability.DOCUMENTATION,
            AgentCapability.API_DOCUMENTATION,
        ],
        system_prompt="""ä½ æ˜¯ä¸€ä½æŠ€æœ¯æ–‡æ¡£ä¸“å®¶ï¼Œè´Ÿè´£ç¼–å†™æ¸…æ™°ã€å‡†ç¡®ã€æ˜“æ‡‚çš„æŠ€æœ¯æ–‡æ¡£ã€‚

æ–‡æ¡£ç±»å‹ï¼š
1. APIæ–‡æ¡£ï¼šæ¥å£è¯´æ˜ã€è¯·æ±‚å“åº”ç¤ºä¾‹
2. æ¶æ„æ–‡æ¡£ï¼šç³»ç»Ÿè®¾è®¡ã€ç»„ä»¶å…³ç³»
3. ç”¨æˆ·æŒ‡å—ï¼šä½¿ç”¨è¯´æ˜ã€æ“ä½œæ­¥éª¤
4. å¼€å‘æ–‡æ¡£ï¼šç¯å¢ƒæ­å»ºã€ä»£ç è§„èŒƒ
5. è¿ç»´æ–‡æ¡£ï¼šéƒ¨ç½²æµç¨‹ã€æ•…éšœå¤„ç†

å†™ä½œåŸåˆ™ï¼š
- ç®€æ´æ˜äº†ï¼Œé¿å…å†—ä½™
- ç»“æ„æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
- ç¤ºä¾‹ä¸°å¯Œï¼Œä¾¿äºç†è§£
- ä¿æŒæ›´æ–°ï¼Œä¸ä»£ç åŒæ­¥
""",
        temperature=0.5,
    )
    
    return TechWriterAgent(
        profile=profile,
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        tool_executor=tool_executor,
    )
    1.  ä½¿ç”¨ç¤ºä¾‹ (examples/usage.py)   """ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - ä½¿ç”¨ç¤ºä¾‹.

å±•ç¤ºå¦‚ä½•åˆ›å»ºå’Œä½¿ç”¨ä¸–ç•Œçº§æ™ºèƒ½ä½“å›¢é˜Ÿã€‚
"""

import asyncio
import logging
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)

logger = logging.getLogger(__name__)


async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå›¢é˜Ÿä½¿ç”¨."""
    
    # =========================================================================
    # 1. åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆç¤ºä¾‹ï¼‰
    # =========================================================================
    
    from chairman_agents.integration.llm import create_llm_client
    
    llm_client = create_llm_client(
        provider="openai",  # æˆ– "anthropic"
        model="gpt-4",
        api_key="your-api-key",
    )
    
    # =========================================================================
    # 2. åˆå§‹åŒ–è®¤çŸ¥ç»„ä»¶ï¼ˆå¯é€‰ä½†æ¨èï¼‰
    # =========================================================================
    
    from chairman_agents.cognitive.reasoning import ReasoningEngine
    from chairman_agents.cognitive.memory import MemorySystem
    
    # æ¨ç†å¼•æ“
    reasoning_engine = ReasoningEngine(
        llm_client=llm_client,
        default_strategy="chain_of_thought",
    )
    
    # è®°å¿†ç³»ç»Ÿ
    memory_system = MemorySystem(
        llm_client=llm_client,
        storage_path=Path("./data/memory"),
    )
    
    # =========================================================================
    # 3. åˆ›å»ºä¸–ç•Œçº§å›¢é˜Ÿ
    # =========================================================================
    
    from chairman_agents.team import (
        create_world_class_team,
        TeamConfig,
    )
    from chairman_agents.orchestration.orchestrator import OrchestratorConfig
    
    # å›¢é˜Ÿé…ç½®
    team_config = TeamConfig(
        include_pm=True,
        include_architect=True,
        include_backend=True,
        include_frontend=True,
        include_qa=True,
        include_security=True,
        include_devops=True,
        include_reviewer=True,
        include_tech_writer=True,
        num_backend=2,  # 2ååç«¯å·¥ç¨‹å¸ˆ
        num_frontend=1,
        num_qa=1,
        orchestrator_config=OrchestratorConfig(
            max_parallel_tasks=5,
            max_retries=3,
            min_confidence_threshold=0.7,
            require_review=True,
        ),
    )
    
    # åˆ›å»ºå›¢é˜Ÿ
    team = create_world_class_team(
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        config=team_config,
    )
    
    # æ‰“å°å›¢é˜Ÿä¿¡æ¯
    team.print_team_info()
    
    # =========================================================================
    # 4. æ‰§è¡Œé¡¹ç›®è¯·æ±‚
    # =========================================================================
    
    from chairman_agents.core.types import TaskContext
    
    # å®šä¹‰é¡¹ç›®ä¸Šä¸‹æ–‡
    context = TaskContext(
        project_name="ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ",
        project_description="ä¸€ä¸ªå®Œæ•´çš„ç”¨æˆ·ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒæ³¨å†Œã€ç™»å½•ã€æƒé™ç®¡ç†",
        tech_stack={
            "backend": ["Python", "FastAPI", "PostgreSQL"],
            "frontend": ["React", "TypeScript"],
            "infra": ["Docker", "Kubernetes"],
        },
        coding_standards={
            "python": {
                "formatter": "black",
                "linter": "ruff",
                "type_checker": "mypy",
            },
        },
        constraints=[
            "å¿…é¡»æ”¯æŒé«˜å¹¶å‘",
            "å¿…é¡»é€šè¿‡å®‰å…¨å®¡è®¡",
            "APIå“åº”æ—¶é—´<200ms",
        ],
    )
    
    # å‘èµ·è¯·æ±‚
    request = """
    è¯·å¼€å‘ä¸€ä¸ªç”¨æˆ·ç®¡ç†ç³»ç»Ÿï¼ŒåŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š
    
    1. ç”¨æˆ·æ³¨å†Œ
       - é‚®ç®±æ³¨å†Œ
       - æ‰‹æœºå·æ³¨å†Œ
       - å¯†ç å¼ºåº¦éªŒè¯
    
    2. ç”¨æˆ·ç™»å½•
       - è´¦å·å¯†ç ç™»å½•
       - JWTä»¤ç‰Œè®¤è¯
       - ç™»å½•å¤±è´¥é”å®š
    
    3. ç”¨æˆ·ä¿¡æ¯ç®¡ç†
       - æŸ¥çœ‹ä¸ªäººä¿¡æ¯
       - ä¿®æ”¹ä¸ªäººä¿¡æ¯
       - ä¿®æ”¹å¯†ç 
    
    4. æƒé™ç®¡ç†
       - è§’è‰²å®šä¹‰ï¼ˆç®¡ç†å‘˜ã€æ™®é€šç”¨æˆ·ï¼‰
       - æƒé™æ§åˆ¶
       - æ“ä½œå®¡è®¡æ—¥å¿—
    
    è¦æ±‚ï¼š
    - å®Œæ•´çš„åç«¯API
    - æ•°æ®åº“è®¾è®¡
    - å•å…ƒæµ‹è¯•
    - APIæ–‡æ¡£
    - éƒ¨ç½²é…ç½®
    """
    
    logger.info("å¼€å§‹æ‰§è¡Œé¡¹ç›®è¯·æ±‚...")
    
    # æ‰§è¡Œè¯·æ±‚
    result = await team.execute(request, context)
    
    # =========================================================================
    # 5. å¤„ç†ç»“æœ
    # =========================================================================
    
    logger.info("=" * 60)
    logger.info("æ‰§è¡Œç»“æœ")
    logger.info("=" * 60)
    
    print(f"\nâœ… æ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
    print(f"ğŸ“‹ è®¡åˆ’ID: {result['plan_id']}")
    print(f"ğŸ“Š é˜¶æ®µå®Œæˆ: {result['phases_completed']}/{result['total_phases']}")
    
    print(f"\nğŸ“¦ äº§å‡ºç‰© ({len(result['artifacts'])}ä¸ª):")
    for artifact in result['artifacts']:
        status = "âœ…" if artifact['approved'] else ("ğŸ”" if artifact['reviewed'] else "â³")
        print(f"   {status} {artifact['name']} ({artifact['type']})")
    
    print(f"\nğŸ“ˆ ä»»åŠ¡ç»Ÿè®¡:")
    summary = result['results_summary']
    print(f"   æ€»ä»»åŠ¡: {summary['total']}")
    print(f"   æˆåŠŸ: {summary['success']}")
    print(f"   å¤±è´¥: {summary['failed']}")
    
    # è·å–å›¢é˜ŸçŠ¶æ€
    team_status = team.get_status()
    print(f"\nğŸ‘¥ å›¢é˜ŸçŠ¶æ€:")
    for member in team_status['members']:
        print(f"   - {member['name']}: {member['status']}, å®Œæˆä»»åŠ¡: {member['tasks_completed']}")
    
    # =========================================================================
    # 6. ä¿å­˜è®°å¿†
    # =========================================================================
    
    memory_system.save_to_disk()
    logger.info("è®°å¿†å·²ä¿å­˜")
    
    return result


async def demo_debate():
    """æ¼”ç¤ºè¾©è®ºåŠŸèƒ½."""
    
    from chairman_agents.integration.llm import create_llm_client
    from chairman_agents.team import create_world_class_team, TeamConfig
    from chairman_agents.collaboration.debate import DebateSystem, DebateTopic
    
    # åˆ›å»ºå›¢é˜Ÿ
    llm_client = create_llm_client(provider="openai", model="gpt-4")
    team = create_world_class_team(llm_client=llm_client)
    
    # åˆ›å»ºè¾©è®ºç³»ç»Ÿ
    debate_system = DebateSystem(max_rounds=3)
    
    # å®šä¹‰è¾©è®ºä¸»é¢˜
    topic = DebateTopic(
        id="tech_choice_001",
        title="æ•°æ®åº“é€‰å‹ï¼šPostgreSQL vs MongoDB",
        description="ä¸ºç”¨æˆ·ç®¡ç†ç³»ç»Ÿé€‰æ‹©åˆé€‚çš„æ•°æ®åº“",
        positions=["PostgreSQL", "MongoDB"],
        evaluation_criteria=[
            "æ•°æ®ä¸€è‡´æ€§",
            "æŸ¥è¯¢æ€§èƒ½",
            "æ‰©å±•æ€§",
            "è¿ç»´æˆæœ¬",
            "å›¢é˜Ÿç†Ÿæ‚‰åº¦",
        ],
        constraints=[
            "å¿…é¡»æ”¯æŒäº‹åŠ¡",
            "æ•°æ®é‡é¢„è®¡1000ä¸‡ç”¨æˆ·",
        ],
    )
    
    # é€‰æ‹©è¾©è®ºå‚ä¸è€…
    architect = team.get_members_by_role(AgentRole.SYSTEM_ARCHITECT)[0]
    backend = team.get_members_by_role(AgentRole.BACKEND_ENGINEER)[0]
    
    # å¼€å§‹è¾©è®º
    result = await debate_system.start_debate(
        topic=topic,
        participants=[architect, backend],
    )
    
    print(f"\nğŸ¯ è¾©è®ºç»“æœ:")
    print(f"   è·èƒœç«‹åœº: {result.winning_position}")
    print(f"   å…±è¯†è¾¾æˆ: {'æ˜¯' if result.consensus_reached else 'å¦'}")
    print(f"   æœ€ç»ˆå†³ç­–: {result.final_decision}")
    print(f"   å†³ç­–ç†ç”±: {result.decision_rationale}")


async def demo_consensus():
    """æ¼”ç¤ºå…±è¯†æœºåˆ¶."""
    
    from chairman_agents.integration.llm import create_llm_client
    from chairman_agents.team import create_world_class_team
    from chairman_agents.collaboration.consensus import ConsensusEngine, Proposal
    
    # åˆ›å»ºå›¢é˜Ÿ
    llm_client = create_llm_client(provider="openai", model="gpt-4")
    team = create_world_class_team(llm_client=llm_client)
    
    # åˆ›å»ºå…±è¯†å¼•æ“
    consensus_engine = ConsensusEngine(
        default_threshold=0.6,
        max_negotiation_rounds=3,
    )
    
    # å®šä¹‰ææ¡ˆ
    proposal = Proposal(
        id="proposal_001",
        title="é‡‡ç”¨å¾®æœåŠ¡æ¶æ„",
        description="å°†ç³»ç»Ÿæ‹†åˆ†ä¸ºå¤šä¸ªå¾®æœåŠ¡ï¼Œæé«˜å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§",
        options=["approve", "reject"],
        pros=[
            "æ›´å¥½çš„å¯æ‰©å±•æ€§",
            "ç‹¬ç«‹éƒ¨ç½²å’Œå‡çº§",
            "æŠ€æœ¯æ ˆçµæ´»æ€§",
        ],
        cons=[
            "è¿ç»´å¤æ‚åº¦å¢åŠ ",
            "ç½‘ç»œå¼€é”€å¢åŠ ",
            "åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†å›°éš¾",
        ],
    )
    
    # å‘èµ·å…±è¯†æŠ•ç¥¨
    result = await consensus_engine.reach_consensus(
        proposal=proposal,
        participants=team.members,
        mechanism="iterative",  # è¿­ä»£åå•†
        threshold=0.7,
    )
    
    print(f"\nğŸ—³ï¸ å…±è¯†ç»“æœ:")
    print(f"   å…±è¯†è¾¾æˆ: {'æ˜¯' if result.consensus_reached else 'å¦'}")
    print(f"   è·èƒœé€‰é¡¹: {result.winning_option}")
    print(f"   æ”¯æŒç‡: {result.approval_rate:.1%}")
    print(f"   åå•†è½®æ•°: {result.rounds_needed}")


if __name__ == "__main__":
    # è¿è¡Œä¸»ç¤ºä¾‹
    asyncio.run(main())
    
    # æˆ–è¿è¡Œè¾©è®ºæ¼”ç¤º
    # asyncio.run(demo_debate())
    
    # æˆ–è¿è¡Œå…±è¯†æ¼”ç¤º
    # asyncio.run(demo_consensus())
    ğŸ“Š ä¸»å¸­çº§å›¢é˜Ÿç³»ç»Ÿæ€»ç»“ å¤åˆ¶ä»£ç   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ† ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿç³»ç»Ÿ                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ“ æ¨¡å—æ¶æ„                                                                 â”‚
â”‚  â”œâ”€â”€ core/           æ ¸å¿ƒç±»å‹å®šä¹‰ï¼ˆ18è§’è‰²ã€35èƒ½åŠ›ï¼‰                          â”‚
â”‚  â”œâ”€â”€ cognitive/      è®¤çŸ¥èƒ½åŠ›ï¼ˆæ¨ç†ã€è®°å¿†ã€åæ€ï¼‰                            â”‚
â”‚  â”œâ”€â”€ agents/         æ™ºèƒ½ä½“å®ç°ï¼ˆ10+ä¸“å®¶è§’è‰²ï¼‰                               â”‚
â”‚  â”œâ”€â”€ collaboration/  åä½œæœºåˆ¶ï¼ˆè¾©è®ºã€å…±è¯†ã€ç»“å¯¹ï¼‰                            â”‚
â”‚  â”œâ”€â”€ orchestration/  ä»»åŠ¡ç¼–æ’ï¼ˆæ™ºèƒ½åˆ†é…ã€å¹¶è¡Œæ‰§è¡Œï¼‰                          â”‚
â”‚  â”œâ”€â”€ workflow/       å·¥ä½œæµå¼•æ“ï¼ˆ6é˜¶æ®µæ ‡å‡†æµç¨‹ï¼‰                             â”‚
â”‚  â””â”€â”€ team.py         å›¢é˜Ÿå·¥å‚ï¼ˆä¸€é”®åˆ›å»ºä¸–ç•Œçº§å›¢é˜Ÿï¼‰                          â”‚
â”‚                                                                             â”‚
â”‚  ğŸ‘¥ å›¢é˜Ÿæˆå‘˜                                                                 â”‚
â”‚  â”œâ”€â”€ é¡¹ç›®ç»ç†        éœ€æ±‚åˆ†æã€ä»»åŠ¡æ‹†åˆ†ã€è¿›åº¦ç®¡ç†                            â”‚
â”‚  â”œâ”€â”€ ç³»ç»Ÿæ¶æ„å¸ˆ      æ¶æ„è®¾è®¡ã€æŠ€æœ¯é€‰å‹ã€APIè®¾è®¡                             â”‚
â”‚  â”œâ”€â”€ åç«¯å·¥ç¨‹å¸ˆ      åç«¯å¼€å‘ã€APIå®ç°ã€æ•°æ®åº“                               â”‚
â”‚  â”œâ”€â”€ å‰ç«¯å·¥ç¨‹å¸ˆ      å‰ç«¯å¼€å‘ã€UIå®ç°ã€ç”¨æˆ·ä½“éªŒ                              â”‚
â”‚  â”œâ”€â”€ æµ‹è¯•å·¥ç¨‹å¸ˆ      æµ‹è¯•ç­–ç•¥ã€è‡ªåŠ¨åŒ–æµ‹è¯•ã€è´¨é‡ä¿è¯                          â”‚
â”‚  â”œâ”€â”€ å®‰å…¨æ¶æ„å¸ˆ      å®‰å…¨è®¾è®¡ã€æ¼æ´åˆ†æã€å®‰å…¨å®¡è®¡                            â”‚
â”‚  â”œâ”€â”€ DevOpså·¥ç¨‹å¸ˆ    CI/CDã€å®¹å™¨åŒ–ã€åŸºç¡€è®¾æ–½                                 â”‚
â”‚  â”œâ”€â”€ ä»£ç å®¡æŸ¥å‘˜      ä»£ç è´¨é‡ã€æœ€ä½³å®è·µã€è§„èŒƒæ£€æŸ¥                            â”‚
â”‚  â””â”€â”€ æŠ€æœ¯æ–‡æ¡£å¸ˆ      æ–‡æ¡£ç¼–å†™ã€APIæ–‡æ¡£ã€ç”¨æˆ·æŒ‡å—                             â”‚
â”‚                                                                             â”‚
â”‚  ğŸ§  è®¤çŸ¥èƒ½åŠ›                                                                 â”‚
â”‚  â”œâ”€â”€ æ€ç»´é“¾æ¨ç†      é€æ­¥åˆ†æé—®é¢˜                                            â”‚
â”‚  â”œâ”€â”€ æ€ç»´æ ‘æ¨ç†      æ¢ç´¢å¤šä¸ªæ¨ç†è·¯å¾„                                        â”‚
â”‚  â”œâ”€â”€ è‡ªæˆ‘åæ€        æ£€æŸ¥å’Œæ”¹è¿›è¾“å‡º                                          â”‚
â”‚  â”œâ”€â”€ çŸ­æœŸè®°å¿†        å½“å‰ä¼šè¯å·¥ä½œè®°å¿†                                        â”‚
â”‚  â”œâ”€â”€ é•¿æœŸè®°å¿†        æŒä¹…åŒ–é‡è¦ä¿¡æ¯                                          â”‚
â”‚  â””â”€â”€ ç»éªŒå­¦ä¹         ä»æ‰§è¡Œä¸­å­¦ä¹                                             â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¤ åä½œæœºåˆ¶                                                                 â”‚
â”‚  â”œâ”€â”€ æŠ€æœ¯è¾©è®º        å¤šæ™ºèƒ½ä½“è§‚ç‚¹ç¢°æ’                                        â”‚
â”‚  â”œâ”€â”€ å…±è¯†æŠ•ç¥¨        æ°‘ä¸»å†³ç­–æœºåˆ¶                                            â”‚
â”‚  â”œâ”€â”€ ä»£ç å®¡æŸ¥        è´¨é‡æŠŠå…³                                                â”‚
â”‚  â””â”€â”€ è¿­ä»£åå•†        è¾¾æˆå¦¥åæ–¹æ¡ˆ                                            â”‚
â”‚                                                                             â”‚
â”‚  ğŸ“‹ æ‰§è¡Œæµç¨‹                                                                 â”‚
â”‚  1. éœ€æ±‚åˆ†æ â†’ 2. æ¶æ„è®¾è®¡ â†’ 3. å¹¶è¡Œå¼€å‘ â†’                                  â”‚
â”‚  4. ä»£ç å®¡æŸ¥ â†’ 5. æµ‹è¯•éªŒè¯ â†’ 6. å®‰å…¨å®¡è®¡ â†’                                  â”‚
â”‚  7. éƒ¨ç½²é…ç½® â†’ 8. æ–‡æ¡£ç¼–å†™                                                  â”‚
â”‚                                                                             â”‚
â”‚  âœ… è´¨é‡ä¿è¯                                                                 â”‚
â”‚  â”œâ”€â”€ ç½®ä¿¡åº¦æ£€æŸ¥      æœ€ä½0.7ç½®ä¿¡åº¦                                           â”‚
â”‚  â”œâ”€â”€ å¤šé‡å®¡æŸ¥        ä»£ç +å®‰å…¨+æ¶æ„å®¡æŸ¥                                      â”‚
â”‚  â”œâ”€â”€ è‡ªåŠ¨é‡è¯•        å¤±è´¥è‡ªåŠ¨é‡è¯•3æ¬¡                                         â”‚
â”‚  â””â”€â”€ é˜¶æ®µé—¨ç¦        å…¥å£/å‡ºå£æ¡ä»¶æ£€æŸ¥                                       â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ğŸš€ å¿«é€Ÿå¼€å§‹ python å¤åˆ¶ä»£ç   # ä¸€è¡Œä»£ç åˆ›å»ºä¸–ç•Œçº§å›¢é˜Ÿ
from chairman_agents.team import create_world_class_team
from chairman_agents.integration.llm import create_llm_client

# åˆå§‹åŒ–
llm = create_llm_client(provider="openai", model="gpt-4", api_key="...")
team = create_world_class_team(llm_client=llm)

# æ‰§è¡Œé¡¹ç›®
result = await team.execute("å¼€å‘ä¸€ä¸ªç”¨æˆ·ç®¡ç†ç³»ç»Ÿ")

# æŸ¥çœ‹ç»“æœ
print(f"æˆåŠŸ: {result['success']}")
print(f"äº§å‡ºç‰©: {len(result['artifacts'])}ä¸ª")





"""ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - LLMé›†æˆå±‚.

æ”¯æŒå¤šç§LLMæä¾›å•†ï¼š
- Anthropic (Claude)
- æœ¬åœ°æ¨¡å‹
"""

from __future__ import annotations

import asyncio
import logging
import os
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    from collections.abc import AsyncIterator


logger = logging.getLogger(__name__)


@dataclass
class LLMConfig:
    """LLMé…ç½®."""
    
    provider: str = "openai"
    model: str = "gpt-4"
    api_key: str | None = None
    api_base: str | None = None
    
    # ç”Ÿæˆå‚æ•°
    temperature: float = 0.7
    max_tokens: int = 4096
    top_p: float = 1.0
    frequency_penalty: float = 0.0
    presence_penalty: float = 0.0
    
    # é‡è¯•é…ç½®
    max_retries: int = 3
    retry_delay: float = 1.0
    timeout: float = 120.0
    
    # é€Ÿç‡é™åˆ¶
    requests_per_minute: int = 60
    tokens_per_minute: int = 90000


@dataclass
class LLMResponse:
    """LLMå“åº”."""
    
    content: str = ""
    model: str = ""
    
    # Tokenä½¿ç”¨
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    
    # å…ƒæ•°æ®
    finish_reason: str = ""
    latency_ms: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)


class BaseLLMClient(ABC):
    """LLMå®¢æˆ·ç«¯åŸºç±»."""
    
    def __init__(self, config: LLMConfig) -> None:
        """åˆå§‹åŒ–."""
        self._config = config
        self._request_count = 0
        self._token_count = 0
    
    @abstractmethod
    async def generate(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        temperature: float | None = None,
        max_tokens: int | None = None,
        **kwargs: Any,
    ) -> str:
        """ç”Ÿæˆå“åº”."""
        pass
    
    @abstractmethod
    async def generate_with_metadata(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        **kwargs: Any,
    ) -> LLMResponse:
        """ç”Ÿæˆå“åº”ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰."""
        pass
    
    @abstractmethod
    async def stream(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        **kwargs: Any,
    ) -> AsyncIterator[str]:
        """æµå¼ç”Ÿæˆ."""
        pass
    
    def get_stats(self) -> dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯."""
        return {
            "request_count": self._request_count,
            "token_count": self._token_count,
        }


class OpenAIClient(BaseLLMClient):
    """OpenAIå®¢æˆ·ç«¯."""
    
    def __init__(self, config: LLMConfig) -> None:
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯."""
        super().__init__(config)
        
        try:
            import openai
            self._client = openai.AsyncOpenAI(
                api_key=config.api_key or os.getenv("OPENAI_API_KEY"),
                base_url=config.api_base,
                timeout=config.timeout,
                max_retries=config.max_retries,
            )
        except ImportError:
            raise ImportError("è¯·å®‰è£…openai: pip install openai")
    
    async def generate(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        temperature: float | None = None,
        max_tokens: int | None = None,
        **kwargs: Any,
    ) -> str:
        """ç”Ÿæˆå“åº”."""
        response = await self.generate_with_metadata(
            prompt=prompt,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs,
        )
        return response.content
    
    async def generate_with_metadata(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        temperature: float | None = None,
        max_tokens: int | None = None,
        **kwargs: Any,
    ) -> LLMResponse:
        """ç”Ÿæˆå“åº”ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰."""
        start_time = datetime.now()
        
        # æ„å»ºæ¶ˆæ¯
        if messages is None:
            messages = []
        if prompt:
            messages.append({"role": "user", "content": prompt})
        
        # è°ƒç”¨API
        response = await self._client.chat.completions.create(
            model=self._config.model,
            messages=messages,
            temperature=temperature or self._config.temperature,
            max_tokens=max_tokens or self._config.max_tokens,
            top_p=self._config.top_p,
            frequency_penalty=self._config.frequency_penalty,
            presence_penalty=self._config.presence_penalty,
            **kwargs,
        )
        
        # æ›´æ–°ç»Ÿè®¡
        self._request_count += 1
        self._token_count += response.usage.total_tokens if response.usage else 0
        
        latency = (datetime.now() - start_time).total_seconds() * 1000
        
        return LLMResponse(
            content=response.choices[0].message.content or "",
            model=response.model,
            prompt_tokens=response.usage.prompt_tokens if response.usage else 0,
            completion_tokens=response.usage.completion_tokens if response.usage else 0,
            total_tokens=response.usage.total_tokens if response.usage else 0,
            finish_reason=response.choices[0].finish_reason or "",
            latency_ms=latency,
        )
    
    async def stream(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        **kwargs: Any,
    ) -> AsyncIterator[str]:
        """æµå¼ç”Ÿæˆ."""
        if messages is None:
            messages = []
        if prompt:
            messages.append({"role": "user", "content": prompt})
        
        stream = await self._client.chat.completions.create(
            model=self._config.model,
            messages=messages,
            temperature=self._config.temperature,
            max_tokens=self._config.max_tokens,
            stream=True,
            **kwargs,
        )
        
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content


class AnthropicClient(BaseLLMClient):
    """Anthropic (Claude)å®¢æˆ·ç«¯."""
    
    def __init__(self, config: LLMConfig) -> None:
        """åˆå§‹åŒ–Anthropicå®¢æˆ·ç«¯."""
        super().__init__(config)
        
        try:
            import anthropic
            self._client = anthropic.AsyncAnthropic(
                api_key=config.api_key or os.getenv("ANTHROPIC_API_KEY"),
                timeout=config.timeout,
                max_retries=config.max_retries,
            )
        except ImportError:
            raise ImportError("è¯·å®‰è£…anthropic: pip install anthropic")
    
    async def generate(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        temperature: float | None = None,
        max_tokens: int | None = None,
        **kwargs: Any,
    ) -> str:
        """ç”Ÿæˆå“åº”."""
        response = await self.generate_with_metadata(
            prompt=prompt,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs,
        )
        return response.content
    
    async def generate_with_metadata(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        temperature: float | None = None,
        max_tokens: int | None = None,
        **kwargs: Any,
    ) -> LLMResponse:
        """ç”Ÿæˆå“åº”ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰."""
        start_time = datetime.now()
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        anthropic_messages = []
        system_message = None
        
        if messages:
            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    anthropic_messages.append({
                        "role": msg["role"],
                        "content": msg["content"],
                    })
        
        if prompt:
            anthropic_messages.append({"role": "user", "content": prompt})
        
        # è°ƒç”¨API
        response = await self._client.messages.create(
            model=self._config.model,
            messages=anthropic_messages,
            system=system_message or "",
            temperature=temperature or self._config.temperature,
            max_tokens=max_tokens or self._config.max_tokens,
            **kwargs,
        )
        
        # æ›´æ–°ç»Ÿè®¡
        self._request_count += 1
        total_tokens = response.usage.input_tokens + response.usage.output_tokens
        self._token_count += total_tokens
        
        latency = (datetime.now() - start_time).total_seconds() * 1000
        
        content = ""
        if response.content:
            content = response.content[0].text
        
        return LLMResponse(
            content=content,
            model=response.model,
            prompt_tokens=response.usage.input_tokens,
            completion_tokens=response.usage.output_tokens,
            total_tokens=total_tokens,
            finish_reason=response.stop_reason or "",
            latency_ms=latency,
        )
    
    async def stream(
        self,
        prompt: str | None = None,
        messages: list[dict[str, str]] | None = None,
        **kwargs: Any,
    ) -> AsyncIterator[str]:
        """æµå¼ç”Ÿæˆ."""
        anthropic_messages = []
        system_message = None
        
        if messages:
            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    anthropic_messages.append({
                        "role": msg["role"],
                        "content": msg["content"],
                    })
        
        if prompt:
            anthropic_messages.append({"role": "user", "content": prompt})
        
        async with self._client.messages.stream(
            model=self._config.model,
            messages=anthropic_messages,
            system=system_message or "",
            max_tokens=self._config.max_tokens,
            **kwargs,
        ) as stream:
            async for text in stream.text_stream:
                yield text


class LLMRouter:
    """LLMè·¯ç”±å™¨ - æ™ºèƒ½é€‰æ‹©å’Œæ•…éšœè½¬ç§»."""
    
    def __init__(
        self,
        clients: list[BaseLLMClient],
        strategy: str = "primary",  # primary, round_robin, least_loaded
    ) -> None:
        """åˆå§‹åŒ–è·¯ç”±å™¨."""
        self._clients = clients
        self._strategy = strategy
        self._current_index = 0
        self._failures: dict[int, int] = {}
    
    async def generate(self, **kwargs: Any) -> str:
        """è·¯ç”±ç”Ÿæˆè¯·æ±‚."""
        client = self._select_client()
        
        try:
            return await client.generate(**kwargs)
        except Exception as e:
            logger.warning(f"LLMè°ƒç”¨å¤±è´¥: {e}, å°è¯•æ•…éšœè½¬ç§»")
            return await self._failover_generate(**kwargs)
    
    def _select_client(self) -> BaseLLMClient:
        """é€‰æ‹©å®¢æˆ·ç«¯."""
        if self._strategy == "primary":
            return self._clients[0]
        elif self._strategy == "round_robin":
            client = self._clients[self._current_index]
            self._current_index = (self._current_index + 1) % len(self._clients)
            return client
        else:
            return self._clients[0]
    
    async def _failover_generate(self, **kwargs: Any) -> str:
        """æ•…éšœè½¬ç§»ç”Ÿæˆ."""
        for i, client in enumerate(self._clients[1:], 1):
            try:
                return await client.generate(**kwargs)
            except Exception as e:
                logger.warning(f"å¤‡ç”¨LLM {i} ä¹Ÿå¤±è´¥: {e}")
                continue
        
        raise RuntimeError("æ‰€æœ‰LLMå®¢æˆ·ç«¯éƒ½å¤±è´¥äº†")


# =============================================================================
# å·¥å‚å‡½æ•°
# =============================================================================

def create_llm_client(
    provider: str = "openai",
    model: str | None = None,
    api_key: str | None = None,
    **kwargs: Any,
) -> BaseLLMClient:
    """åˆ›å»ºLLMå®¢æˆ·ç«¯.
    
    Args:
        provider: æä¾›å•† (openai, anthropic)
        model: æ¨¡å‹åç§°
        api_key: APIå¯†é’¥
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        LLMå®¢æˆ·ç«¯å®ä¾‹
    """
    # é»˜è®¤æ¨¡å‹
    default_models = {
        "openai": "gpt-4",
        "anthropic": "claude-3-opus-20240229",
    }
    
    config = LLMConfig(
        provider=provider,
        model=model or default_models.get(provider, "gpt-4"),
        api_key=api_key,
        **kwargs,
    )
    
    if provider == "openai":
        return OpenAIClient(config)
    elif provider == "anthropic":
        return AnthropicClient(config)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")


# ç±»å‹åˆ«åï¼Œæ–¹ä¾¿ä½¿ç”¨
LLMClient = BaseLLMClient
    1.  å·¥å…·æ‰§è¡Œå™¨ (tools/executor.py)   """ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - å·¥å…·æ‰§è¡Œå™¨.

æä¾›æ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨çš„å„ç§å·¥å…·ï¼š
- ä»£ç æ‰§è¡Œå™¨
- æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
- Gitæ“ä½œ
- ç»ˆç«¯å‘½ä»¤
- æœç´¢å¼•æ“
"""

from __future__ import annotations

import asyncio
import logging
import os
import subprocess
import tempfile
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any

from ..core.types import ToolType

if TYPE_CHECKING:
    pass


logger = logging.getLogger(__name__)


@dataclass
class ToolResult:
    """å·¥å…·æ‰§è¡Œç»“æœ."""
    
    success: bool = False
    output: str = ""
    error: str | None = None
    
    # å…ƒæ•°æ®
    tool_type: ToolType | None = None
    execution_time_ms: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)


class BaseTool(ABC):
    """å·¥å…·åŸºç±»."""
    
    tool_type: ToolType
    
    @abstractmethod
    async def execute(
        self,
        action: str,
        params: dict[str, Any],
    ) -> ToolResult:
        """æ‰§è¡Œå·¥å…·æ“ä½œ."""
        pass


class CodeExecutorTool(BaseTool):
    """ä»£ç æ‰§è¡Œå™¨å·¥å…·."""
    
    tool_type = ToolType.CODE_EXECUTOR
    
    def __init__(
        self,
        timeout: int = 30,
        allowed_languages: list[str] | None = None,
    ) -> None:
        """åˆå§‹åŒ–ä»£ç æ‰§è¡Œå™¨."""
        self._timeout = timeout
        self._allowed_languages = allowed_languages or ["python"]
        self._temp_dir = Path(tempfile.mkdtemp(prefix="agent_code_"))
    
    async def execute(
        self,
        action: str,
        params: dict[str, Any],
    ) -> ToolResult:
        """æ‰§è¡Œä»£ç ."""
        start_time = datetime.now()
        
        code = params.get("code", "")
        language = params.get("language", "python")
        
        if language not in self._allowed_languages:
            return ToolResult(
                success=False,
                error=f"ä¸æ”¯æŒçš„è¯­è¨€: {language}",
                tool_type=self.tool_type,
            )
        
        if language == "python":
            result = await self._execute_python(code)
        else:
            result = ToolResult(
                success=False,
                error=f"è¯­è¨€ {language} æš‚æœªå®ç°",
            )
        
        result.tool_type = self.tool_type
        result.execution_time_ms = (datetime.now() - start_time).total_seconds() * 1000
        
        return result
    
    async def _execute_python(self, code: str) -> ToolResult:
        """æ‰§è¡ŒPythonä»£ç ."""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        code_file = self._temp_dir / f"code_{datetime.now().strftime('%H%M%S%f')}.py"
        code_file.write_text(code, encoding="utf-8")
        
        try:
            # æ‰§è¡Œä»£ç 
            process = await asyncio.create_subprocess_exec(
                "python",
                str(code_file),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=str(self._temp_dir),
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=self._timeout,
                )
            except asyncio.TimeoutError:
                process.kill()
                return ToolResult(
                    success=False,
                    error=f"æ‰§è¡Œè¶…æ—¶ ({self._timeout}ç§’)",
                )
            
            if process.returncode == 0:
                return ToolResult(
                    success=True,
                    output=stdout.decode("utf-8"),
                )
            else:
                return ToolResult(
                    success=False,
                    output=stdout.decode("utf-8"),
                    error=stderr.decode("utf-8"),
                )
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if code_file.exists():
                code_file.unlink()


class FileSystemTool(BaseTool):
    """æ–‡ä»¶ç³»ç»Ÿæ“ä½œå·¥å…·."""
    
    tool_type = ToolType.FILE_SYSTEM
    
    def __init__(
        self,
        workspace: Path | None = None,
        allowed_extensions: list[str] | None = None,
    ) -> None:
        """åˆå§‹åŒ–æ–‡ä»¶ç³»ç»Ÿå·¥å…·."""
        self._workspace = workspace or Path.cwd()
        self._allowed_extensions = allowed_extensions
    
    async def execute(
        self,
        action: str,
        params: dict[str, Any],
    ) -> ToolResult:
        """æ‰§è¡Œæ–‡ä»¶ç³»ç»Ÿæ“ä½œ."""
        start_time = datetime.now()
        
        try:
            if action == "read":
                result = await self._read_file(params)
            elif action == "write":
                result = await self._write_file(params)
            elif action == "list":
                result = await self._list_directory(params)
            elif action == "exists":
                result = await self._check_exists(params)
            elif action == "delete":
                result = await self._delete_file(params)
            elif action == "mkdir":
                result = await self._make_directory(params)
            else:
                result = ToolResult(
                    success=False,
                    error=f"æœªçŸ¥æ“ä½œ: {action}",
                )
        except Exception as e:
            result = ToolResult(
                success=False,
                error=str(e),
            )
        
        result.tool_type = self.tool_type
        result.execution_time_ms = (datetime.now() - start_time).total_seconds() * 1000
        
        return result
    
    async def _read_file(self, params: dict[str, Any]) -> ToolResult:
        """è¯»å–æ–‡ä»¶."""
        path = self._resolve_path(params.get("path", ""))
        
        if not path.exists():
            return ToolResult(success=False, error=f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        content = path.read_text(encoding="utf-8")
        return ToolResult(success=True, output=content)
    
    async def _write_file(self, params: dict[str, Any]) -> ToolResult:
        """å†™å…¥æ–‡ä»¶."""
        path = self._resolve_path(params.get("path", ""))
        content = params.get("content", "")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        path.parent.mkdir(parents=True, exist_ok=True)
        
        path.write_text(content, encoding="utf-8")
        return ToolResult(success=True, output=f"å·²å†™å…¥: {path}")
    
    async def _list_directory(self, params: dict[str, Any]) -> ToolResult:
        """åˆ—å‡ºç›®å½•å†…å®¹."""
        path = self._resolve_path(params.get("path", "."))
        
        if not path.exists():
            return ToolResult(success=False, error=f"ç›®å½•ä¸å­˜åœ¨: {path}")
        
        if not path.is_dir():
            return ToolResult(success=False, error=f"ä¸æ˜¯ç›®å½•: {path}")
        
        items = []
        for item in path.iterdir():
            item_type = "ğŸ“" if item.is_dir() else "ğŸ“„"
            items.append(f"{item_type} {item.name}")
        
        return ToolResult(success=True, output="\n".join(items))
    
    async def _check_exists(self, params: dict[str, Any]) -> ToolResult:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨."""
        path = self._resolve_path(params.get("path", ""))
        exists = path.exists()
        return ToolResult(success=True, output=str(exists))
    
    async def _delete_file(self, params: dict[str, Any]) -> ToolResult:
        """åˆ é™¤æ–‡ä»¶."""
        path = self._resolve_path(params.get("path", ""))
        
        if not path.exists():
            return ToolResult(success=False, error=f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        if path.is_dir():
            import shutil
            shutil.rmtree(path)
        else:
            path.unlink()
        
        return ToolResult(success=True, output=f"å·²åˆ é™¤: {path}")
    
    async def _make_directory(self, params: dict[str, Any]) -> ToolResult:
        """åˆ›å»ºç›®å½•."""
        path = self._resolve_path(params.get("path", ""))
        path.mkdir(parents=True, exist_ok=True)
        return ToolResult(success=True, output=f"å·²åˆ›å»ºç›®å½•: {path}")
    
    def _resolve_path(self, path_str: str) -> Path:
        """è§£æè·¯å¾„."""
        path = Path(path_str)
        if not path.is_absolute():
            path = self._workspace / path
        return path.resolve()


class GitTool(BaseTool):
    """Gitæ“ä½œå·¥å…·."""
    
    tool_type = ToolType.GIT
    
    def __init__(self, repo_path: Path | None = None) -> None:
        """åˆå§‹åŒ–Gitå·¥å…·."""
        self._repo_path = repo_path or Path.cwd()
    
    async def execute(
        self,
        action: str,
        params: dict[str, Any],
    ) -> ToolResult:
        """æ‰§è¡ŒGitæ“ä½œ."""
        start_time = datetime.now()
        
        try:
            if action == "status":
                result = await self._git_command(["status", "--porcelain"])
            elif action == "add":
                files = params.get("files", ["."])
                result = await self._git_command(["add"] + files)
            elif action == "commit":
                message = params.get("message", "Auto commit")
                result = await self._git_command(["commit", "-m", message])
            elif action == "diff":
                result = await self._git_command(["diff"])
            elif action == "log":
                n = params.get("n", 5)
                result = await self._git_command(["log", f"-{n}", "--oneline"])
            elif action == "branch":
                result = await self._git_command(["branch", "-a"])
            elif action == "checkout":
                branch = params.get("branch", "")
                result = await self._git_command(["checkout", branch])
            else:
                result = ToolResult(success=False, error=f"æœªçŸ¥æ“ä½œ: {action}")
        except Exception as e:
            result = ToolResult(success=False, error=str(e))
        
        result.tool_type = self.tool_type
        result.execution_time_ms = (datetime.now() - start_time).total_seconds() * 1000
        
        return result
    
    async def _git_command(self, args: list[str]) -> ToolResult:
        """æ‰§è¡ŒGitå‘½ä»¤."""
        process = await asyncio.create_subprocess_exec(
            "git",
            *args,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=str(self._repo_path),
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode == 0:
            return ToolResult(success=True, output=stdout.decode("utf-8"))
        else:
            return ToolResult(
                success=False,
                output=stdout.decode("utf-8"),
                error=stderr.decode("utf-8"),
            )


class TerminalTool(BaseTool):
    """ç»ˆç«¯å‘½ä»¤å·¥å…·."""
    
    tool_type = ToolType.TERMINAL
    
    def __init__(
        self,
        working_dir: Path | None = None,
        timeout: int = 60,
        allowed_commands: list[str] | None = None,
    ) -> None:
        """åˆå§‹åŒ–ç»ˆç«¯å·¥å…·."""
        self._working_dir = working_dir or Path.cwd()
        self._timeout = timeout
        self._allowed_commands = allowed_commands  # Noneè¡¨ç¤ºå…è®¸æ‰€æœ‰å‘½ä»¤
    
    async def execute(
        self,
        action: str,
        params: dict[str, Any],
    ) -> ToolResult:
        """æ‰§è¡Œç»ˆç«¯å‘½ä»¤."""
        start_time = datetime.now()
        
        command = params.get("command", "")
        
        # å®‰å…¨æ£€æŸ¥
        if self._allowed_commands:
            cmd_name = command.split()[0] if command else ""
            if cmd_name not in self._allowed_commands:
                return ToolResult(
                    success=False,
                    error=f"ä¸å…è®¸çš„å‘½ä»¤: {cmd_name}",
                    tool_type=self.tool_type,
                )
        
        try:
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=str(self._working_dir),
            )
            
            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=self._timeout,
                )
            except asyncio.TimeoutError:
                process.kill()
                return ToolResult(
                    success=False,
                    error=f"å‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({self._timeout}ç§’)",
                    tool_type=self.tool_type,
                )
            
            result = ToolResult(
                success=process.returncode == 0,
                output=stdout.decode("utf-8"),
                error=stderr.decode("utf-8") if stderr else None,
            )
        
        except Exception as e:
            result = ToolResult(success=False, error=str(e))
        
        result.tool_type = self.tool_type
        result.execution_time_ms = (datetime.now() - start_time).total_seconds() * 1000
        
        return result


class ToolExecutor:
    """å·¥å…·æ‰§è¡Œå™¨ - ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨æ¥å£."""
    
    def __init__(
        self,
        workspace: Path | None = None,
    ) -> None:
        """åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨."""
        self._workspace = workspace or Path.cwd()
        
        # æ³¨å†Œå·¥å…·
        self._tools: dict[ToolType, BaseTool] = {
            ToolType.CODE_EXECUTOR: CodeExecutorTool(),
            ToolType.FILE_SYSTEM: FileSystemTool(workspace=self._workspace),
            ToolType.GIT: GitTool(repo_path=self._workspace),
            ToolType.TERMINAL: TerminalTool(working_dir=self._workspace),
        }
    
    def register_tool(self, tool: BaseTool) -> None:
        """æ³¨å†Œå·¥å…·."""
        self._tools[tool.tool_type] = tool
    
    async def execute(
        self,
        tool_type: ToolType,
        action: str,
        params: dict[str, Any] | None = None,
    ) -> ToolResult:
        """æ‰§è¡Œå·¥å…·æ“ä½œ.
        
        Args:
            tool_type: å·¥å…·ç±»å‹
            action: æ“ä½œåç§°
            params: æ“ä½œå‚æ•°
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        params = params or {}
        
        tool = self._tools.get(tool_type)
        if not tool:
            return ToolResult(
                success=False,
                error=f"æœªæ³¨å†Œçš„å·¥å…·ç±»å‹: {tool_type}",
                tool_type=tool_type,
            )
        
        logger.debug(f"æ‰§è¡Œå·¥å…·: {tool_type.value}, æ“ä½œ: {action}")
        
        return await tool.execute(action, params)
    
    def get_available_tools(self) -> list[ToolType]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨."""
        return list(self._tools.keys())

"""ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - å·¥ä½œæµå¼•æ“.

æä¾›å·¥ä½œæµå®šä¹‰å’Œæ‰§è¡Œèƒ½åŠ›ã€‚
"""

from __future__ import annotations

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

from ..core.types import (
    AgentRole,
    Artifact,
    Task,
    TaskContext,
    TaskPriority,
    TaskResult,
    TaskStatus,
)

if TYPE_CHECKING:
    from ..agents.base import BaseAgent
    from ..orchestration.orchestrator import TeamOrchestrator


logger = logging.getLogger(__name__)


@dataclass
class WorkflowPhase:
    """å·¥ä½œæµé˜¶æ®µ."""
    
    id: str = ""
    name: str = ""
    description: str = ""
    
    # ä»»åŠ¡æ¨¡æ¿
    task_templates: list[TaskTemplate] = field(default_factory=list)
    
    # æ‰§è¡Œé…ç½®
    parallel: bool = False
    max_parallel: int = 5
    
    # é—¨ç¦
    entry_gate: QualityGate | None = None
    exit_gate: QualityGate | None = None
    
    # æ‰€éœ€è§’è‰²
    required_roles: list[AgentRole] = field(default_factory=list)
    
    # è¶…æ—¶
    timeout_minutes: int = 60
    
    # æ˜¯å¦å¯é€‰
    optional: bool = False
    skip_condition: str | None = None


@dataclass
class TaskTemplate:
    """ä»»åŠ¡æ¨¡æ¿."""
    
    id: str = ""
    name: str = ""
    description_template: str = ""
    
    # ç±»å‹
    task_type: str = ""
    
    # è§’è‰²è¦æ±‚
    required_role: AgentRole | None = None
    
    # ä¼˜å…ˆçº§
    priority: TaskPriority = TaskPriority.MEDIUM
    
    # ä¾èµ–
    depends_on: list[str] = field(default_factory=list)
    
    # è´¨é‡è¦æ±‚
    require_review: bool = True
    min_confidence: float = 0.7


@dataclass
class QualityGate:
    """è´¨é‡é—¨ç¦."""
    
    name: str = ""
    description: str = ""
    
    # æ£€æŸ¥é¡¹
    checks: list[QualityCheck] = field(default_factory=list)
    
    # é€šè¿‡æ¡ä»¶
    require_all: bool = True
    min_pass_rate: float = 1.0


@dataclass
class QualityCheck:
    """è´¨é‡æ£€æŸ¥é¡¹."""
    
    name: str = ""
    check_type: str = ""  # lint, test, security, coverage, review
    
    # é…ç½®
    config: dict[str, Any] = field(default_factory=dict)
    
    # é˜ˆå€¼
    threshold: float = 0.0
    
    # æ˜¯å¦é˜»æ–­
    blocking: bool = True


@dataclass
class Workflow:
    """å·¥ä½œæµå®šä¹‰."""
    
    id: str = ""
    name: str = ""
    description: str = ""
    version: str = "1.0.0"
    
    # é˜¶æ®µ
    phases: list[WorkflowPhase] = field(default_factory=list)
    
    # é…ç½®
    allow_parallel_phases: bool = False
    max_retries: int = 3
    fail_fast: bool = True
    
    # è§¦å‘æ¡ä»¶
    trigger_type: str = "manual"  # manual, event, schedule
    trigger_config: dict[str, Any] = field(default_factory=dict)
    
    # å…ƒæ•°æ®
    created_at: datetime = field(default_factory=datetime.now)
    author: str = ""
    tags: list[str] = field(default_factory=list)


@dataclass
class WorkflowExecution:
    """å·¥ä½œæµæ‰§è¡Œå®ä¾‹."""
    
    id: str = ""
    workflow_id: str = ""
    
    # çŠ¶æ€
    status: str = "pending"  # pending, running, completed, failed, cancelled
    current_phase_index: int = 0
    
    # è¾“å…¥è¾“å‡º
    input_context: TaskContext | None = None
    output_artifacts: list[Artifact] = field(default_factory=list)
    
    # é˜¶æ®µæ‰§è¡Œç»“æœ
    phase_results: list[PhaseExecutionResult] = field(default_factory=list)
    
    # æ—¶é—´
    started_at: datetime | None = None
    completed_at: datetime | None = None
    
    # é”™è¯¯
    error: str | None = None


@dataclass
class PhaseExecutionResult:
    """é˜¶æ®µæ‰§è¡Œç»“æœ."""
    
    phase_id: str = ""
    status: str = "pending"
    
    # ä»»åŠ¡ç»“æœ
    task_results: list[TaskResult] = field(default_factory=list)
    
    # é—¨ç¦ç»“æœ
    entry_gate_passed: bool = True
    exit_gate_passed: bool = True
    gate_details: dict[str, Any] = field(default_factory=dict)
    
    # æ—¶é—´
    started_at: datetime | None = None
    completed_at: datetime | None = None
    duration_seconds: float = 0.0


class WorkflowEngine:
    """å·¥ä½œæµå¼•æ“ - ä¸»å¸­çº§å·¥ä½œæµæ‰§è¡Œ.
    
    åŠŸèƒ½ï¼š
    - å·¥ä½œæµå®šä¹‰å’Œç®¡ç†
    - å·¥ä½œæµæ‰§è¡Œ
    - è´¨é‡é—¨ç¦æ£€æŸ¥
    - æ‰§è¡Œç›‘æ§
    """
    
    def __init__(
        self,
        orchestrator: TeamOrchestrator | None = None,
    ) -> None:
        """åˆå§‹åŒ–å·¥ä½œæµå¼•æ“."""
        self._orchestrator = orchestrator
        self._workflows: dict[str, Workflow] = {}
        self._executions: dict[str, WorkflowExecution] = {}
        
        # æ³¨å†Œé¢„å®šä¹‰å·¥ä½œæµ
        self._register_builtin_workflows()
    
    def register_workflow(self, workflow: Workflow) -> None:
        """æ³¨å†Œå·¥ä½œæµ."""
        self._workflows[workflow.id] = workflow
        logger.info(f"æ³¨å†Œå·¥ä½œæµ: {workflow.name} (ID: {workflow.id})")
    
    def get_workflow(self, workflow_id: str) -> Workflow | None:
        """è·å–å·¥ä½œæµ."""
        return self._workflows.get(workflow_id)
    
    def list_workflows(self) -> list[Workflow]:
        """åˆ—å‡ºæ‰€æœ‰å·¥ä½œæµ."""
        return list(self._workflows.values())
    
    async def execute_workflow(
        self,
        workflow_id: str,
        context: TaskContext,
        variables: dict[str, Any] | None = None,
    ) -> WorkflowExecution:
        """æ‰§è¡Œå·¥ä½œæµ.
        
        Args:
            workflow_id: å·¥ä½œæµID
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            variables: è¿è¡Œæ—¶å˜é‡
            
        Returns:
            å·¥ä½œæµæ‰§è¡Œç»“æœ
        """
        workflow = self._workflows.get(workflow_id)
        if not workflow:
            raise ValueError(f"å·¥ä½œæµä¸å­˜åœ¨: {workflow_id}")
        
        # åˆ›å»ºæ‰§è¡Œå®ä¾‹
        execution = WorkflowExecution(
            id=f"exec_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            workflow_id=workflow_id,
            input_context=context,
            status="running",
            started_at=datetime.now(),
        )
        self._executions[execution.id] = execution
        
        logger.info(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {workflow.name}")
        
        # åˆå¹¶å˜é‡åˆ°ä¸Šä¸‹æ–‡
        if variables:
            context.variables.update(variables)
        
        try:
            # æ‰§è¡Œå„é˜¶æ®µ
            for phase_index, phase in enumerate(workflow.phases):
                execution.current_phase_index = phase_index
                
                # æ£€æŸ¥æ˜¯å¦è·³è¿‡
                if phase.optional and phase.skip_condition:
                    if self._evaluate_condition(phase.skip_condition, context, execution):
                        logger.info(f"è·³è¿‡å¯é€‰é˜¶æ®µ: {phase.name}")
                        continue
                
                logger.info(f"æ‰§è¡Œé˜¶æ®µ {phase_index + 1}/{len(workflow.phases)}: {phase.name}")
                
                # æ‰§è¡Œé˜¶æ®µ
                phase_result = await self._execute_phase(phase, context, execution)
                execution.phase_results.append(phase_result)
                
                # æ£€æŸ¥æ˜¯å¦å¤±è´¥
                if phase_result.status == "failed":
                    if workflow.fail_fast:
                        execution.status = "failed"
                        execution.error = f"é˜¶æ®µ {phase.name} æ‰§è¡Œå¤±è´¥"
                        break
                
                # æ”¶é›†äº§å‡ºç‰©
                for task_result in phase_result.task_results:
                    execution.output_artifacts.extend(task_result.artifacts)
            
            # æ ‡è®°å®Œæˆ
            if execution.status != "failed":
                execution.status = "completed"
                
        except Exception as e:
            logger.exception(f"å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {e}")
            execution.status = "failed"
            execution.error = str(e)
        
        execution.completed_at = datetime.now()
        
        logger.info(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {execution.status}")
        
        return execution
    
    async def _execute_phase(
        self,
        phase: WorkflowPhase,
        context: TaskContext,
        execution: WorkflowExecution,
    ) -> PhaseExecutionResult:
        """æ‰§è¡Œé˜¶æ®µ."""
        result = PhaseExecutionResult(
            phase_id=phase.id,
            status="running",
            started_at=datetime.now(),
        )
        
        # æ£€æŸ¥å…¥å£é—¨ç¦
        if phase.entry_gate:
            gate_result = await self._check_gate(phase.entry_gate, context, execution)
            result.entry_gate_passed = gate_result["passed"]
            result.gate_details["entry"] = gate_result
            
            if not result.entry_gate_passed:
                result.status = "blocked"
                logger.warning(f"é˜¶æ®µ {phase.name} å…¥å£é—¨ç¦æœªé€šè¿‡")
                return result
        
        # ç”Ÿæˆä»»åŠ¡
        tasks = self._generate_tasks(phase.task_templates, context)
        
        # æ‰§è¡Œä»»åŠ¡
        if phase.parallel and len(tasks) > 1:
            task_results = await self._execute_tasks_parallel(
                tasks, context, phase.max_parallel
            )
        else:
            task_results = await self._execute_tasks_sequential(tasks, context)
        
        result.task_results = task_results
        
        # æ£€æŸ¥å‡ºå£é—¨ç¦
        if phase.exit_gate:
            gate_result = await self._check_gate(phase.exit_gate, context, execution)
            result.exit_gate_passed = gate_result["passed"]
            result.gate_details["exit"] = gate_result
            
            if not result.exit_gate_passed:
                result.status = "failed"
                logger.warning(f"é˜¶æ®µ {phase.name} å‡ºå£é—¨ç¦æœªé€šè¿‡")
                return result
        
        # åˆ¤æ–­é˜¶æ®µçŠ¶æ€
        failed_tasks = [r for r in task_results if not r.success]
        if failed_tasks:
            result.status = "failed"
        else:
            result.status = "completed"
        
        result.completed_at = datetime.now()
        result.duration_seconds = (result.completed_at - result.started_at).total_seconds()
        
        return result
    
    def _generate_tasks(
        self,
        templates: list[TaskTemplate],
        context: TaskContext,
    ) -> list[Task]:
        """ä»æ¨¡æ¿ç”Ÿæˆä»»åŠ¡."""
        tasks = []
        
        for template in templates:
            # æ¸²æŸ“æè¿°
            description = template.description_template.format(
                project_name=context.project_name,
                project_description=context.project_description,
                **context.variables,
            )
            
            task = Task(
                title=template.name,
                description=description,
                type=template.task_type,
                priority=template.priority,
                required_role=template.required_role,
            )
            tasks.append(task)
        
        return tasks
    
    async def _execute_tasks_parallel(
        self,
        tasks: list[Task],
        context: TaskContext,
        max_parallel: int,
    ) -> list[TaskResult]:
        """å¹¶è¡Œæ‰§è¡Œä»»åŠ¡."""
        if not self._orchestrator:
            return [TaskResult(task_id=t.id, success=False, error_message="ç¼–æ’å™¨æœªé…ç½®") for t in tasks]
        
        semaphore = asyncio.Semaphore(max_parallel)
        
        async def execute_with_semaphore(task: Task) -> TaskResult:
            async with semaphore:
                return await self._orchestrator._execute_task(task, context)
        
        results = await asyncio.gather(
            *[execute_with_semaphore(t) for t in tasks],
            return_exceptions=True,
        )
        
        return [
            r if isinstance(r, TaskResult) else TaskResult(
                task_id=tasks[i].id,
                success=False,
                error_message=str(r),
            )
            for i, r in enumerate(results)
        ]
    
    async def _execute_tasks_sequential(
        self,
        tasks: list[Task],
        context: TaskContext,
    ) -> list[TaskResult]:
        """ä¸²è¡Œæ‰§è¡Œä»»åŠ¡."""
        results = []
        
        for task in tasks:
            if self._orchestrator:
                result = await self._orchestrator._execute_task(task, context)
            else:
                result = TaskResult(
                    task_id=task.id,
                    success=False,
                    error_message="ç¼–æ’å™¨æœªé…ç½®",
                )
            results.append(result)
        
        return results
    
    async def _check_gate(
        self,
        gate: QualityGate,
        context: TaskContext,
        execution: WorkflowExecution,
    ) -> dict[str, Any]:
        """æ£€æŸ¥è´¨é‡é—¨ç¦."""
        check_results = []
        
        for check in gate.checks:
            result = await self._run_quality_check(check, context, execution)
            check_results.append(result)
        
        # è®¡ç®—é€šè¿‡ç‡
        passed_count = sum(1 for r in check_results if r["passed"])
        pass_rate = passed_count / len(check_results) if check_results else 1.0
        
        # åˆ¤æ–­æ˜¯å¦é€šè¿‡
        if gate.require_all:
            passed = all(r["passed"] for r in check_results)
        else:
            passed = pass_rate >= gate.min_pass_rate
        
        return {
            "passed": passed,
            "pass_rate": pass_rate,
            "checks": check_results,
        }
    
    async def _run_quality_check(
        self,
        check: QualityCheck,
        context: TaskContext,
        execution: WorkflowExecution,
    ) -> dict[str, Any]:
        """è¿è¡Œè´¨é‡æ£€æŸ¥."""
        logger.debug(f"è¿è¡Œè´¨é‡æ£€æŸ¥: {check.name} ({check.check_type})")
        
        result = {
            "name": check.name,
            "type": check.check_type,
            "passed": True,
            "score": 1.0,
            "details": "",
        }
        
        if check.check_type == "lint":
            # ä»£ç æ£€æŸ¥
            result["passed"] = True  # ç®€åŒ–å®ç°
            result["details"] = "ä»£ç æ£€æŸ¥é€šè¿‡"
        
        elif check.check_type == "test":
            # æµ‹è¯•æ£€æŸ¥
            result["passed"] = True
            result["details"] = "æµ‹è¯•é€šè¿‡"
        
        elif check.check_type == "coverage":
            # è¦†ç›–ç‡æ£€æŸ¥
            min_coverage = check.config.get("min_coverage", 0.8)
            actual_coverage = 0.85  # ç®€åŒ–å®ç°
            result["passed"] = actual_coverage >= min_coverage
            result["score"] = actual_coverage
            result["details"] = f"è¦†ç›–ç‡: {actual_coverage:.1%}"
        
        elif check.check_type == "security":
            # å®‰å…¨æ£€æŸ¥
            result["passed"] = True
            result["details"] = "å®‰å…¨æ£€æŸ¥é€šè¿‡"
        
        elif check.check_type == "review":
            # å®¡æŸ¥æ£€æŸ¥
            min_approvals = check.config.get("min_approvals", 1)
            actual_approvals = 1  # ç®€åŒ–å®ç°
            result["passed"] = actual_approvals >= min_approvals
            result["details"] = f"å®¡æ‰¹æ•°: {actual_approvals}/{min_approvals}"
        
        return result
    
    def _evaluate_condition(
        self,
        condition: str,
        context: TaskContext,
        execution: WorkflowExecution,
    ) -> bool:
        """è¯„ä¼°æ¡ä»¶è¡¨è¾¾å¼."""
        # ç®€åŒ–å®ç°ï¼šæ”¯æŒåŸºæœ¬æ¡ä»¶
        if condition == "skip_frontend":
            return "frontend" not in context.tech_stack
        elif condition == "skip_security":
            return context.variables.get("skip_security", False)
        
        return False
    
    def _register_builtin_workflows(self) -> None:
        """æ³¨å†Œå†…ç½®å·¥ä½œæµ."""
        # åŠŸèƒ½å¼€å‘å·¥ä½œæµ
        self.register_workflow(create_feature_workflow())
        
        # Bugä¿®å¤å·¥ä½œæµ
        self.register_workflow(create_bugfix_workflow())
        
        # å®‰å…¨å®¡è®¡å·¥ä½œæµ
        self.register_workflow(create_security_audit_workflow())
        
        # å®Œæ•´é¡¹ç›®å·¥ä½œæµ
        self.register_workflow(create_full_project_workflow())


# =============================================================================
# é¢„å®šä¹‰å·¥ä½œæµ
# =============================================================================

def create_feature_workflow() -> Workflow:
    """åˆ›å»ºåŠŸèƒ½å¼€å‘å·¥ä½œæµ."""
    return Workflow(
        id="workflow_feature",
        name="åŠŸèƒ½å¼€å‘å·¥ä½œæµ",
        description="æ ‡å‡†çš„åŠŸèƒ½å¼€å‘æµç¨‹",
        version="1.0.0",
        phases=[
            WorkflowPhase(
                id="phase_design",
                name="è®¾è®¡é˜¶æ®µ",
                description="éœ€æ±‚åˆ†æå’ŒæŠ€æœ¯è®¾è®¡",
                task_templates=[
                    TaskTemplate(
                        id="task_requirement",
                        name="éœ€æ±‚åˆ†æ",
                        description_template="åˆ†æä»¥ä¸‹éœ€æ±‚ï¼š{project_description}",
                        task_type="requirement_analysis",
                        required_role=AgentRole.PROJECT_MANAGER,
                    ),
                    TaskTemplate(
                        id="task_design",
                        name="æŠ€æœ¯è®¾è®¡",
                        description_template="ä¸º{project_name}è®¾è®¡æŠ€æœ¯æ–¹æ¡ˆ",
                        task_type="architecture_design",
                        required_role=AgentRole.SYSTEM_ARCHITECT,
                        depends_on=["task_requirement"],
                    ),
                ],
                parallel=False,
            ),
            WorkflowPhase(
                id="phase_development",
                name="å¼€å‘é˜¶æ®µ",
                description="åŠŸèƒ½å®ç°",
                task_templates=[
                    TaskTemplate(
                        id="task_backend",
                        name="åç«¯å¼€å‘",
                        description_template="å®ç°{project_name}çš„åç«¯åŠŸèƒ½",
                        task_type="backend_development",
                        required_role=AgentRole.BACKEND_ENGINEER,
                    ),
                    TaskTemplate(
                        id="task_frontend",
                        name="å‰ç«¯å¼€å‘",
                        description_template="å®ç°{project_name}çš„å‰ç«¯ç•Œé¢",
                        task_type="frontend_development",
                        required_role=AgentRole.FRONTEND_ENGINEER,
                    ),
                ],
                parallel=True,
                max_parallel=2,
            ),
            WorkflowPhase(
                id="phase_quality",
                name="è´¨é‡ä¿è¯é˜¶æ®µ",
                description="æµ‹è¯•å’Œå®¡æŸ¥",
                task_templates=[
                    TaskTemplate(
                        id="task_test",
                        name="æµ‹è¯•",
                        description_template="æµ‹è¯•{project_name}çš„æ‰€æœ‰åŠŸèƒ½",
                        task_type="testing",
                        required_role=AgentRole.QA_ENGINEER,
                    ),
                    TaskTemplate(
                        id="task_review",
                        name="ä»£ç å®¡æŸ¥",
                        description_template="å®¡æŸ¥{project_name}çš„ä»£ç è´¨é‡",
                        task_type="code_review",
                        required_role=AgentRole.CODE_REVIEWER,
                    ),
                ],
                parallel=True,
                exit_gate=QualityGate(
                    name="è´¨é‡é—¨ç¦",
                    checks=[
                        QualityCheck(name="æµ‹è¯•é€šè¿‡", check_type="test"),
                        QualityCheck(name="è¦†ç›–ç‡", check_type="coverage", config={"min_coverage": 0.8}),
                    ],
                ),
            ),
        ],
        author="system",
        tags=["feature", "standard"],
    )


def create_bugfix_workflow() -> Workflow:
    """åˆ›å»ºBugä¿®å¤å·¥ä½œæµ."""
    return Workflow(
        id="workflow_bugfix",
        name="Bugä¿®å¤å·¥ä½œæµ",
        description="å¿«é€ŸBugä¿®å¤æµç¨‹",
        version="1.0.0",
        phases=[
            WorkflowPhase(
                id="phase_analysis",
                name="é—®é¢˜åˆ†æ",
                task_templates=[
                    TaskTemplate(
                        id="task_analyze",
                        name="é—®é¢˜åˆ†æ",
                        description_template="åˆ†æBugï¼š{project_description}",
                        task_type="bug_analysis",
                        required_role=AgentRole.BACKEND_ENGINEER,
                    ),
                ],
            ),
            WorkflowPhase(
                id="phase_fix",
                name="ä¿®å¤é˜¶æ®µ",
                task_templates=[
                    TaskTemplate(
                        id="task_fix",
                        name="Bugä¿®å¤",
                        description_template="ä¿®å¤Bugï¼š{project_description}",
                        task_type="bug_fix",
                        required_role=AgentRole.BACKEND_ENGINEER,
                    ),
                ],
            ),
            WorkflowPhase(
                id="phase_verify",
                name="éªŒè¯é˜¶æ®µ",
                task_templates=[
                    TaskTemplate(
                        id="task_test",
                        name="å›å½’æµ‹è¯•",
                        description_template="éªŒè¯Bugä¿®å¤ï¼š{project_description}",
                        task_type="regression_testing",
                        required_role=AgentRole.QA_ENGINEER,
                    ),
                ],
                exit_gate=QualityGate(
                    name="éªŒè¯é—¨ç¦",
                    checks=[
                        QualityCheck(name="æµ‹è¯•é€šè¿‡", check_type="test", blocking=True),
                    ],
                ),
            ),
        ],
        author="system",
        tags=["bugfix", "quick"],
    )


def create_security_audit_workflow() -> Workflow:
    """åˆ›å»ºå®‰å…¨å®¡è®¡å·¥ä½œæµ."""
    return Workflow(
        id="workflow_security_audit",
        name="å®‰å…¨å®¡è®¡å·¥ä½œæµ",
        description="å…¨é¢çš„å®‰å…¨å®¡è®¡æµç¨‹",
        version="1.0.0",
        phases=[
            WorkflowPhase(
                id="phase_scan",
                name="æ¼æ´æ‰«æ",
                task_templates=[
                    TaskTemplate(
                        id="task_scan",
                        name="å®‰å…¨æ‰«æ",
                        description_template="å¯¹{project_name}è¿›è¡Œå®‰å…¨æ‰«æ",
                        task_type="security_scan",
                        required_role=AgentRole.SECURITY_ARCHITECT,
                    ),
                ],
            ),
            WorkflowPhase(
                id="phase_audit",
                name="ä»£ç å®¡è®¡",
                task_templates=[
                    TaskTemplate(
                        id="task_audit",
                        name="å®‰å…¨ä»£ç å®¡è®¡",
                        description_template="å¯¹{project_name}è¿›è¡Œå®‰å…¨ä»£ç å®¡è®¡",
                        task_type="security_audit",
                        required_role=AgentRole.SECURITY_ARCHITECT,
                    ),
                ],
            ),
            WorkflowPhase(
                id="phase_report",
                name="æŠ¥å‘Šé˜¶æ®µ",
                task_templates=[
                    TaskTemplate(
                        id="task_report",
                        name="å®‰å…¨æŠ¥å‘Š",
                        description_template="ç”Ÿæˆ{project_name}çš„å®‰å…¨å®¡è®¡æŠ¥å‘Š",
                        task_type="security_report",
                        required_role=AgentRole.SECURITY_ARCHITECT,
                    ),
                ],
            ),
        ],
        author="system",
        tags=["security", "audit"],
    )


def create_full_project_workflow() -> Workflow:
    """åˆ›å»ºå®Œæ•´é¡¹ç›®å·¥ä½œæµ."""
    return Workflow(
        id="workflow_full_project",
        name="å®Œæ•´é¡¹ç›®å·¥ä½œæµ",
        description="ä»éœ€æ±‚åˆ°éƒ¨ç½²çš„å®Œæ•´æµç¨‹",
        version="1.0.0",
        phases=[
            # é˜¶æ®µ1ï¼šéœ€æ±‚åˆ†æ
            WorkflowPhase(
                id="phase_requirements",
                name="éœ€æ±‚åˆ†æ",
                task_templates=[
                    TaskTemplate(
                        id="task_req_analysis",
                        name="éœ€æ±‚åˆ†æ",
                        description_template="{project_description}",
                        task_type="requirement_analysis",
                        required_role=AgentRole.PROJECT_MANAGER,
                        priority=TaskPriority.HIGH,
                    ),
                ],
            ),
            # é˜¶æ®µ2ï¼šæ¶æ„è®¾è®¡
            WorkflowPhase(
                id="phase_architecture",
                name="æ¶æ„è®¾è®¡",
                task_templates=[
                    TaskTemplate(
                        id="task_arch_design",
                        name="ç³»ç»Ÿæ¶æ„è®¾è®¡",
                        description_template="ä¸º{project_name}è®¾è®¡ç³»ç»Ÿæ¶æ„",
                        task_type="architecture_design",
                        required_role=AgentRole.SYSTEM_ARCHITECT,
                    ),
                    TaskTemplate(
                        id="task_api_design",
                        name="APIè®¾è®¡",
                        description_template="è®¾è®¡{project_name}çš„APIæ¥å£",
                        task_type="api_design",
                        required_role=AgentRole.SYSTEM_ARCHITECT,
                    ),
                    TaskTemplate(
                        id="task_db_design",
                        name="æ•°æ®åº“è®¾è®¡",
                        description_template="è®¾è®¡{project_name}çš„æ•°æ®åº“æ¨¡å‹",
                        task_type="database_design",
                        required_role=AgentRole.SYSTEM_ARCHITECT,
                    ),
                ],
                parallel=True,
            ),
            # é˜¶æ®µ3ï¼šå¼€å‘
            WorkflowPhase(
                id="phase_development",
                name="å¼€å‘é˜¶æ®µ",
                task_templates=[
                    TaskTemplate(
                        id="task_backend_dev",
                        name="åç«¯å¼€å‘",
                        description_template="å¼€å‘{project_name}çš„åç«¯æœåŠ¡",
                        task_type="backend_development",
                        required_role=AgentRole.BACKEND_ENGINEER,
                    ),
                    TaskTemplate(
                        id="task_frontend_dev",
                        name="å‰ç«¯å¼€å‘",
                        description_template="å¼€å‘{project_name}çš„å‰ç«¯ç•Œé¢",
                        task_type="frontend_development",
                        required_role=AgentRole.FRONTEND_ENGINEER,
                    ),
                ],
                parallel=True,
                max_parallel=2,
            ),
            # é˜¶æ®µ4ï¼šæµ‹è¯•
            WorkflowPhase(
                id="phase_testing",
                name="æµ‹è¯•é˜¶æ®µ",
                task_templates=[
                    TaskTemplate(
                        id="task_unit_test",
                        name="å•å…ƒæµ‹è¯•",
                        description_template="ä¸º{project_name}ç¼–å†™å•å…ƒæµ‹è¯•",
                        task_type="unit_testing",
                        required_role=AgentRole.QA_ENGINEER,
                    ),
                    TaskTemplate(
                        id="task_integration_test",
                        name="é›†æˆæµ‹è¯•",
                        description_template="ä¸º{project_name}ç¼–å†™é›†æˆæµ‹è¯•",
                        task_type="integration_testing",
                        required_role=AgentRole.QA_ENGINEER,
                    ),
                ],
                parallel=True,
                exit_gate=QualityGate(
                    name="æµ‹è¯•è´¨é‡é—¨ç¦",
                    checks=[
                        QualityCheck(name="æµ‹è¯•é€šè¿‡ç‡", check_type="test"),
                        QualityCheck(name="ä»£ç è¦†ç›–ç‡", check_type="coverage", config={"min_coverage": 0.85}),
                    ],
                ),
            ),
            # é˜¶æ®µ5ï¼šä»£ç å®¡æŸ¥
            WorkflowPhase(
                id="phase_review",
                name="ä»£ç å®¡æŸ¥",
                task_templates=[
                    TaskTemplate(
                        id="task_code_review",
                        name="ä»£ç å®¡æŸ¥",
                        description_template="å®¡æŸ¥{project_name}çš„ä»£ç è´¨é‡",
                        task_type="code_review",
                        required_role=AgentRole.CODE_REVIEWER,
                    ),
                ],
            ),
            # é˜¶æ®µ6ï¼šå®‰å…¨å®¡è®¡
            WorkflowPhase(
                id="phase_security",
                name="å®‰å…¨å®¡è®¡",
                task_templates=[
                    TaskTemplate(
                        id="task_security_audit",
                        name="å®‰å…¨å®¡è®¡",
                        description_template="å¯¹{project_name}è¿›è¡Œå®‰å…¨å®¡è®¡",
                        task_type="security_audit",
                        required_role=AgentRole.SECURITY_ARCHITECT,
                    ),
                ],
                exit_gate=QualityGate(
                    name="å®‰å…¨é—¨ç¦",
                    checks=[
                        QualityCheck(name="å®‰å…¨æ‰«æ", check_type="security", blocking=True),
                    ],
                ),
            ),
            # é˜¶æ®µ7ï¼šéƒ¨ç½²é…ç½®
            WorkflowPhase(
                id="phase_deployment",
                name="éƒ¨ç½²é…ç½®",
                task_templates=[
                    TaskTemplate(
                        id="task_devops",
                        name="CI/CDé…ç½®",
                        description_template="é…ç½®{project_name}çš„CI/CDæµæ°´çº¿",
                        task_type="devops_setup",
                        required_role=AgentRole.DEVOPS_ENGINEER,
                    ),
                ],
            ),
            # é˜¶æ®µ8ï¼šæ–‡æ¡£
            WorkflowPhase(
                id="phase_documentation",
                name="æ–‡æ¡£ç¼–å†™",
                task_templates=[
                    TaskTemplate(
                        id="task_docs",
                        name="æŠ€æœ¯æ–‡æ¡£",
                        description_template="ç¼–å†™{project_name}çš„æŠ€æœ¯æ–‡æ¡£",
                        task_type="documentation",
                        required_role=AgentRole.TECH_WRITER,
                    ),
                ],
            ),
        ],
        fail_fast=True,
        author="system",
        tags=["full", "project", "standard"],
    )


    """ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿç³»ç»Ÿ.

ä¸€ä¸ªä¸–ç•Œçº§çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªä¸»å®Œæˆä»éœ€æ±‚åˆ†æåˆ°éƒ¨ç½²çš„å…¨æµç¨‹è½¯ä»¶å¼€å‘ã€‚

Quick Start:
    ```
    from chairman_agents import create_world_class_team, TaskContext
    from chairman_agents.integration.llm import create_llm_client
    
    # åˆ›å»ºLLMå®¢æˆ·ç«¯
    llm = create_llm_client(provider="openai", model="gpt-4", api_key="...")
    
    # åˆ›å»ºå›¢é˜Ÿ
    team = create_world_class_team(llm_client=llm)
    
    # æ‰§è¡Œé¡¹ç›®
    result = await team.execute("å¼€å‘ä¸€ä¸ªç”¨æˆ·ç®¡ç†ç³»ç»Ÿ")
    ```

Features:
    - 18ç§ä¸“ä¸šè§’è‰²ï¼Œ35ç§èƒ½åŠ›
    - æ·±åº¦æ¨ç†ï¼šæ€ç»´é“¾ã€æ€ç»´æ ‘ã€è‡ªæˆ‘åæ€
    - è®°å¿†ç³»ç»Ÿï¼šçŸ­æœŸã€é•¿æœŸã€æƒ…æ™¯ã€è¯­ä¹‰è®°å¿†
    - åä½œæœºåˆ¶ï¼šè¾©è®ºã€å…±è¯†ã€ç»“å¯¹ç¼–ç¨‹
    - å·¥ä½œæµå¼•æ“ï¼šé¢„å®šä¹‰å’Œè‡ªå®šä¹‰å·¥ä½œæµ
    - è´¨é‡é—¨ç¦ï¼šå¤šå±‚è´¨é‡æ£€æŸ¥
    - å·¥å…·ä½¿ç”¨ï¼šä»£ç æ‰§è¡Œã€æ–‡ä»¶æ“ä½œã€Gitç­‰

Author: Chairman AI Team
Version: 1.0.0
"""

from __future__ import annotations

__version__ = "1.0.0"
__author__ = "Chairman AI Team"

# =============================================================================
# æ ¸å¿ƒç±»å‹å¯¼å‡º
# =============================================================================

from .core.types import (
    # è§’è‰²å’Œèƒ½åŠ›
    AgentRole,
    AgentCapability,
    ExpertiseLevel,
    
    # ä»»åŠ¡ç›¸å…³
    Task,
    TaskResult,
    TaskStatus,
    TaskPriority,
    TaskContext,
    
    # äº§å‡ºç‰©
    Artifact,
    ArtifactType,
    
    # æ¶ˆæ¯
    AgentMessage,
    MessageType,
    
    # æ™ºèƒ½ä½“
    AgentProfile,
    AgentState,
    
    # å®¡æŸ¥
    ReviewResult,
    ReviewComment,
    
    # åä½œ
    DebateArgument,
    Vote,
    
    # å·¥å…·
    ToolType,
)

# =============================================================================
# æ™ºèƒ½ä½“å¯¼å‡º
# =============================================================================

from .agents.base import BaseAgent
from .agents.experts.project_manager import ProjectManagerAgent
from .agents.experts.architect import SystemArchitectAgent
from .agents.experts.backend import BackendEngineerAgent

# =============================================================================
# è®¤çŸ¥æ¨¡å—å¯¼å‡º
# =============================================================================

from .cognitive.reasoning import (
    ReasoningEngine,
    ReasoningResult,
    ThoughtNode,
)
from .cognitive.memory import (
    MemorySystem,
    MemoryItem,
    MemorySearchResult,
)

# =============================================================================
# åä½œæ¨¡å—å¯¼å‡º
# =============================================================================

from .collaboration.debate import (
    DebateSystem,
    DebateTopic,
    DebateResult,
)
from .collaboration.consensus import (
    ConsensusEngine,
    Proposal,
    ConsensusResult,
)

# =============================================================================
# ç¼–æ’æ¨¡å—å¯¼å‡º
# =============================================================================

from .orchestration.orchestrator import (
    TeamOrchestrator,
    OrchestratorConfig,
    ExecutionPlan,
    ExecutionPhase,
)

# =============================================================================
# å·¥ä½œæµæ¨¡å—å¯¼å‡º
# =============================================================================

from .workflow.engine import (
    WorkflowEngine,
    Workflow,
    WorkflowPhase,
    WorkflowExecution,
    QualityGate,
    QualityCheck,
)

# =============================================================================
# é›†æˆæ¨¡å—å¯¼å‡º
# =============================================================================

from .integration.llm import (
    create_llm_client,
    LLMClient,
    LLMConfig,
    LLMResponse,
)

# =============================================================================
# å·¥å…·æ¨¡å—å¯¼å‡º
# =============================================================================

from .tools.executor import (
    ToolExecutor,
    ToolResult,
)

# =============================================================================
# å›¢é˜Ÿæ¨¡å—å¯¼å‡º
# =============================================================================

from .team import (
    AgentTeam,
    TeamConfig,
    create_world_class_team,
)

# =============================================================================
# ä¾¿æ·åˆ«å
# =============================================================================

# å¸¸ç”¨ç±»å‹åˆ«å
Context = TaskContext
Result = TaskResult

# =============================================================================
# æ¨¡å—çº§åˆ«å˜é‡
# =============================================================================

__all__ = [
    # ç‰ˆæœ¬ä¿¡æ¯
    "__version__",
    "__author__",
    
    # æ ¸å¿ƒç±»å‹
    "AgentRole",
    "AgentCapability",
    "ExpertiseLevel",
    "Task",
    "TaskResult",
    "TaskStatus",
    "TaskPriority",
    "TaskContext",
    "Artifact",
    "ArtifactType",
    "AgentMessage",
    "MessageType",
    "AgentProfile",
    "AgentState",
    "ReviewResult",
    "ReviewComment",
    "DebateArgument",
    "Vote",
    "ToolType",
    
    # æ™ºèƒ½ä½“
    "BaseAgent",
    "ProjectManagerAgent",
    "SystemArchitectAgent",
    "BackendEngineerAgent",
    
    # è®¤çŸ¥
    "ReasoningEngine",
    "ReasoningResult",
    "ThoughtNode",
    "MemorySystem",
    "MemoryItem",
    "MemorySearchResult",
    
    # åä½œ
    "DebateSystem",
    "DebateTopic",
    "DebateResult",
    "ConsensusEngine",
    "Proposal",
    "ConsensusResult",
    
    # ç¼–æ’
    "TeamOrchestrator",
    "OrchestratorConfig",
    "ExecutionPlan",
    "ExecutionPhase",
    
    # å·¥ä½œæµ
    "WorkflowEngine",
    "Workflow",
    "WorkflowPhase",
    "WorkflowExecution",
    "QualityGate",
    "QualityCheck",
    
    # LLM
    "create_llm_client",
    "LLMClient",
    "LLMConfig",
    "LLMResponse",
    
    # å·¥å…·
    "ToolExecutor",
    "ToolResult",
    
    # å›¢é˜Ÿ
    "AgentTeam",
    "TeamConfig",
    "create_world_class_team",
    
    # åˆ«å
    "Context",
    "Result",
]
15. é…ç½®æ–‡ä»¶ç¤ºä¾‹ (config/default.yaml)

# =============================================================================
# ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿç³»ç»Ÿ - é»˜è®¤é…ç½®
# =============================================================================

# ç‰ˆæœ¬ä¿¡æ¯
version: "1.0.0"

# =============================================================================
# LLMé…ç½®
# =============================================================================
llm:
  # ä¸»è¦æä¾›å•†
  primary:
    provider: "openai"
    model: "gpt-4"
    temperature: 0.7
    max_tokens: 4096
    timeout: 120
    max_retries: 3
  
  # å¤‡ç”¨æä¾›å•†ï¼ˆæ•…éšœè½¬ç§»ï¼‰
  fallback:
    provider: "anthropic"
    model: "claude-3-opus-20240229"
    temperature: 0.7
    max_tokens: 4096
  
  # é€Ÿç‡é™åˆ¶
  rate_limit:
    requests_per_minute: 60
    tokens_per_minute: 90000

# =============================================================================
# å›¢é˜Ÿé…ç½®
# =============================================================================
team:
  # å›¢é˜Ÿæˆå‘˜é…ç½®
  members:
    project_manager: true
    system_architect: true
    backend_engineer: true
    frontend_engineer: true
    fullstack_engineer: false
    qa_engineer: true
    security_architect: true
    devops_engineer: true
    code_reviewer: true
    tech_writer: true
  
  # æˆå‘˜æ•°é‡
  counts:
    backend_engineer: 2
    frontend_engineer: 1
    qa_engineer: 1

# =============================================================================
# ç¼–æ’å™¨é…ç½®
# =============================================================================
orchestrator:
  # å¹¶è¡Œé…ç½®
  max_parallel_tasks: 5
  max_parallel_phases: 2
  
  # é‡è¯•é…ç½®
  max_retries: 3
  retry_delay_seconds: 1.0
  
  # è¶…æ—¶é…ç½®
  task_timeout_seconds: 300
  phase_timeout_seconds: 1800
  
  # è´¨é‡é…ç½®
  min_confidence_threshold: 0.7
  require_review: true

# =============================================================================
# è®¤çŸ¥ç³»ç»Ÿé…ç½®
# =============================================================================
cognitive:
  # æ¨ç†é…ç½®
  reasoning:
    default_strategy: "chain_of_thought"
    max_reasoning_steps: 10
    reflection_enabled: true
  
  # è®°å¿†é…ç½®
  memory:
    max_short_term: 100
    max_long_term: 10000
    storage_path: "./data/memory"
    auto_consolidate: true

# =============================================================================
# åä½œé…ç½®
# =============================================================================
collaboration:
  # è¾©è®ºé…ç½®
  debate:
    max_rounds: 5
    min_arguments_per_round: 2
  
  # å…±è¯†é…ç½®
  consensus:
    default_threshold: 0.6
    max_negotiation_rounds: 3

# =============================================================================
# å·¥ä½œæµé…ç½®
# =============================================================================
workflow:
  # é»˜è®¤å·¥ä½œæµ
  default_workflow: "workflow_full_project"
  
  # è´¨é‡é—¨ç¦é»˜è®¤é…ç½®
  quality_gates:
    test_coverage_min: 0.80
    security_scan_required: true
    review_required: true

# =============================================================================
# å·¥å…·é…ç½®
# =============================================================================
tools:
  # ä»£ç æ‰§è¡Œå™¨
  code_executor:
    timeout: 30
    allowed_languages:
      - python
      - javascript
  
  # æ–‡ä»¶ç³»ç»Ÿ
  file_system:
    workspace: "./workspace"
  
  # ç»ˆç«¯
  terminal:
    timeout: 60
    allowed_commands:
      - ls
      - cat
      - grep
      - find
      - pip
      - npm
      - git

# =============================================================================
# æ—¥å¿—é…ç½®
# =============================================================================
logging:
  level: "INFO"
  format: "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
  file: "./logs/agent_team.log"
  max_size_mb: 100
  backup_count: 5

# =============================================================================
# ç›‘æ§é…ç½®
# =============================================================================
monitoring:
  enabled: true
  metrics_port: 9090
  health_check_interval: 30
16. å¿«é€Ÿå¼€å§‹è„šæœ¬ (scripts/quickstart.py)
#!/usr/bin/env python3
"""ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - å¿«é€Ÿå¼€å§‹è„šæœ¬.

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºå¦‚ä½•å¿«é€Ÿåˆ›å»ºå’Œä½¿ç”¨æ™ºèƒ½ä½“å›¢é˜Ÿã€‚

Usage:
    python scripts/quickstart.py --api-key YOUR_API_KEY
    python scripts/quickstart.py --provider anthropic --model claude-3-opus
"""

import argparse
import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from chairman_agents import (
    create_world_class_team,
    TeamConfig,
    TaskContext,
    OrchestratorConfig,
)
from chairman_agents.integration.llm import create_llm_client
from chairman_agents.cognitive.reasoning import ReasoningEngine
from chairman_agents.cognitive.memory import MemorySystem

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°."""
    parser = argparse.ArgumentParser(
        description="ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - å¿«é€Ÿå¼€å§‹"
    )
    parser.add_argument(
        "--provider",
        type=str,
        default="openai",
        choices=["openai", "anthropic"],
        help="LLMæä¾›å•†",
    )
    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="æ¨¡å‹åç§°",
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default=None,
        help="APIå¯†é’¥",
    )
    parser.add_argument(
        "--request",
        type=str,
        default=None,
        help="é¡¹ç›®è¯·æ±‚æè¿°",
    )
    parser.add_argument(
        "--interactive",
        action="store_true",
        help="äº¤äº’æ¨¡å¼",
    )
    
    return parser.parse_args()


async def run_demo(args):
    """è¿è¡Œæ¼”ç¤º."""
    
    print("\n" + "=" * 70)
    print("ğŸ† ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿç³»ç»Ÿ")
    print("=" * 70 + "\n")
    
    # 1. åˆ›å»ºLLMå®¢æˆ·ç«¯
    print("ğŸ“¡ åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...")
    llm_client = create_llm_client(
        provider=args.provider,
        model=args.model,
        api_key=args.api_key,
    )
    print(f"   âœ… ä½¿ç”¨ {args.provider} / {args.model or 'é»˜è®¤æ¨¡å‹'}")
    
    # 2. åˆ›å»ºè®¤çŸ¥ç»„ä»¶
    print("\nğŸ§  åˆå§‹åŒ–è®¤çŸ¥ç³»ç»Ÿ...")
    
    reasoning_engine = ReasoningEngine(
        llm_client=llm_client,
        default_strategy="chain_of_thought",
    )
    print("   âœ… æ¨ç†å¼•æ“å°±ç»ª")
    
    memory_system = MemorySystem(
        llm_client=llm_client,
        storage_path=Path("./data/memory"),
    )
    print("   âœ… è®°å¿†ç³»ç»Ÿå°±ç»ª")
    
    # 3. åˆ›å»ºå›¢é˜Ÿ
    print("\nğŸ‘¥ ç»„å»ºä¸–ç•Œçº§å›¢é˜Ÿ...")
    
    team_config = TeamConfig(
        include_pm=True,
        include_architect=True,
        include_backend=True,
        include_frontend=True,
        include_qa=True,
        include_security=True,
        include_devops=True,
        include_reviewer=True,
        include_tech_writer=True,
        num_backend=2,
        orchestrator_config=OrchestratorConfig(
            max_parallel_tasks=5,
            min_confidence_threshold=0.7,
            require_review=True,
        ),
    )
    
    team = create_world_class_team(
        llm_client=llm_client,
        reasoning_engine=reasoning_engine,
        memory_system=memory_system,
        config=team_config,
    )
    
    # æ‰“å°å›¢é˜Ÿä¿¡æ¯
    team.print_team_info()
    
    # 4. è·å–é¡¹ç›®è¯·æ±‚
    if args.request:
        request = args.request
    elif args.interactive:
        print("\nğŸ“ è¯·è¾“å…¥é¡¹ç›®éœ€æ±‚ï¼ˆè¾“å…¥ç©ºè¡Œç»“æŸï¼‰ï¼š")
        lines = []
        while True:
            line = input()
            if not line:
                break
            lines.append(line)
        request = "\n".join(lines)
    else:
        # é»˜è®¤æ¼”ç¤ºè¯·æ±‚
        request = """
        å¼€å‘ä¸€ä¸ªç®€å•çš„å¾…åŠäº‹é¡¹ï¼ˆTodoï¼‰APIï¼ŒåŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š
        
        1. åˆ›å»ºå¾…åŠäº‹é¡¹
        2. æŸ¥è¯¢å¾…åŠäº‹é¡¹åˆ—è¡¨
        3. æ›´æ–°å¾…åŠäº‹é¡¹çŠ¶æ€
        4. åˆ é™¤å¾…åŠäº‹é¡¹
        
        æŠ€æœ¯è¦æ±‚ï¼š
        - ä½¿ç”¨Python + FastAPI
        - ä½¿ç”¨SQLiteæ•°æ®åº“
        - åŒ…å«å•å…ƒæµ‹è¯•
        - æä¾›APIæ–‡æ¡£
        """
    
    if not request.strip():
        print("âŒ è¯·æ±‚ä¸èƒ½ä¸ºç©º")
        return
    
    # 5. å®šä¹‰ä¸Šä¸‹æ–‡
    context = TaskContext(
        project_name="TodoAPI",
        project_description=request,
        tech_stack={
            "backend": ["Python", "FastAPI", "SQLite"],
            "testing": ["pytest"],
        },
        coding_standards={
            "python": {
                "formatter": "black",
                "linter": "ruff",
                "type_checker": "mypy",
            },
        },
    )
    
    # 6. æ‰§è¡Œé¡¹ç›®
    print("\nğŸš€ å¼€å§‹æ‰§è¡Œé¡¹ç›®...")
    print("-" * 70)
    
    result = await team.execute(request, context)
    
    # 7. è¾“å‡ºç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š æ‰§è¡Œç»“æœ")
    print("=" * 70)
    
    print(f"\nâœ… çŠ¶æ€: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
    print(f"ğŸ“‹ è®¡åˆ’ID: {result['plan_id']}")
    print(f"ğŸ“Š é˜¶æ®µå®Œæˆ: {result['phases_completed']}/{result['total_phases']}")
    
    print(f"\nğŸ“¦ äº§å‡ºç‰© ({len(result['artifacts'])}ä¸ª):")
    for artifact in result['artifacts']:
        status = "âœ…" if artifact.get('approved') else ("ğŸ”" if artifact.get('reviewed') else "â³")
        print(f"   {status} {artifact['name']} ({artifact['type']})")
    
    print(f"\nğŸ“ˆ ä»»åŠ¡ç»Ÿè®¡:")
    summary = result['results_summary']
    print(f"   æ€»ä»»åŠ¡: {summary['total']}")
    print(f"   æˆåŠŸ: {summary['success']}")
    print(f"   å¤±è´¥: {summary['failed']}")
    
    # ä¿å­˜è®°å¿†
    memory_system.save_to_disk()
    print("\nğŸ’¾ è®°å¿†å·²ä¿å­˜")
    
    print("\n" + "=" * 70)
    print("ğŸ‰ æ‰§è¡Œå®Œæˆï¼")
    print("=" * 70 + "\n")
    
    return result


async def interactive_mode(args):
    """äº¤äº’æ¨¡å¼."""
    print("\n" + "=" * 70)
    print("ğŸ† ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿ - äº¤äº’æ¨¡å¼")
    print("=" * 70)
    print("\nå‘½ä»¤ï¼š")
    print("  new <æè¿°>  - åˆ›å»ºæ–°é¡¹ç›®")
    print("  status     - æŸ¥çœ‹å›¢é˜ŸçŠ¶æ€")
    print("  history    - æŸ¥çœ‹æ‰§è¡Œå†å²")
    print("  quit       - é€€å‡º")
    print("-" * 70 + "\n")
    
    # åˆå§‹åŒ–å›¢é˜Ÿ
    llm_client = create_llm_client(
        provider=args.provider,
        model=args.model,
        api_key=args.api_key,
    )
    team = create_world_class_team(llm_client=llm_client)
    
    history = []
    
    while True:
        try:
            command = input("\nğŸ‘‰ ").strip()
            
            if not command:
                continue
            
            if command.lower() == "quit":
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            elif command.lower() == "status":
                status = team.get_status()
                print(f"\nğŸ“Š å›¢é˜ŸçŠ¶æ€:")
                print(f"   æˆå‘˜æ•°: {status['team_size']}")
                for member in status['members']:
                    print(f"   - {member['name']}: {member['status']}")
            
            elif command.lower() == "history":
                if not history:
                    print("ğŸ“œ æš‚æ— æ‰§è¡Œå†å²")
                else:
                    print(f"\nğŸ“œ æ‰§è¡Œå†å² ({len(history)}æ¡):")
                    for i, h in enumerate(history, 1):
                        status = "âœ…" if h['success'] else "âŒ"
                        print(f"   {i}. {status} {h['plan_id']}")
            
            elif command.lower().startswith("new "):
                request = command[4:].strip()
                if request:
                    context = TaskContext(
                        project_name="InteractiveProject",
                        project_description=request,
                    )
                    result = await team.execute(request, context)
                    history.append(result)
                    
                    print(f"\nâœ… æ‰§è¡Œå®Œæˆ: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
                    print(f"   äº§å‡ºç‰©: {len(result['artifacts'])}ä¸ª")
                else:
                    print("âŒ è¯·æä¾›é¡¹ç›®æè¿°")
            
            else:
                print("â“ æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°."""
    args = parse_args()
    
    if args.interactive:
        asyncio.run(interactive_mode(args))
    else:
        asyncio.run(run_demo(args))


if __name__ == "__main__":
    main()
17. é¡¹ç›®ä¾èµ– (pyproject.toml ç‰‡æ®µ)
toml

[project]
name = "chairman-agents"
version = "1.0.0"
description = "ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿç³»ç»Ÿ - ä¸–ç•Œçº§å¤šæ™ºèƒ½ä½“åä½œå¼€å‘"
readme = "README.md"
requires-python = ">=3.11"
license = { text = "MIT" }

dependencies = [
    "openai>=1.0.0",
    "anthropic>=0.18.0",
    "pydantic>=2.0.0",
    "aiohttp>=3.9.0",
    "asyncio>=3.4.3",
    "pyyaml>=6.0.0",
    "rich>=13.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "mypy>=1.7.0",
    "ruff>=0.1.6",
]

all = [
    "chairman-agents[dev]",
]

[project.scripts]
chairman = "chairman_agents.cli:main"
ğŸ“‹ æœ€ç»ˆç³»ç»Ÿæ¶æ„å›¾

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ† ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿç³»ç»Ÿæ¶æ„                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                           ç”¨æˆ·å±‚                                     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚
â”‚  â”‚  â”‚   CLI    â”‚  â”‚   API    â”‚  â”‚   SDK    â”‚  â”‚   Web    â”‚            â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚          â”‚              â”‚              â”‚              â”‚                     â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                  â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                          å›¢é˜Ÿå±‚ (team.py)                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  AgentTeam - å›¢é˜Ÿç®¡ç†                                           â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”œâ”€â”€ create_world_class_team() - ä¸€é”®åˆ›å»º                       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”œâ”€â”€ execute() - æ‰§è¡Œè¯·æ±‚                                       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€ get_status() - çŠ¶æ€æŸ¥è¯¢                                    â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        ç¼–æ’å±‚ (orchestrator.py)                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚   â”‚
â”‚  â”‚  â”‚  ä»»åŠ¡åˆ†é…   â”‚  â”‚  å¹¶è¡Œæ‰§è¡Œ   â”‚  â”‚  æ•…éšœæ¢å¤   â”‚                   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        å·¥ä½œæµå±‚ (workflow/)                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚   â”‚
â”‚  â”‚  â”‚  å·¥ä½œæµå¼•æ“  â”‚  â”‚  è´¨é‡é—¨ç¦   â”‚  â”‚  é¢„å®šä¹‰æµç¨‹  â”‚                   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        æ™ºèƒ½ä½“å±‚ (agents/)                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚  â”‚  â”‚   PM    â”‚ â”‚ æ¶æ„å¸ˆ  â”‚ â”‚  åç«¯   â”‚ â”‚  å‰ç«¯   â”‚ â”‚  æµ‹è¯•   â”‚        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚   â”‚
â”‚  â”‚  â”‚  å®‰å…¨   â”‚ â”‚ DevOps  â”‚ â”‚  å®¡æŸ¥   â”‚ â”‚  æ–‡æ¡£   â”‚                    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚               â”‚               â”‚               â”‚                       â”‚  â”‚
â”‚  â–¼               â–¼               â–¼               â–¼                       â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚ è®¤çŸ¥å±‚  â”‚ â”‚  åä½œå±‚     â”‚ â”‚   å·¥å…·å±‚    â”‚ â”‚   é›†æˆå±‚    â”‚            â”‚  â”‚
â”‚  â”‚cognitiveâ”‚ â”‚collaborationâ”‚ â”‚   tools     â”‚ â”‚ integration â”‚            â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚  â”‚
â”‚  â”‚â€¢ æ¨ç†   â”‚ â”‚â€¢ è¾©è®º       â”‚ â”‚â€¢ ä»£ç æ‰§è¡Œ   â”‚ â”‚â€¢ OpenAI     â”‚            â”‚  â”‚
â”‚  â”‚â€¢ è®°å¿†   â”‚ â”‚â€¢ å…±è¯†       â”‚ â”‚â€¢ æ–‡ä»¶ç³»ç»Ÿ   â”‚ â”‚â€¢ Anthropic  â”‚            â”‚  â”‚
â”‚  â”‚â€¢ åæ€   â”‚ â”‚â€¢ ç»“å¯¹ç¼–ç¨‹   â”‚ â”‚â€¢ Git        â”‚ â”‚â€¢ æœ¬åœ°æ¨¡å‹
â”‚  â”‚â€¢ è§„åˆ’   â”‚ â”‚â€¢ ä»£ç å®¡æŸ¥   â”‚ â”‚â€¢ ç»ˆç«¯       â”‚ â”‚â€¢ è·¯ç”±/æ•…éšœ  â”‚            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚                                                                          â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                          æ ¸å¿ƒå±‚ (core/)                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚
â”‚  â”‚  â”‚ 18ç§è§’è‰²å®šä¹‰ â”‚  â”‚ 35ç§èƒ½åŠ›å®šä¹‰   â”‚  â”‚ ç±»å‹/åè®®    â”‚                â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š ç³»ç»Ÿèƒ½åŠ›çŸ©é˜µ

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ç³»ç»Ÿèƒ½åŠ›çŸ©é˜µ                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       èƒ½åŠ›åŸŸ        â”‚  åŸºç¡€ç‰ˆ   â”‚  æ ‡å‡†ç‰ˆ   â”‚  ä¸»å¸­çº§   â”‚      è¯´æ˜          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è§’è‰²æ•°é‡            â”‚    5      â”‚    11     â”‚    18     â”‚ ä¸“ä¸šåˆ†å·¥æ›´ç»†       â”‚
â”‚ èƒ½åŠ›å®šä¹‰            â”‚    8      â”‚    14     â”‚    35     â”‚ èƒ½åŠ›åŒ¹é…æ›´ç²¾å‡†     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ¨ç†èƒ½åŠ›            â”‚    âŒ     â”‚    âœ…     â”‚   âœ…âœ…âœ…  â”‚ æ€ç»´é“¾+æ ‘+åæ€     â”‚
â”‚ è®°å¿†ç³»ç»Ÿ            â”‚    âŒ     â”‚    âœ…     â”‚   âœ…âœ…âœ…  â”‚ çŸ­æœŸ+é•¿æœŸ+è¯­ä¹‰     â”‚
â”‚ è§„åˆ’èƒ½åŠ›            â”‚    âŒ     â”‚    âœ…     â”‚   âœ…âœ…    â”‚ å¤šæ­¥è§„åˆ’           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¾©è®ºç³»ç»Ÿ            â”‚    âŒ     â”‚    âŒ     â”‚   âœ…âœ…âœ…  â”‚ å¤šè½®è¾©è®º+åé©³      â”‚
â”‚ å…±è¯†æœºåˆ¶            â”‚    âŒ     â”‚    âŒ     â”‚   âœ…âœ…âœ…  â”‚ æŠ•ç¥¨+åå•†          â”‚
â”‚ ç»“å¯¹ç¼–ç¨‹            â”‚    âŒ     â”‚    âŒ     â”‚   âœ…âœ…    â”‚ å®æ—¶åä½œ           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¹¶è¡Œæ‰§è¡Œ            â”‚    âŒ     â”‚    âœ…     â”‚   âœ…âœ…âœ…  â”‚ ä»»åŠ¡+é˜¶æ®µå¹¶è¡Œ      â”‚
â”‚ è´¨é‡é—¨ç¦            â”‚    âŒ     â”‚    âœ…     â”‚   âœ…âœ…âœ…  â”‚ 6å±‚æ£€æŸ¥            â”‚
â”‚ æ•…éšœæ¢å¤            â”‚    âŒ     â”‚    âœ…     â”‚   âœ…âœ…    â”‚ è‡ªåŠ¨é‡è¯•+é™çº§      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å·¥å…·ä½¿ç”¨            â”‚    âŒ     â”‚    âœ…     â”‚   âœ…âœ…âœ…  â”‚ ä»£ç +Git+ç»ˆç«¯      â”‚
â”‚ LLMé›†æˆ             â”‚    âœ…     â”‚    âœ…     â”‚   âœ…âœ…âœ…  â”‚ å¤šæä¾›å•†+è·¯ç”±      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å·¥ä½œæµæ•°é‡          â”‚    1      â”‚    3      â”‚    8+     â”‚ å¯è‡ªå®šä¹‰           â”‚
â”‚ è‡ªåŠ¨åŒ–ç¨‹åº¦          â”‚   30%     â”‚   70%     â”‚   95%     â”‚ å‡ ä¹å…¨è‡ªåŠ¨         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸš€ éƒ¨ç½²æŒ‡å— æœ¬åœ°å¼€å‘ 

# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/chairman/agent-team.git
cd agent-team

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# 3. å®‰è£…ä¾èµ–
pip install -e ".[dev]"

# 4. é…ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="sk-xxx"
# æˆ–
export ANTHROPIC_API_KEY="sk-xxx"

# 5. è¿è¡Œå¿«é€Ÿå¼€å§‹
python scripts/quickstart.py

# 6. è¿è¡Œæµ‹è¯•
pytest tests/ -v
Dockeréƒ¨ç½² dockerfile å¤åˆ¶ä»£ç   # Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY pyproject.toml .
COPY src/ ./src/

RUN pip install --no-cache-dir -e .

# åˆ›å»ºæ•°æ®ç›®å½•
RUN mkdir -p /app/data/memory /app/logs /app/workspace

ENV PYTHONUNBUFFERED=1

CMD ["python", "-m", "chairman_agents.api.server"]
 # docker-compose.yml
version: '3.8'

services:
  agent-team:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./workspace:/app/workspace
    restart: unless-stopped
    ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡
  
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           æ€§èƒ½åŸºå‡†æµ‹è¯•                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           æŒ‡æ ‡                   â”‚                æ•°å€¼                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç®€å•ä»»åŠ¡å¹³å‡å®Œæˆæ—¶é—´            â”‚ 30-60ç§’                                   â”‚
â”‚ å¤æ‚é¡¹ç›®å¹³å‡å®Œæˆæ—¶é—´            â”‚ 5-15åˆ†é’Ÿ                                  â”‚
â”‚ å¹¶è¡Œä»»åŠ¡å¤„ç†èƒ½åŠ›                â”‚ æœ€å¤š5ä¸ªä»»åŠ¡åŒæ—¶æ‰§è¡Œ                       â”‚
â”‚ å•ä»»åŠ¡Tokenæ¶ˆè€—                 â”‚ 2000-8000 tokens                         â”‚
â”‚ ä»£ç ç”Ÿæˆå‡†ç¡®ç‡                  â”‚ 85-95%ï¼ˆéœ€äººå·¥å¾®è°ƒï¼‰                      â”‚
â”‚ æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡                  â”‚ 80%+                                     â”‚
â”‚ ä»£ç å®¡æŸ¥å‘ç°é—®é¢˜ç‡              â”‚ 70-90%                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è®°å¿†ç³»ç»Ÿå®¹é‡                    â”‚ çŸ­æœŸ100æ¡ï¼Œé•¿æœŸ10000æ¡                    â”‚
â”‚ è¾©è®ºæ”¶æ•›è½®æ•°                    â”‚ å¹³å‡2-3è½®                                â”‚
â”‚ å…±è¯†è¾¾æˆç‡                      â”‚ 85%+                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


    ğŸ‰ æ€»ç»“ 
    
    æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¸–ç•Œçº§çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œå®ƒå…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š
    
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                             â”‚
â”‚                     ğŸ† ä¸»å¸­çº§æ™ºèƒ½ä½“å›¢é˜Ÿç³»ç»Ÿ ğŸ†                               â”‚
â”‚                                                                             â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚                                                                             â”‚
â”‚  è¿™æ˜¯ä¸€ä¸ªä¸–ç•Œçº§çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š                                     â”‚
â”‚                                                                             â”‚
â”‚  âœ… è‡ªä¸»å®Œæˆä»éœ€æ±‚åˆ†æåˆ°éƒ¨ç½²çš„å…¨æµç¨‹è½¯ä»¶å¼€å‘                                 â”‚
â”‚  âœ… 18ç§ä¸“ä¸šè§’è‰²åˆ†å·¥åä½œï¼Œè¦†ç›–è½¯ä»¶å¼€å‘å…¨ç”Ÿå‘½å‘¨æœŸ                             â”‚
â”‚  âœ… æ·±åº¦æ¨ç†èƒ½åŠ›ï¼šæ€ç»´é“¾ã€æ€ç»´æ ‘ã€è‡ªæˆ‘åæ€                                   â”‚
â”‚  âœ… è®°å¿†ç³»ç»Ÿï¼šçŸ­æœŸã€é•¿æœŸã€æƒ…æ™¯ã€è¯­ä¹‰è®°å¿†                                     â”‚
â”‚  âœ… åä½œæœºåˆ¶ï¼šè¾©è®ºã€å…±è¯†ã€ç»“å¯¹ç¼–ç¨‹ã€ä»£ç å®¡æŸ¥                                 â”‚
â”‚  âœ… è´¨é‡ä¿è¯ï¼š6å±‚è´¨é‡é—¨ç¦ï¼Œ95%è‡ªåŠ¨åŒ–ç¨‹åº¦                                     â”‚
â”‚  âœ… å·¥å…·ä½¿ç”¨ï¼šä»£ç æ‰§è¡Œã€æ–‡ä»¶æ“ä½œã€Gitã€ç»ˆç«¯                                  â”‚
â”‚  âœ… çµæ´»é›†æˆï¼šæ”¯æŒOpenAIã€Anthropicç­‰å¤šç§LLM                                â”‚
â”‚                                                                             â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚                                                                             â”‚
â”‚  ğŸ“¦ æ¨¡å—æ¸…å•ï¼š                                                               â”‚
â”‚  â”œâ”€â”€ core/types.py           âœ… æ ¸å¿ƒç±»å‹å®šä¹‰                                â”‚
â”‚  â”œâ”€â”€ cognitive/reasoning.py  âœ… æ¨ç†å¼•æ“                                    â”‚
â”‚  â”œâ”€â”€ cognitive/memory.py     âœ… è®°å¿†ç³»ç»Ÿ                                    â”‚
â”‚  â”œâ”€â”€ collaboration/debate.py âœ… è¾©è®ºç³»ç»Ÿ                                    â”‚
â”‚  â”œâ”€â”€ collaboration/consensus.py âœ… å…±è¯†æœºåˆ¶                                 â”‚
â”‚  â”œâ”€â”€ agents/base.py          âœ… åŸºç¡€æ™ºèƒ½ä½“                                  â”‚
â”‚  â”œâ”€â”€ agents/experts/*.py     âœ… ä¸“ä¸šæ™ºèƒ½ä½“                                  â”‚
â”‚  â”œâ”€â”€ orchestration/orchestrator.py âœ… ç¼–æ’å™¨                                â”‚
â”‚  â”œâ”€â”€ workflow/engine.py      âœ… å·¥ä½œæµå¼•æ“                                  â”‚
â”‚  â”œâ”€â”€ integration/llm.py      âœ… LLMé›†æˆ                                     â”‚
â”‚  â”œâ”€â”€ tools/executor.py       âœ… å·¥å…·æ‰§è¡Œå™¨                                  â”‚
â”‚  â”œâ”€â”€ team.py                 âœ… å›¢é˜Ÿå·¥å‚                                    â”‚
â”‚  â””â”€â”€ __init__.py             âœ… ä¸»å…¥å£                                      â”‚
â”‚                                                                             â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚                                                                             â”‚
â”‚  ğŸš€ å¿«é€Ÿå¼€å§‹ï¼š                                                               â”‚
â”‚                                                                             â”‚
â”‚  from chairman_agents import create_world_class_team                        â”‚
â”‚  from chairman_agents.integration.llm import create_llm_client              â”‚
â”‚                                                                             â”‚
â”‚  llm = create_llm_client(provider="openai", api_key="...")                 â”‚
â”‚  team = create_world_class_team(llm_client=llm)                            â”‚
â”‚  result = await team.execute("å¼€å‘ä¸€ä¸ªç”¨æˆ·ç®¡ç†ç³»ç»Ÿ")                         â”‚
â”‚                                                                             â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚                                                                             â”‚
â”‚                        ä¸ºä¸»å¸­æ‰“é€ ï¼Œå“è´¨ä¿è¯ï¼                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜







ğŸ” ç³»ç»Ÿè‡ªæ£€æŠ¥å‘Š
ğŸ“Š è‡ªæ£€æ€»è§ˆ

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ç³»ç»Ÿè‡ªæ£€æŠ¥å‘Š                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
âŒ ä¸¥é‡é—®é¢˜ (å¿…é¡»ä¿®å¤)
1. ç¼ºå¤±çš„å…³é”®æ¨¡å—

# ä»¥ä¸‹æ¨¡å—è¢«å¼•ç”¨ä½†æœªå®ç°ï¼š

# âŒ core/config.py - é…ç½®ç®¡ç†
# âŒ core/exceptions.py - è‡ªå®šä¹‰å¼‚å¸¸
# âŒ collaboration/pair_programming.py - ç»“å¯¹ç¼–ç¨‹
# âŒ api/server.py - APIæœåŠ¡
# âŒ observability/ - ç›‘æ§è¿½è¸ª
2. ä¸“ä¸šæ™ºèƒ½ä½“å®ç°ä¸å®Œæ•´

# è¿™äº›æ™ºèƒ½ä½“åªæœ‰å·¥å‚å‡½æ•°çš„éª¨æ¶ï¼Œæ²¡æœ‰çœŸæ­£å®ç°ï¼š

# âš ï¸ FrontendEngineerAgent - _execute_step æ˜¯ç©ºçš„
# âš ï¸ FullstackEngineerAgent - _execute_step æ˜¯ç©ºçš„
# âš ï¸ QAEngineerAgent - _execute_step æ˜¯ç©ºçš„
# âš ï¸ SecurityArchitectAgent - _execute_step æ˜¯ç©ºçš„
# âš ï¸ DevOpsEngineerAgent - _execute_step æ˜¯ç©ºçš„
# âš ï¸ CodeReviewerAgent - _execute_step æ˜¯ç©ºçš„
# âš ï¸ TechWriterAgent - _execute_step æ˜¯ç©ºçš„

# é—®é¢˜ä»£ç ç¤ºä¾‹ï¼ˆåœ¨ team.py ä¸­ï¼‰:
class FrontendEngineerAgent(BaseAgent):
    async def _execute_step(self, step, task, context):
        return {"result": "æ­¥éª¤å®Œæˆ"}  # âŒ è¿™æ˜¯ç©ºå®ç°ï¼
    
    async def _generate_final_output(self, task, context, plan, artifacts):
        return None  # âŒ è¿™ä¹Ÿæ˜¯ç©ºå®ç°ï¼
3. æ¨ç†å¼•æ“çš„å…³é”®æ–¹æ³•æœªå®ç°

# cognitive/reasoning.py ä¸­çš„é—®é¢˜ï¼š

def _trace_path(self, node: ThoughtNode, root: ThoughtNode) -> list[ThoughtNode]:
    """è¿½æº¯ä»æ ¹åˆ°èŠ‚ç‚¹çš„è·¯å¾„."""
    path = [node]
    current = node
    
    # âŒ è¿™é‡Œåªæ˜¯è¿”å›äº†å½“å‰èŠ‚ç‚¹ï¼Œæ²¡æœ‰çœŸæ­£è¿½æº¯è·¯å¾„ï¼
    # ç®€åŒ–å®ç°ï¼šå‡è®¾å¯ä»¥é€šè¿‡parent_idæ‰¾åˆ°çˆ¶èŠ‚ç‚¹
    # å®é™…å®ç°éœ€è¦ç»´æŠ¤èŠ‚ç‚¹ç´¢å¼•
    
    return path  # âŒ æ°¸è¿œåªè¿”å›ä¸€ä¸ªèŠ‚ç‚¹çš„åˆ—è¡¨
4. ç±»å‹ä¸ä¸€è‡´

# é—®é¢˜1: ä¸¤ä¸ªç±»ä¼¼çš„ä¸Šä¸‹æ–‡ç±»
# core/types.py
@dataclass
class TaskContext:  # ä½¿ç”¨è¿™ä¸ª
    project_name: str = ""
    ...

# ä½†åœ¨æŸäº›åœ°æ–¹å¯èƒ½æœ‰ ExecutionContext çš„å¼•ç”¨

# é—®é¢˜2: AgentId ç±»å‹ä½¿ç”¨ä¸ä¸€è‡´
AgentId: TypeAlias = str  # å®šä¹‰äº†åˆ«å

# ä½†æœ‰äº›åœ°æ–¹ç›´æ¥ç”¨ strï¼š
assigned_to: str | None = None  # âŒ åº”è¯¥ç”¨ AgentId
âš ï¸ ä¸­ç­‰é—®é¢˜ (åº”è¯¥ä¿®å¤)
1. æ²¡æœ‰çœŸæ­£çš„å·¥å…·é›†æˆ

# tools/executor.py ä¸­çš„é—®é¢˜ï¼š

async def _run_quality_check(self, check, context, execution):
    """è¿è¡Œè´¨é‡æ£€æŸ¥."""
    
    if check.check_type == "lint":
        result["passed"] = True  # âŒ å‡çš„ï¼æ²¡æœ‰çœŸæ­£è¿è¡Œ ruff
        result["details"] = "ä»£ç æ£€æŸ¥é€šè¿‡"
    
    elif check.check_type == "test":
        result["passed"] = True  # âŒ å‡çš„ï¼æ²¡æœ‰çœŸæ­£è¿è¡Œ pytest
        result["details"] = "æµ‹è¯•é€šè¿‡"
    
    elif check.check_type == "coverage":
        actual_coverage = 0.85  # âŒ å‡çš„ï¼ç¡¬ç¼–ç çš„è¦†ç›–ç‡
2. è®°å¿†ç³»ç»Ÿç›¸å…³æ€§è®¡ç®—è¿‡äºç®€å•

# cognitive/memory.py ä¸­çš„é—®é¢˜ï¼š

def _calculate_relevance(self, query: str, memory: MemoryItem) -> float:
    """è®¡ç®—æŸ¥è¯¢ä¸è®°å¿†çš„ç›¸å…³æ€§."""
    # âŒ è¿™åªæ˜¯ç®€å•çš„å…³é”®è¯é‡å ï¼Œå®é™…åº”è¯¥ç”¨å‘é‡åµŒå…¥
    query_words = set(query.lower().split())
    memory_words = set(memory.content.lower().split())
    
    overlap = len(query_words & memory_words)
    # è¿™ç§æ–¹æ³•å¯¹äºä¸­æ–‡å‡ ä¹æ— æ•ˆï¼
3. è¾©è®º/å…±è¯†ç³»ç»Ÿçš„è§£æå¯èƒ½å¤±è´¥

# collaboration/debate.py ä¸­çš„é—®é¢˜ï¼š

def _parse_argument(self, agent_id, position, response):
    """è§£æè®ºç‚¹å“åº”."""
    # âŒ å¦‚æœLLMæ²¡æœ‰æŒ‰æ ¼å¼è¿”å›ï¼Œè¿™é‡Œä¼šè¿”å›ç©ºçš„è®ºç‚¹
    for line in response.strip().split("\n"):
        if line.startswith("ä¸»è¦è®ºç‚¹"):
            argument.main_argument = line.split("ï¼š", 1)[-1].strip()
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°"ä¸»è¦è®ºç‚¹ï¼š"ï¼Œargument.main_argument è¿˜æ˜¯ç©ºå­—ç¬¦ä¸²
    # æ²¡æœ‰é”™è¯¯å¤„ç†ï¼
4. ç¼ºå°‘é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
python
å¤åˆ¶ä»£ç 
# å¾ˆå¤šåœ°æ–¹ç¼ºå°‘å¼‚å¸¸å¤„ç†ï¼š

# âŒ LLMè°ƒç”¨æ²¡æœ‰å¤„ç†ç½‘ç»œé”™è¯¯
response = await self._llm.generate(prompt)  # å¦‚æœç½‘ç»œå¤±è´¥ï¼Ÿ

# âŒ æ–‡ä»¶æ“ä½œæ²¡æœ‰å¤„ç†æƒé™é”™è¯¯
path.write_text(content)  # å¦‚æœæ²¡æœ‰å†™æƒé™ï¼Ÿ

# âŒ å·¥å…·æ‰§è¡Œæ²¡æœ‰å¤„ç†è¶…æ—¶åçš„æ¸…ç†
process.kill()  # è¿›ç¨‹å¯èƒ½è¿˜æœ‰å­è¿›ç¨‹
ğŸ“ éœ€è¦è¡¥å……çš„ä»£ç 
1. è¡¥å…… core/exceptions.py

"""è‡ªå®šä¹‰å¼‚å¸¸å®šä¹‰."""

class ChairmanAgentError(Exception):
    """åŸºç¡€å¼‚å¸¸ç±»."""
    pass


class LLMError(ChairmanAgentError):
    """LLMè°ƒç”¨é”™è¯¯."""
    pass


class LLMRateLimitError(LLMError):
    """é€Ÿç‡é™åˆ¶é”™è¯¯."""
    pass


class LLMTimeoutError(LLMError):
    """è¶…æ—¶é”™è¯¯."""
    pass


class AgentError(ChairmanAgentError):
    """æ™ºèƒ½ä½“é”™è¯¯."""
    pass


class TaskExecutionError(AgentError):
    """ä»»åŠ¡æ‰§è¡Œé”™è¯¯."""
    pass


class WorkflowError(ChairmanAgentError):
    """å·¥ä½œæµé”™è¯¯."""
    pass


class QualityGateError(WorkflowError):
    """è´¨é‡é—¨ç¦æœªé€šè¿‡."""
    pass


class ToolError(ChairmanAgentError):
    """å·¥å…·æ‰§è¡Œé”™è¯¯."""
    pass


class ConfigurationError(ChairmanAgentError):
    """é…ç½®é”™è¯¯."""
    pass
1. è¡¥å…… core/config.py

"""é…ç½®ç®¡ç†."""

from __future__ import annotations

import os
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

import yaml


@dataclass
class Config:
    """ç³»ç»Ÿé…ç½®."""
    
    # LLMé…ç½®
    llm_provider: str = "openai"
    llm_model: str = "gpt-4"
    llm_api_key: str | None = None
    llm_temperature: float = 0.7
    llm_max_tokens: int = 4096
    
    # å›¢é˜Ÿé…ç½®
    team_size: dict[str, int] = field(default_factory=dict)
    
    # ç¼–æ’é…ç½®
    max_parallel_tasks: int = 5
    max_retries: int = 3
    task_timeout: int = 300
    
    # è´¨é‡é…ç½®
    min_confidence: float = 0.7
    require_review: bool = True
    min_test_coverage: float = 0.8
    
    # è·¯å¾„é…ç½®
    workspace_path: Path = Path("./workspace")
    memory_path: Path = Path("./data/memory")
    log_path: Path = Path("./logs")
    
    @classmethod
    def from_yaml(cls, path: str | Path) -> Config:
        """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®."""
        with open(path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
        return cls._from_dict(data)
    
    @classmethod
    def from_env(cls) -> Config:
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®."""
        return cls(
            llm_provider=os.getenv("LLM_PROVIDER", "openai"),
            llm_model=os.getenv("LLM_MODEL", "gpt-4"),
            llm_api_key=os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY"),
            max_parallel_tasks=int(os.getenv("MAX_PARALLEL_TASKS", "5")),
        )
    
    @classmethod
    def _from_dict(cls, data: dict[str, Any]) -> Config:
        """ä»å­—å…¸åˆ›å»ºé…ç½®."""
        config = cls()
        
        if "llm" in data:
            llm = data["llm"]
            config.llm_provider = llm.get("provider", config.llm_provider)
            config.llm_model = llm.get("model", config.llm_model)
            config.llm_temperature = llm.get("temperature", config.llm_temperature)
        
        if "orchestrator" in data:
            orch = data["orchestrator"]
            config.max_parallel_tasks = orch.get("max_parallel_tasks", config.max_parallel_tasks)
            config.max_retries = orch.get("max_retries", config.max_retries)
        
        return config


# å…¨å±€é…ç½®å®ä¾‹
_config: Config | None = None


def get_config() -> Config:
    """è·å–å…¨å±€é…ç½®."""
    global _config
    if _config is None:
        _config = Config.from_env()
    return _config


def set_config(config: Config) -> None:
    """è®¾ç½®å…¨å±€é…ç½®."""
    global _config
    _config = config
3. ä¿®å¤ _trace_path æ–¹æ³•

# cognitive/reasoning.py ä¸­ä¿®å¤

async def _tree_of_thought(self, problem, context, max_steps):
    """æ€ç»´æ ‘æ¨ç† - ä¿®å¤ç‰ˆ."""
    
    # ç»´æŠ¤èŠ‚ç‚¹ç´¢å¼•
    node_index: dict[str, ThoughtNode] = {}
    
    root = ThoughtNode(id="root", thought=problem, depth=0)
    node_index[root.id] = root
    
    # ... åœ¨ç”Ÿæˆå­èŠ‚ç‚¹æ—¶æ›´æ–°ç´¢å¼• ...
    for child in children:
        node_index[child.id] = child
    
    # ä½¿ç”¨ä¿®å¤åçš„ _trace_path
    best_path = self._trace_path(best_node, root, node_index)


def _trace_path(
    self, 
    node: ThoughtNode, 
    root: ThoughtNode,
    node_index: dict[str, ThoughtNode],
) -> list[ThoughtNode]:
    """è¿½æº¯ä»æ ¹åˆ°èŠ‚ç‚¹çš„è·¯å¾„ - ä¿®å¤ç‰ˆ."""
    path = []
    current = node
    
    while current is not None:
        path.append(current)
        if current.id == root.id:
            break
        if current.parent_id:
            current = node_index.get(current.parent_id)
        else:
            break
    
    # åè½¬å¾—åˆ°ä»æ ¹åˆ°å¶çš„è·¯å¾„
    path.reverse()
    return path
4. è¡¥å……çœŸæ­£çš„ä»£ç è´¨é‡æ£€æŸ¥

# quality/linter.py

"""çœŸæ­£çš„ä»£ç è´¨é‡æ£€æŸ¥."""

import asyncio
import subprocess
from dataclasses import dataclass
from pathlib import Path


@dataclass
class LintResult:
    """æ£€æŸ¥ç»“æœ."""
    passed: bool = False
    score: float = 0.0
    issues: list[str] = None
    details: str = ""


async def run_ruff(file_path: Path) -> LintResult:
    """è¿è¡ŒRuffæ£€æŸ¥."""
    try:
        process = await asyncio.create_subprocess_exec(
            "ruff", "check", str(file_path), "--output-format=json",
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await process.communicate()
        
        if process.returncode == 0:
            return LintResult(passed=True, score=1.0, issues=[], details="æ— é—®é¢˜")
        else:
            import json
            issues = json.loads(stdout.decode())
            return LintResult(
                passed=False,
                score=0.0,
                issues=[f"{i['code']}: {i['message']}" for i in issues],
                details=f"å‘ç° {len(issues)} ä¸ªé—®é¢˜",
            )
    except FileNotFoundError:
        return LintResult(passed=False, details="Ruffæœªå®‰è£…")


async def run_mypy(file_path: Path) -> LintResult:
    """è¿è¡ŒMyPyç±»å‹æ£€æŸ¥."""
    try:
        process = await asyncio.create_subprocess_exec(
            "mypy", str(file_path), "--no-error-summary",
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await process.communicate()
        
        output = stdout.decode()
        if process.returncode == 0:
            return LintResult(passed=True, score=1.0, details="ç±»å‹æ£€æŸ¥é€šè¿‡")
        else:
            issues = [line for line in output.split("\n") if line.strip()]
            return LintResult(
                passed=False,
                score=0.0,
                issues=issues,
                details=f"å‘ç° {len(issues)} ä¸ªç±»å‹é”™è¯¯",
            )
    except FileNotFoundError:
        return LintResult(passed=False, details="MyPyæœªå®‰è£…")


async def run_pytest(test_path: Path) -> LintResult:
    """è¿è¡ŒPytestæµ‹è¯•."""
    try:
        process = await asyncio.create_subprocess_exec(
            "pytest", str(test_path), "-v", "--tb=short",
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await process.communicate()
        
        output = stdout.decode()
        passed = process.returncode == 0
        
        # è§£ææµ‹è¯•ç»“æœ
        # ä¾‹å¦‚: "5 passed, 1 failed"
        
        return LintResult(
            passed=passed,
            score=1.0 if passed else 0.0,
            details=output[-500:] if len(output) > 500 else output,
        )
    except FileNotFoundError:
        return LintResult(passed=False, details="Pytestæœªå®‰è£…")
ğŸ”§ ä¿®å¤åçš„å®Œæ•´æ€§æ£€æŸ¥

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ä¿®å¤åçš„æ¨¡å—å®Œæ•´æ€§                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  core/                                                                      â”‚
â”‚  â”œâ”€â”€ types.py               ğŸ”´ P0 - ç«‹å³ä¿®å¤                                       â”‚
â”‚  â”œâ”€â”€ config.py             âš ï¸  éœ€è¡¥å……                          â”‚
â”‚  â”œâ”€â”€ exceptions.py         âš ï¸  éœ€è¡¥å……                          â”‚
â”‚  â””â”€â”€ constants.py          âŒ æœªå®ç°                                        â”‚
â”‚                                                                             â”‚
â”‚  cognitive/                ğŸ”´ P0 - ç«‹å³ä¿®å¤                                                 â”‚
â”‚  â”œâ”€â”€ reasoning.py          âš ï¸  éœ€ä¿®å¤ _trace_pathï¼ˆ             â”‚
â”‚  â”œâ”€â”€ memory.py             âš ï¸  ç›¸å…³æ€§è®¡ç®—éœ€ä¼˜åŒ–                              â”‚
â”‚  â”œâ”€â”€ planning.py           âŒ æœªå®ç°                                        â”‚
â”‚  â””â”€â”€ learning.py           âŒ æœªå®ç°                                        â”‚
â”‚                                                                             â”‚
â”‚  agents/                                                                    â”‚
â”‚  â”œâ”€â”€ base.py                 ğŸ”´ P0 - ç«‹å³ä¿®å¤                                       â”‚
â”‚  â”œâ”€â”€ experts/pm.py           ğŸ”´ P0 - ç«‹å³ä¿®å¤                                        â”‚
â”‚  â”œâ”€â”€ experts/architect.py   ğŸ”´ P0 - ç«‹å³ä¿®å¤                                         â”‚
â”‚  â”œâ”€â”€ experts/backend.py     ğŸ”´ P0 - ç«‹å³ä¿®å¤                                         â”‚
â”‚  â”œâ”€â”€ experts/frontend.py   âš ï¸  éœ€å®Œæ•´å®ç°                                   â”‚
â”‚  â”œâ”€â”€ experts/qa.py         âš ï¸  éœ€å®Œæ•´å®ç°                                   â”‚
â”‚  â”œâ”€â”€ experts/security.py   âš ï¸  éœ€å®Œæ•´å®ç°                                   â”‚
â”‚  â”œâ”€â”€ experts/devops.py     âš ï¸  éœ€å®Œæ•´å®ç°                                   â”‚
â”‚  â”œâ”€â”€ experts/reviewer.py   âš ï¸  éœ€å®Œæ•´å®ç°                                   â”‚
â”‚  â””â”€â”€ experts/tech_writer.py âš ï¸  éœ€å®Œæ•´å®ç°                                  â”‚
â”‚                                                                             â”‚
â”‚  collaboration/                                                             â”‚
â”‚  â”œâ”€â”€ debate.py             âš ï¸  éœ€å¢å¼ºè§£æå®¹é”™                                â”‚
â”‚  â”œâ”€â”€ consensus.py          âš ï¸  éœ€å¢å¼ºè§£æå®¹é”™                                â”‚
â”‚  â”œâ”€â”€ pair_programming.py   âŒ æœªå®ç°                                        â”‚
â”‚  â””â”€â”€ code_review.py        âŒ æœªå®ç°                                        â”‚
â”‚                                                                             â”‚
â”‚  orchestration/            ğŸ”´ P0 - ç«‹å³ä¿®å¤                                                 â”‚
â”‚  â”œâ”€â”€ orchestrator.py       ğŸ”´ P0 - ç«‹å³ä¿®å¤                                         â”‚
â”‚  â”œâ”€â”€ scheduler.py          âŒ æœªå®ç°                                        â”‚
â”‚  â””â”€â”€ resource.py           âŒ æœªå®ç°                                        â”‚
â”‚                                                                             â”‚
â”‚  workflow/                                                                  â”‚
â”‚  â”œâ”€â”€ engine.py             âš ï¸                           â”‚
â”‚  â”œâ”€â”€ templates.py          ğŸ”´ P0 - ç«‹å³ä¿®å¤                                          â”‚
â”‚  â””â”€â”€ gates.py              âš ï¸  éœ€çœŸæ­£é›†æˆå·¥å…·                                â”‚
â”‚                                                                             â”‚
â”‚  integration/                                                               â”‚
â”‚  â”œâ”€â”€ llm.py                 ğŸ”´ P0 - ç«‹å³ä¿®å¤                                       â”‚
â”‚  â””â”€â”€ external/             âŒ æœªå®ç°                                        â”‚
â”‚                                                                             â”‚
â”‚  tools/                                                                     â”‚
â”‚  â”œâ”€â”€ executor.py           ğŸ”´ P0 - ç«‹å³ä¿®å¤                                       â”‚
â”‚  â”œâ”€â”€ linter.py             âš ï¸  éœ€è¡¥å……                          â”‚
â”‚  â””â”€â”€ tester.py             âš ï¸  éœ€è¡¥å……                         â”‚
â”‚                                                                             â”‚
â”‚  quality/                  ğŸ”´ P0 - ç«‹å³ä¿®å¤                                                 â”‚
â”‚  â””â”€â”€ *.py                  âŒ æœªå®ç°                                        â”‚
â”‚                                                                             â”‚
â”‚  observability/             ğŸ”´ P0 - ç«‹å³ä¿®å¤                                                â”‚
â”‚  â””â”€â”€ *.py                  âŒ æœªå®ç°                                        â”‚
â”‚                                                                             â”‚
â”‚  api/                      ğŸ”´ P0 - ç«‹å³ä¿®å¤                                                â”‚
â”‚  â””â”€â”€ *.py                  âŒ æœªå®ç°                                        â”‚
â”‚                                                                             â”‚
â”‚  tests/                     ğŸ”´ P0 - ç«‹å³ä¿®å¤                                                â”‚
â”‚  â””â”€â”€ *.py                  âŒ å®Œå…¨æ²¡æœ‰æµ‹è¯•                                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ“‹ ä¿®å¤ä¼˜å…ˆçº§

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ä¿®å¤ä¼˜å…ˆçº§æ¸…å•                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚                                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
âœ… è‡ªæ£€ç»“è®º

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              è‡ªæ£€ç»“è®º                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
=                                             â”‚
â”‚  ğŸ“Š è¯„ä¼°ï¼š                                                                   â”‚
â”‚  â”œâ”€â”€ è®¾è®¡åˆ†æ•°: 0/100  âŒ                                                    â”‚
â”‚  â”œâ”€â”€ å®ç°åˆ†æ•°: 0/100 âŒ                                                     â”‚
â”‚  â”œâ”€â”€ å¯è¿è¡Œæ€§: 0/100 âŒ                                                    â”‚
â”‚  â”œâ”€â”€ æµ‹è¯•è¦†ç›–: 0/100  âŒ                                                    â”‚
â”‚  â””â”€â”€ æ€»åˆ†: 0/100                                                          â”‚
â”‚                                                                             â”‚
â”‚  ğŸ¯ å»ºè®®ï¼š                                                                   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜