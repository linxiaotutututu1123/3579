"""ç½®ä¿¡åº¦è¯„ä¼°æ¨¡å— (å†›è§„çº§ v4.0).

V4PRO Platform Component - ç½®ä¿¡åº¦è¯„ä¼°ç³»ç»Ÿ
å†›è§„è¦†ç›–: M3(å®Œæ•´å®¡è®¡), M19(é£é™©å½’å› )

V4PRO Scenarios:
- K50: CONFIDENCE.PRE_EXEC - é¢„æ‰§è¡Œç½®ä¿¡åº¦æ£€æŸ¥
- K51: CONFIDENCE.SIGNAL - ä¿¡å·ç½®ä¿¡åº¦è¯„ä¼°
- K52: CONFIDENCE.AUDIT - ç½®ä¿¡åº¦å®¡è®¡è¿½è¸ª

é›†æˆ superclaude ConfidenceChecker æ¨¡å¼ä¸ V4PRO ä¿¡å·ç³»ç»Ÿã€‚

ç¤ºä¾‹:
    >>> assessor = ConfidenceAssessor()
    >>> context = ConfidenceContext(
    ...     task_type=TaskType.STRATEGY_EXECUTION,
    ...     has_official_docs=True,
    ...     architecture_verified=True,
    ... )
    >>> result = assessor.assess(context)
    >>> if result.can_proceed:
    ...     execute_strategy()
"""

from __future__ import annotations

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, ClassVar


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾."""

    STRATEGY_EXECUTION = "STRATEGY_EXECUTION"  # ç­–ç•¥æ‰§è¡Œ
    SIGNAL_GENERATION = "SIGNAL_GENERATION"  # ä¿¡å·ç”Ÿæˆ
    RISK_ASSESSMENT = "RISK_ASSESSMENT"  # é£é™©è¯„ä¼°
    ORDER_PLACEMENT = "ORDER_PLACEMENT"  # ä¸‹å•æ“ä½œ
    POSITION_ADJUSTMENT = "POSITION_ADJUSTMENT"  # ä»“ä½è°ƒæ•´


class ConfidenceLevel(Enum):
    """ç½®ä¿¡åº¦ç­‰çº§æšä¸¾."""

    HIGH = "HIGH"  # â‰¥90% - å¯ç›´æ¥æ‰§è¡Œ
    MEDIUM = "MEDIUM"  # 70-89% - éœ€è¦ç¡®è®¤/æ›¿ä»£æ–¹æ¡ˆ
    LOW = "LOW"  # <70% - åœæ­¢å¹¶è°ƒæŸ¥


@dataclass
class ConfidenceCheck:
    """å•é¡¹ç½®ä¿¡åº¦æ£€æŸ¥ç»“æœ."""

    name: str
    passed: bool
    weight: float
    message: str
    details: dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸."""
        return {
            "name": self.name,
            "passed": self.passed,
            "weight": self.weight,
            "message": self.message,
            "details": self.details,
        }


@dataclass
class ConfidenceContext:
    """ç½®ä¿¡åº¦è¯„ä¼°ä¸Šä¸‹æ–‡.

    å±æ€§:
        task_type: ä»»åŠ¡ç±»å‹
        task_name: ä»»åŠ¡åç§°
        symbol: åˆçº¦ä»£ç (å¯é€‰)
        strategy_id: ç­–ç•¥ID(å¯é€‰)

        # é¢„æ‰§è¡Œæ£€æŸ¥é¡¹ (superclaude æ¨¡å¼)
        duplicate_check_complete: æ˜¯å¦å®Œæˆé‡å¤æ£€æŸ¥
        architecture_verified: æ˜¯å¦éªŒè¯æ¶æ„åˆè§„
        has_official_docs: æ˜¯å¦æœ‰å®˜æ–¹æ–‡æ¡£
        has_oss_reference: æ˜¯å¦æœ‰OSSå‚è€ƒ
        root_cause_identified: æ˜¯å¦è¯†åˆ«æ ¹å› 

        # ä¿¡å·æ£€æŸ¥é¡¹ (V4PRO æ¨¡å¼)
        signal_strength: ä¿¡å·å¼ºåº¦
        signal_consistency: ä¿¡å·ä¸€è‡´æ€§
        market_condition: å¸‚åœºçŠ¶æ€
        risk_within_limits: é£é™©åœ¨é™åˆ¶å†…

        # æ‰©å±•æ£€æŸ¥é¡¹ (v4.3å¢å¼º)
        volatility: å¸‚åœºæ³¢åŠ¨ç‡ (0.0-1.0)
        liquidity_score: æµåŠ¨æ€§è¯„åˆ† (0.0-1.0)
        historical_win_rate: ç­–ç•¥å†å²èƒœç‡ (0.0-1.0)
        position_concentration: æŒä»“é›†ä¸­åº¦ (0.0-1.0)

        # é«˜çº§æ£€æŸ¥é¡¹ (v4.4å¢å¼º)
        backtest_sample_size: å›æµ‹æ ·æœ¬æ•°é‡ (>=100ä¸ºå……è¶³)
        backtest_sharpe: å›æµ‹å¤æ™®æ¯”ç‡ (>=1.0ä¸ºè‰¯å¥½)
        external_signal_valid: å¤–éƒ¨ä¿¡å·æœ‰æ•ˆæ€§
        external_signal_correlation: å¤–éƒ¨ä¿¡å·ç›¸å…³æ€§ (0.0-1.0)
        regime_alignment: å¸‚åœºä½“åˆ¶å¯¹é½
        current_regime: å½“å‰å¸‚åœºä½“åˆ¶ (TRENDING/RANGE/VOLATILE/UNKNOWN)
        strategy_regime: ç­–ç•¥é€‚ç”¨ä½“åˆ¶
        cross_asset_correlation: è·¨èµ„äº§ç›¸å…³æ€§é£é™© (0=ä½ç›¸å…³, 1=é«˜ç›¸å…³)

        # v4.5 å¹¶è¡Œæ‰§è¡Œæ£€æŸ¥
        parallel_execution_mode: æ˜¯å¦å¯ç”¨å¹¶è¡Œæ‰§è¡Œæ¨¡å¼
        independent_operations: ç‹¬ç«‹æ“ä½œæ•°é‡ (å¯å¹¶è¡Œæ‰§è¡Œçš„æ“ä½œæ•°)
        has_dependencies: æ˜¯å¦å­˜åœ¨ä¾èµ–å…³ç³» (False=å¯å®Œå…¨å¹¶è¡Œ)

        # v4.5 ä»¤ç‰Œæ•ˆç‡æ£€æŸ¥
        estimated_tokens: é¢„ä¼°ä»¤ç‰Œæ¶ˆè€—
        task_complexity: ä»»åŠ¡å¤æ‚åº¦ (SIMPLE/MEDIUM/COMPLEX)
        token_budget_ok: ä»¤ç‰Œé¢„ç®—æ˜¯å¦å……è¶³

        # v4.5 å·¥å…·ä¼˜åŒ–æ£€æŸ¥
        uses_optimal_tools: æ˜¯å¦ä½¿ç”¨æœ€ä¼˜å·¥å…·ç»„åˆ
        tool_selection_score: å·¥å…·é€‰æ‹©è¯„åˆ† (0.0-1.0)

        # å…ƒæ•°æ®
        metadata: é™„åŠ å…ƒæ•°æ®
    """

    task_type: TaskType
    task_name: str = ""
    symbol: str = ""
    strategy_id: str = ""

    # é¢„æ‰§è¡Œæ£€æŸ¥é¡¹ (superclaude æ¨¡å¼)
    duplicate_check_complete: bool = False
    architecture_verified: bool = False
    has_official_docs: bool = False
    has_oss_reference: bool = False
    root_cause_identified: bool = False

    # ä¿¡å·æ£€æŸ¥é¡¹ (V4PRO æ¨¡å¼)
    signal_strength: float = 0.0
    signal_consistency: float = 0.0
    market_condition: str = "NORMAL"
    risk_within_limits: bool = True

    # æ‰©å±•æ£€æŸ¥é¡¹ (v4.3å¢å¼º)
    volatility: float = 0.0  # å¸‚åœºæ³¢åŠ¨ç‡
    liquidity_score: float = 1.0  # æµåŠ¨æ€§è¯„åˆ† (é»˜è®¤é«˜æµåŠ¨æ€§)
    historical_win_rate: float = 0.5  # ç­–ç•¥å†å²èƒœç‡
    position_concentration: float = 0.0  # æŒä»“é›†ä¸­åº¦ (0=åˆ†æ•£, 1=é›†ä¸­)

    # é«˜çº§æ£€æŸ¥é¡¹ (v4.4å¢å¼º)
    backtest_sample_size: int = 0  # å›æµ‹æ ·æœ¬æ•°é‡
    backtest_sharpe: float = 0.0  # å›æµ‹å¤æ™®æ¯”ç‡
    external_signal_valid: bool = False  # å¤–éƒ¨ä¿¡å·æœ‰æ•ˆæ€§
    external_signal_correlation: float = 0.0  # å¤–éƒ¨ä¿¡å·ç›¸å…³æ€§ (0.0-1.0)
    regime_alignment: bool = False  # å¸‚åœºä½“åˆ¶å¯¹é½
    current_regime: str = "UNKNOWN"  # å½“å‰å¸‚åœºä½“åˆ¶ (TRENDING/RANGE/VOLATILE/UNKNOWN)
    strategy_regime: str = "UNKNOWN"  # ç­–ç•¥é€‚ç”¨ä½“åˆ¶
    cross_asset_correlation: float = 0.0  # è·¨èµ„äº§ç›¸å…³æ€§é£é™© (0=ä½ç›¸å…³, 1=é«˜ç›¸å…³)

    # v4.5 å¹¶è¡Œæ‰§è¡Œæ£€æŸ¥
    parallel_execution_mode: bool = False  # æ˜¯å¦å¯ç”¨å¹¶è¡Œæ‰§è¡Œæ¨¡å¼
    independent_operations: int = 0  # ç‹¬ç«‹æ“ä½œæ•°é‡ (å¯å¹¶è¡Œæ‰§è¡Œçš„æ“ä½œæ•°)
    has_dependencies: bool = True  # æ˜¯å¦å­˜åœ¨ä¾èµ–å…³ç³» (False=å¯å®Œå…¨å¹¶è¡Œ)

    # v4.5 ä»¤ç‰Œæ•ˆç‡æ£€æŸ¥
    estimated_tokens: int = 0  # é¢„ä¼°ä»¤ç‰Œæ¶ˆè€—
    task_complexity: str = "MEDIUM"  # ä»»åŠ¡å¤æ‚åº¦ (SIMPLE/MEDIUM/COMPLEX)
    token_budget_ok: bool = True  # ä»¤ç‰Œé¢„ç®—æ˜¯å¦å……è¶³

    # v4.5 å·¥å…·ä¼˜åŒ–æ£€æŸ¥
    uses_optimal_tools: bool = False  # æ˜¯å¦ä½¿ç”¨æœ€ä¼˜å·¥å…·ç»„åˆ
    tool_selection_score: float = 0.0  # å·¥å…·é€‰æ‹©è¯„åˆ† (0.0-1.0)

    # å…ƒæ•°æ®
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass(frozen=True)
class ConfidenceResult:
    """ç½®ä¿¡åº¦è¯„ä¼°ç»“æœ (ä¸å¯å˜).

    å±æ€§:
        score: ç½®ä¿¡åº¦åˆ†æ•° (0.0-1.0)
        level: ç½®ä¿¡åº¦ç­‰çº§
        can_proceed: æ˜¯å¦å¯ä»¥ç»§ç»­
        checks: å„é¡¹æ£€æŸ¥ç»“æœ
        recommendation: å»ºè®®æ“ä½œ
        timestamp: æ—¶é—´æˆ³
        context_summary: ä¸Šä¸‹æ–‡æ‘˜è¦
    """

    score: float
    level: ConfidenceLevel
    can_proceed: bool
    checks: tuple[ConfidenceCheck, ...]
    recommendation: str
    timestamp: str = ""
    context_summary: dict[str, Any] = field(default_factory=dict)

    def to_audit_dict(self) -> dict[str, Any]:
        """è½¬æ¢ä¸ºå®¡è®¡æ—¥å¿—æ ¼å¼ (M3)."""
        return {
            "event_type": "CONFIDENCE_ASSESSMENT",
            "score": round(self.score, 4),
            "level": self.level.value,
            "can_proceed": self.can_proceed,
            "checks": [c.to_dict() for c in self.checks],
            "recommendation": self.recommendation,
            "timestamp": self.timestamp,
            "context_summary": self.context_summary,
        }

    @property
    def passed_checks(self) -> list[ConfidenceCheck]:
        """è·å–é€šè¿‡çš„æ£€æŸ¥é¡¹."""
        return [c for c in self.checks if c.passed]

    @property
    def failed_checks(self) -> list[ConfidenceCheck]:
        """è·å–å¤±è´¥çš„æ£€æŸ¥é¡¹."""
        return [c for c in self.checks if not c.passed]


class ConfidenceAssessor:
    """ç½®ä¿¡åº¦è¯„ä¼°å™¨ (å†›è§„ M3/M19).

    ç»Ÿä¸€ superclaude é¢„å®ç°ç½®ä¿¡åº¦æ£€æŸ¥ä¸ V4PRO ä¿¡å·ç½®ä¿¡åº¦è¯„ä¼°ã€‚

    åŠŸèƒ½:
    - é¢„æ‰§è¡Œç½®ä¿¡åº¦æ£€æŸ¥ (é˜²æ­¢é”™è¯¯æ–¹å‘æ‰§è¡Œ)
    - ä¿¡å·ç½®ä¿¡åº¦è¯„ä¼° (äº¤æ˜“å†³ç­–æ”¯æŒ)
    - å®¡è®¡è¿½è¸ª (M3)
    - é£é™©å½’å›  (M19)

    ç½®ä¿¡åº¦é˜ˆå€¼:
    - â‰¥90%: é«˜ç½®ä¿¡åº¦ - å¯ç›´æ¥æ‰§è¡Œ
    - 70-89%: ä¸­ç­‰ç½®ä¿¡åº¦ - éœ€è¦ç¡®è®¤æˆ–æ›¿ä»£æ–¹æ¡ˆ
    - <70%: ä½ç½®ä¿¡åº¦ - åœæ­¢å¹¶è°ƒæŸ¥

    ç¤ºä¾‹:
        >>> assessor = ConfidenceAssessor()
        >>> context = ConfidenceContext(
        ...     task_type=TaskType.STRATEGY_EXECUTION,
        ...     has_official_docs=True,
        ... )
        >>> result = assessor.assess(context)
        >>> print(f"ç½®ä¿¡åº¦: {result.score:.0%}")
    """

    # é˜ˆå€¼å¸¸é‡
    HIGH_THRESHOLD: ClassVar[float] = 0.90
    MEDIUM_THRESHOLD: ClassVar[float] = 0.70

    # æ£€æŸ¥é¡¹æƒé‡ (superclaude æ¨¡å¼)
    WEIGHT_NO_DUPLICATES: ClassVar[float] = 0.25
    WEIGHT_ARCHITECTURE: ClassVar[float] = 0.25
    WEIGHT_OFFICIAL_DOCS: ClassVar[float] = 0.20
    WEIGHT_OSS_REFERENCE: ClassVar[float] = 0.15
    WEIGHT_ROOT_CAUSE: ClassVar[float] = 0.15

    # æ£€æŸ¥é¡¹æƒé‡ (V4PRO ä¿¡å·æ¨¡å¼)
    WEIGHT_SIGNAL_STRENGTH: ClassVar[float] = 0.30
    WEIGHT_SIGNAL_CONSISTENCY: ClassVar[float] = 0.25
    WEIGHT_MARKET_CONDITION: ClassVar[float] = 0.25
    WEIGHT_RISK_LIMITS: ClassVar[float] = 0.20

    # æ‰©å±•æ£€æŸ¥é¡¹æƒé‡ (v4.3å¢å¼º)
    WEIGHT_VOLATILITY: ClassVar[float] = 0.15
    WEIGHT_LIQUIDITY: ClassVar[float] = 0.15
    WEIGHT_WIN_RATE: ClassVar[float] = 0.10
    WEIGHT_CONCENTRATION: ClassVar[float] = 0.10

    # é«˜çº§æ£€æŸ¥é¡¹æƒé‡ (v4.4å¢å¼º)
    WEIGHT_BACKTEST_DATA: ClassVar[float] = 0.15  # å›æµ‹æ•°æ®éªŒè¯
    WEIGHT_EXTERNAL_SIGNAL: ClassVar[float] = 0.10  # å¤–éƒ¨ä¿¡å·ç›¸å…³æ€§
    WEIGHT_REGIME_ALIGNMENT: ClassVar[float] = 0.10  # å¸‚åœºä½“åˆ¶å¯¹é½
    WEIGHT_CORRELATION: ClassVar[float] = 0.10  # è·¨èµ„äº§ç›¸å…³æ€§

    # v4.5 å¢å¼ºæ£€æŸ¥é¡¹æƒé‡
    WEIGHT_PARALLEL_EXECUTION: ClassVar[float] = 0.10  # å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–
    WEIGHT_TOKEN_EFFICIENCY: ClassVar[float] = 0.10  # ä»¤ç‰Œæ•ˆç‡
    WEIGHT_TOOL_OPTIMIZATION: ClassVar[float] = 0.10  # å·¥å…·é€‰æ‹©ä¼˜åŒ–

    def __init__(
        self,
        high_threshold: float = 0.90,
        medium_threshold: float = 0.70,
        adaptive_mode: bool = False,
    ) -> None:
        """åˆå§‹åŒ–ç½®ä¿¡åº¦è¯„ä¼°å™¨.

        å‚æ•°:
            high_threshold: é«˜ç½®ä¿¡åº¦é˜ˆå€¼
            medium_threshold: ä¸­ç­‰ç½®ä¿¡åº¦é˜ˆå€¼
            adaptive_mode: æ˜¯å¦å¯ç”¨è‡ªé€‚åº”é˜ˆå€¼æ¨¡å¼
        """
        self._high_threshold = high_threshold
        self._medium_threshold = medium_threshold
        self._adaptive_mode = adaptive_mode
        self._assessment_count = 0
        self._high_count = 0
        self._medium_count = 0
        self._low_count = 0
        self._score_history: list[float] = []  # ç½®ä¿¡åº¦å†å²è®°å½•
        self._max_history = 100  # æœ€å¤§å†å²è®°å½•æ•°

    def assess(self, context: ConfidenceContext) -> ConfidenceResult:
        """è¯„ä¼°ç½®ä¿¡åº¦.

        æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©é€‚å½“çš„è¯„ä¼°ç­–ç•¥ã€‚
        æ”¯æŒè‡ªé€‚åº”é˜ˆå€¼æ¨¡å¼ (v4.3å¢å¼º)ã€‚

        å‚æ•°:
            context: è¯„ä¼°ä¸Šä¸‹æ–‡

        è¿”å›:
            ç½®ä¿¡åº¦è¯„ä¼°ç»“æœ
        """
        self._assessment_count += 1
        timestamp = datetime.now().isoformat()  # noqa: DTZ005

        # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©è¯„ä¼°ç­–ç•¥
        if context.task_type in (TaskType.STRATEGY_EXECUTION, TaskType.ORDER_PLACEMENT):
            checks = self._assess_pre_execution(context)
        elif context.task_type == TaskType.SIGNAL_GENERATION:
            checks = self._assess_signal(context)
        else:
            checks = self._assess_combined(context)

        # è®¡ç®—æ€»åˆ†
        score = sum(c.weight for c in checks if c.passed)

        # è®°å½•åˆ†æ•°å†å²
        self._record_score(score)

        # è·å–é˜ˆå€¼ (æ”¯æŒè‡ªé€‚åº”æ¨¡å¼)
        if self._adaptive_mode:
            high_thresh, medium_thresh = self.get_adaptive_thresholds(context)
        else:
            high_thresh = self._high_threshold
            medium_thresh = self._medium_threshold

        # ç¡®å®šç­‰çº§
        if score >= high_thresh:
            level = ConfidenceLevel.HIGH
            can_proceed = True
            self._high_count += 1
        elif score >= medium_thresh:
            level = ConfidenceLevel.MEDIUM
            can_proceed = False  # éœ€è¦ç¡®è®¤
            self._medium_count += 1
        else:
            level = ConfidenceLevel.LOW
            can_proceed = False
            self._low_count += 1

        recommendation = self._get_recommendation(level, checks)

        context_summary = {
            "task_type": context.task_type.value,
            "task_name": context.task_name,
            "symbol": context.symbol,
            "strategy_id": context.strategy_id,
            "adaptive_mode": self._adaptive_mode,
            "thresholds": {"high": high_thresh, "medium": medium_thresh},
        }

        return ConfidenceResult(
            score=score,
            level=level,
            can_proceed=can_proceed,
            checks=tuple(checks),
            recommendation=recommendation,
            timestamp=timestamp,
            context_summary=context_summary,
        )

    def _assess_pre_execution(
        self, context: ConfidenceContext
    ) -> list[ConfidenceCheck]:
        """é¢„æ‰§è¡Œç½®ä¿¡åº¦è¯„ä¼° (superclaude æ¨¡å¼).

        æ£€æŸ¥é¡¹:
        1. æ— é‡å¤å®ç° (25%)
        2. æ¶æ„åˆè§„ (25%)
        3. å®˜æ–¹æ–‡æ¡£éªŒè¯ (20%)
        4. OSSå‚è€ƒå®ç° (15%)
        5. æ ¹å› è¯†åˆ« (15%)
        """
        checks: list[ConfidenceCheck] = []

        # æ£€æŸ¥1: æ— é‡å¤å®ç°
        checks.append(
            ConfidenceCheck(
                name="no_duplicates",
                passed=context.duplicate_check_complete,
                weight=self.WEIGHT_NO_DUPLICATES,
                message=(
                    "âœ… æ— é‡å¤å®ç°"
                    if context.duplicate_check_complete
                    else "âŒ è¯·å…ˆæ£€æŸ¥ç°æœ‰å®ç°"
                ),
            )
        )

        # æ£€æŸ¥2: æ¶æ„åˆè§„
        checks.append(
            ConfidenceCheck(
                name="architecture_verified",
                passed=context.architecture_verified,
                weight=self.WEIGHT_ARCHITECTURE,
                message=(
                    "âœ… æ¶æ„åˆè§„"
                    if context.architecture_verified
                    else "âŒ è¯·éªŒè¯æ¶æ„åˆè§„æ€§"
                ),
            )
        )

        # æ£€æŸ¥3: å®˜æ–¹æ–‡æ¡£
        checks.append(
            ConfidenceCheck(
                name="official_docs",
                passed=context.has_official_docs,
                weight=self.WEIGHT_OFFICIAL_DOCS,
                message=(
                    "âœ… å®˜æ–¹æ–‡æ¡£å·²éªŒè¯"
                    if context.has_official_docs
                    else "âŒ è¯·æŸ¥é˜…å®˜æ–¹æ–‡æ¡£"
                ),
            )
        )

        # æ£€æŸ¥4: OSSå‚è€ƒ
        checks.append(
            ConfidenceCheck(
                name="oss_reference",
                passed=context.has_oss_reference,
                weight=self.WEIGHT_OSS_REFERENCE,
                message=(
                    "âœ… OSSå‚è€ƒå·²æ‰¾åˆ°"
                    if context.has_oss_reference
                    else "âŒ è¯·æœç´¢OSSå‚è€ƒå®ç°"
                ),
            )
        )

        # æ£€æŸ¥5: æ ¹å› è¯†åˆ«
        checks.append(
            ConfidenceCheck(
                name="root_cause",
                passed=context.root_cause_identified,
                weight=self.WEIGHT_ROOT_CAUSE,
                message=(
                    "âœ… æ ¹å› å·²è¯†åˆ«"
                    if context.root_cause_identified
                    else "âŒ è¯·ç»§ç»­è°ƒæŸ¥æ ¹å› "
                ),
            )
        )

        return checks

    def _assess_signal(self, context: ConfidenceContext) -> list[ConfidenceCheck]:
        """ä¿¡å·ç½®ä¿¡åº¦è¯„ä¼° (V4PRO æ¨¡å¼).

        æ£€æŸ¥é¡¹:
        1. ä¿¡å·å¼ºåº¦ (30%)
        2. ä¿¡å·ä¸€è‡´æ€§ (25%)
        3. å¸‚åœºçŠ¶æ€ (25%)
        4. é£é™©é™åˆ¶ (20%)
        """
        checks: list[ConfidenceCheck] = []

        # æ£€æŸ¥1: ä¿¡å·å¼ºåº¦
        strength_ok = context.signal_strength >= 0.5
        checks.append(
            ConfidenceCheck(
                name="signal_strength",
                passed=strength_ok,
                weight=self.WEIGHT_SIGNAL_STRENGTH if strength_ok else 0.0,
                message=(
                    f"âœ… ä¿¡å·å¼ºåº¦: {context.signal_strength:.0%}"
                    if strength_ok
                    else f"âŒ ä¿¡å·å¼ºåº¦ä¸è¶³: {context.signal_strength:.0%}"
                ),
                details={"value": context.signal_strength},
            )
        )

        # æ£€æŸ¥2: ä¿¡å·ä¸€è‡´æ€§
        consistency_ok = context.signal_consistency >= 0.6
        checks.append(
            ConfidenceCheck(
                name="signal_consistency",
                passed=consistency_ok,
                weight=self.WEIGHT_SIGNAL_CONSISTENCY if consistency_ok else 0.0,
                message=(
                    f"âœ… ä¿¡å·ä¸€è‡´æ€§: {context.signal_consistency:.0%}"
                    if consistency_ok
                    else f"âŒ ä¿¡å·ä¸€è‡´æ€§ä¸è¶³: {context.signal_consistency:.0%}"
                ),
                details={"value": context.signal_consistency},
            )
        )

        # æ£€æŸ¥3: å¸‚åœºçŠ¶æ€
        normal_conditions = {"NORMAL", "TRENDING", "RANGE"}
        market_ok = context.market_condition in normal_conditions
        checks.append(
            ConfidenceCheck(
                name="market_condition",
                passed=market_ok,
                weight=self.WEIGHT_MARKET_CONDITION if market_ok else 0.0,
                message=(
                    f"âœ… å¸‚åœºçŠ¶æ€: {context.market_condition}"
                    if market_ok
                    else f"âŒ å¸‚åœºçŠ¶æ€å¼‚å¸¸: {context.market_condition}"
                ),
                details={"condition": context.market_condition},
            )
        )

        # æ£€æŸ¥4: é£é™©é™åˆ¶
        checks.append(
            ConfidenceCheck(
                name="risk_limits",
                passed=context.risk_within_limits,
                weight=self.WEIGHT_RISK_LIMITS if context.risk_within_limits else 0.0,
                message=(
                    "âœ… é£é™©åœ¨é™åˆ¶å†…"
                    if context.risk_within_limits
                    else "âŒ é£é™©è¶…å‡ºé™åˆ¶"
                ),
            )
        )

        return checks

    def _assess_extended(self, context: ConfidenceContext) -> list[ConfidenceCheck]:
        """æ‰©å±•ç½®ä¿¡åº¦è¯„ä¼° (v4.3å¢å¼º).

        æ£€æŸ¥é¡¹:
        1. æ³¢åŠ¨ç‡æ£€æŸ¥ (15%) - ä½æ³¢åŠ¨ç‡æ›´å®‰å…¨
        2. æµåŠ¨æ€§æ£€æŸ¥ (15%) - é«˜æµåŠ¨æ€§æ›´å¯é 
        3. å†å²èƒœç‡æ£€æŸ¥ (10%) - é«˜èƒœç‡ç­–ç•¥æ›´å¯ä¿¡
        4. æŒä»“é›†ä¸­åº¦æ£€æŸ¥ (10%) - åˆ†æ•£æŒä»“æ›´ç¨³å¥
        """
        checks: list[ConfidenceCheck] = []

        # æ£€æŸ¥1: æ³¢åŠ¨ç‡ (ä½äº0.3ä¸ºæ­£å¸¸)
        volatility_ok = context.volatility <= 0.3
        checks.append(
            ConfidenceCheck(
                name="volatility",
                passed=volatility_ok,
                weight=self.WEIGHT_VOLATILITY if volatility_ok else 0.0,
                message=(
                    f"âœ… æ³¢åŠ¨ç‡æ­£å¸¸: {context.volatility:.0%}"
                    if volatility_ok
                    else f"âš ï¸ æ³¢åŠ¨ç‡åé«˜: {context.volatility:.0%}"
                ),
                details={"value": context.volatility, "threshold": 0.3},
            )
        )

        # æ£€æŸ¥2: æµåŠ¨æ€§ (é«˜äº0.6ä¸ºè‰¯å¥½)
        liquidity_ok = context.liquidity_score >= 0.6
        checks.append(
            ConfidenceCheck(
                name="liquidity",
                passed=liquidity_ok,
                weight=self.WEIGHT_LIQUIDITY if liquidity_ok else 0.0,
                message=(
                    f"âœ… æµåŠ¨æ€§è‰¯å¥½: {context.liquidity_score:.0%}"
                    if liquidity_ok
                    else f"âš ï¸ æµåŠ¨æ€§ä¸è¶³: {context.liquidity_score:.0%}"
                ),
                details={"value": context.liquidity_score, "threshold": 0.6},
            )
        )

        # æ£€æŸ¥3: å†å²èƒœç‡ (é«˜äº0.5ä¸ºæ­£å‘æœŸæœ›)
        win_rate_ok = context.historical_win_rate >= 0.5
        checks.append(
            ConfidenceCheck(
                name="win_rate",
                passed=win_rate_ok,
                weight=self.WEIGHT_WIN_RATE if win_rate_ok else 0.0,
                message=(
                    f"âœ… å†å²èƒœç‡: {context.historical_win_rate:.0%}"
                    if win_rate_ok
                    else f"âš ï¸ å†å²èƒœç‡åä½: {context.historical_win_rate:.0%}"
                ),
                details={"value": context.historical_win_rate, "threshold": 0.5},
            )
        )

        # æ£€æŸ¥4: æŒä»“é›†ä¸­åº¦ (ä½äº0.5ä¸ºåˆ†æ•£)
        concentration_ok = context.position_concentration <= 0.5
        checks.append(
            ConfidenceCheck(
                name="concentration",
                passed=concentration_ok,
                weight=self.WEIGHT_CONCENTRATION if concentration_ok else 0.0,
                message=(
                    f"âœ… æŒä»“åˆ†æ•£: {context.position_concentration:.0%}"
                    if concentration_ok
                    else f"âš ï¸ æŒä»“é›†ä¸­: {context.position_concentration:.0%}"
                ),
                details={"value": context.position_concentration, "threshold": 0.5},
            )
        )

        return checks

    def _assess_advanced(self, context: ConfidenceContext) -> list[ConfidenceCheck]:
        """é«˜çº§ç½®ä¿¡åº¦è¯„ä¼° (v4.4å¢å¼º).

        æ£€æŸ¥é¡¹:
        1. å›æµ‹æ•°æ®æ£€æŸ¥ (15%) - éªŒè¯å›æµ‹æ ·æœ¬é‡å’Œå¤æ™®æ¯”ç‡
        2. å¤–éƒ¨ä¿¡å·æ£€æŸ¥ (10%) - éªŒè¯å¤–éƒ¨ä¿¡å·æ¥æº
        3. å¸‚åœºä½“åˆ¶å¯¹é½æ£€æŸ¥ (10%) - éªŒè¯ç­–ç•¥ä¸å½“å‰å¸‚åœºä½“åˆ¶åŒ¹é…
        4. è·¨èµ„äº§ç›¸å…³æ€§æ£€æŸ¥ (10%) - éªŒè¯ç›¸å…³æ€§é£é™©å¯æ§
        """
        checks: list[ConfidenceCheck] = []

        # æ£€æŸ¥1: å›æµ‹æ•°æ®å……è¶³æ€§
        backtest_ok = (
            context.backtest_sample_size >= 100 and context.backtest_sharpe >= 1.0
        )
        checks.append(
            ConfidenceCheck(
                name="backtest_data",
                passed=backtest_ok,
                weight=self.WEIGHT_BACKTEST_DATA if backtest_ok else 0.0,
                message=(
                    f"âœ… å›æµ‹æ•°æ®å……è¶³: {context.backtest_sample_size}æ ·æœ¬, "
                    f"å¤æ™®={context.backtest_sharpe:.2f}"
                    if backtest_ok
                    else f"âš ï¸ å›æµ‹æ•°æ®ä¸è¶³: {context.backtest_sample_size}æ ·æœ¬, "
                    f"å¤æ™®={context.backtest_sharpe:.2f}"
                ),
                details={
                    "sample_size": context.backtest_sample_size,
                    "sharpe": context.backtest_sharpe,
                    "min_sample": 100,
                    "min_sharpe": 1.0,
                },
            )
        )

        # æ£€æŸ¥2: å¤–éƒ¨ä¿¡å·æœ‰æ•ˆæ€§
        external_ok = (
            context.external_signal_valid
            and context.external_signal_correlation >= 0.5
        )
        checks.append(
            ConfidenceCheck(
                name="external_signal",
                passed=external_ok,
                weight=self.WEIGHT_EXTERNAL_SIGNAL if external_ok else 0.0,
                message=(
                    f"âœ… å¤–éƒ¨ä¿¡å·æœ‰æ•ˆ: ç›¸å…³æ€§={context.external_signal_correlation:.0%}"
                    if external_ok
                    else f"âš ï¸ å¤–éƒ¨ä¿¡å·æ— æ•ˆæˆ–ç›¸å…³æ€§ä½: {context.external_signal_correlation:.0%}"
                ),
                details={
                    "valid": context.external_signal_valid,
                    "correlation": context.external_signal_correlation,
                    "threshold": 0.5,
                },
            )
        )

        # æ£€æŸ¥3: å¸‚åœºä½“åˆ¶å¯¹é½
        regime_ok = context.regime_alignment or (
            context.current_regime != "UNKNOWN"
            and context.current_regime == context.strategy_regime
        )
        checks.append(
            ConfidenceCheck(
                name="regime_alignment",
                passed=regime_ok,
                weight=self.WEIGHT_REGIME_ALIGNMENT if regime_ok else 0.0,
                message=(
                    f"âœ… å¸‚åœºä½“åˆ¶å¯¹é½: {context.current_regime}"
                    if regime_ok
                    else f"âš ï¸ å¸‚åœºä½“åˆ¶ä¸åŒ¹é…: å½“å‰={context.current_regime}, "
                    f"ç­–ç•¥é€‚ç”¨={context.strategy_regime}"
                ),
                details={
                    "current_regime": context.current_regime,
                    "strategy_regime": context.strategy_regime,
                    "aligned": regime_ok,
                },
            )
        )

        # æ£€æŸ¥4: è·¨èµ„äº§ç›¸å…³æ€§é£é™©
        correlation_ok = context.cross_asset_correlation <= 0.7
        checks.append(
            ConfidenceCheck(
                name="cross_correlation",
                passed=correlation_ok,
                weight=self.WEIGHT_CORRELATION if correlation_ok else 0.0,
                message=(
                    f"[PASS] ç›¸å…³æ€§é£é™©å¯æ§: {context.cross_asset_correlation:.0%}"
                    if correlation_ok
                    else f"[WARN] ç›¸å…³æ€§é£é™©åé«˜: {context.cross_asset_correlation:.0%}"
                ),
                details={
                    "correlation": context.cross_asset_correlation,
                    "threshold": 0.7,
                },
            )
        )

        return checks

    def _assess_v45_enhanced(
        self, context: ConfidenceContext
    ) -> list[ConfidenceCheck]:
        """v4.5 å¢å¼ºç½®ä¿¡åº¦è¯„ä¼°.

        å†›è§„è¦†ç›–: M3(å®Œæ•´å®¡è®¡), M19(é£é™©å½’å› )

        æ£€æŸ¥é¡¹:
        1. å¹¶è¡Œæ‰§è¡Œæ£€æŸ¥ (10%) - éªŒè¯æ˜¯å¦å¯ç”¨å¹¶è¡Œæ‰§è¡Œæ¨¡å¼åŠç‹¬ç«‹æ“ä½œæ•°
        2. ä»¤ç‰Œæ•ˆç‡æ£€æŸ¥ (10%) - éªŒè¯ä»¤ç‰Œé¢„ç®—æ˜¯å¦å……è¶³
        3. å·¥å…·ä¼˜åŒ–æ£€æŸ¥ (10%) - éªŒè¯æ˜¯å¦ä½¿ç”¨æœ€ä¼˜å·¥å…·ç»„åˆ

        å‚æ•°:
            context: è¯„ä¼°ä¸Šä¸‹æ–‡

        è¿”å›:
            æ£€æŸ¥ç»“æœåˆ—è¡¨
        """
        checks: list[ConfidenceCheck] = []

        # æ£€æŸ¥1: å¹¶è¡Œæ‰§è¡Œä¼˜åŒ– (M19: é£é™©å½’å›  - æ‰§è¡Œæ•ˆç‡)
        # æ¡ä»¶: å¯ç”¨å¹¶è¡Œæ¨¡å¼ + ç‹¬ç«‹æ“ä½œæ•°>=2 + æ— ä¾èµ–å…³ç³»
        parallel_ok = (
            context.parallel_execution_mode
            and context.independent_operations >= 2
            and not context.has_dependencies
        )
        # éƒ¨åˆ†æ»¡è¶³æ¡ä»¶ä¹Ÿç»™äºˆéƒ¨åˆ†åˆ†æ•°
        parallel_score = 0.0
        if context.parallel_execution_mode:
            parallel_score += 0.4
        if context.independent_operations >= 2:
            parallel_score += 0.3
        if not context.has_dependencies:
            parallel_score += 0.3

        checks.append(
            ConfidenceCheck(
                name="parallel_execution",
                passed=parallel_ok,
                weight=self.WEIGHT_PARALLEL_EXECUTION if parallel_ok else 0.0,
                message=(
                    f"[PASS] å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–: {context.independent_operations}ä¸ªç‹¬ç«‹æ“ä½œ"
                    if parallel_ok
                    else f"[WARN] å¹¶è¡Œæ‰§è¡Œæœªä¼˜åŒ–: æ¨¡å¼={context.parallel_execution_mode}, "
                    f"ç‹¬ç«‹æ“ä½œ={context.independent_operations}, ä¾èµ–={context.has_dependencies}"
                ),
                details={
                    "parallel_mode": context.parallel_execution_mode,
                    "independent_ops": context.independent_operations,
                    "has_dependencies": context.has_dependencies,
                    "partial_score": round(parallel_score, 2),
                    "audit_tag": "M19",  # é£é™©å½’å› : æ‰§è¡Œæ•ˆç‡å½±å“
                },
            )
        )

        # æ£€æŸ¥2: ä»¤ç‰Œæ•ˆç‡ (M3: å®¡è®¡ - èµ„æºæ¶ˆè€—è¿½è¸ª)
        # æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åˆ¤æ–­ä»¤ç‰Œé¢„ç®—æ˜¯å¦åˆç†
        complexity_budgets = {
            "SIMPLE": 200,
            "MEDIUM": 1000,
            "COMPLEX": 2500,
        }
        expected_budget = complexity_budgets.get(context.task_complexity, 1000)

        token_ok = context.token_budget_ok and (
            context.estimated_tokens <= expected_budget * 1.2  # å…è®¸20%æµ®åŠ¨
        )

        checks.append(
            ConfidenceCheck(
                name="token_efficiency",
                passed=token_ok,
                weight=self.WEIGHT_TOKEN_EFFICIENCY if token_ok else 0.0,
                message=(
                    f"[PASS] ä»¤ç‰Œæ•ˆç‡è‰¯å¥½: {context.estimated_tokens}/{expected_budget} "
                    f"({context.task_complexity})"
                    if token_ok
                    else f"[WARN] ä»¤ç‰Œæ•ˆç‡å¾…ä¼˜åŒ–: {context.estimated_tokens}/{expected_budget} "
                    f"({context.task_complexity})"
                ),
                details={
                    "estimated_tokens": context.estimated_tokens,
                    "expected_budget": expected_budget,
                    "task_complexity": context.task_complexity,
                    "budget_ok": context.token_budget_ok,
                    "audit_tag": "M3",  # å®¡è®¡: èµ„æºæ¶ˆè€—è¿½è¸ª
                },
            )
        )

        # æ£€æŸ¥3: å·¥å…·é€‰æ‹©ä¼˜åŒ– (M19: é£é™©å½’å›  - å·¥å…·æ•ˆèƒ½)
        # å·¥å…·é€‰æ‹©è¯„åˆ† >= 0.7 ä¸”ä½¿ç”¨æœ€ä¼˜å·¥å…·
        tool_ok = context.uses_optimal_tools and context.tool_selection_score >= 0.7

        checks.append(
            ConfidenceCheck(
                name="tool_optimization",
                passed=tool_ok,
                weight=self.WEIGHT_TOOL_OPTIMIZATION if tool_ok else 0.0,
                message=(
                    f"[PASS] å·¥å…·é€‰æ‹©ä¼˜åŒ–: è¯„åˆ†={context.tool_selection_score:.0%}"
                    if tool_ok
                    else f"[WARN] å·¥å…·é€‰æ‹©å¾…ä¼˜åŒ–: æœ€ä¼˜å·¥å…·={context.uses_optimal_tools}, "
                    f"è¯„åˆ†={context.tool_selection_score:.0%}"
                ),
                details={
                    "uses_optimal_tools": context.uses_optimal_tools,
                    "tool_selection_score": context.tool_selection_score,
                    "threshold": 0.7,
                    "audit_tag": "M19",  # é£é™©å½’å› : å·¥å…·æ•ˆèƒ½å½±å“
                },
            )
        )

        return checks

    def _assess_combined(self, context: ConfidenceContext) -> list[ConfidenceCheck]:
        """ç»„åˆè¯„ä¼° (é¢„æ‰§è¡Œ + ä¿¡å· + æ‰©å±• + é«˜çº§).

        æƒé‡åˆ†é…:
        - é¢„æ‰§è¡Œæ£€æŸ¥: 30%
        - ä¿¡å·æ£€æŸ¥: 30%
        - æ‰©å±•æ£€æŸ¥: 20%
        - é«˜çº§æ£€æŸ¥: 20%
        """
        pre_exec_checks = self._assess_pre_execution(context)
        signal_checks = self._assess_signal(context)
        extended_checks = self._assess_extended(context)
        advanced_checks = self._assess_advanced(context)

        # è°ƒæ•´æƒé‡ (é¢„æ‰§è¡Œ30% + ä¿¡å·30% + æ‰©å±•20% + é«˜çº§20%)
        for check in pre_exec_checks:
            check_dict = check.to_dict()
            check_dict["weight"] *= 0.3

        for check in signal_checks:
            check_dict = check.to_dict()
            check_dict["weight"] *= 0.3

        for check in extended_checks:
            check_dict = check.to_dict()
            check_dict["weight"] *= 0.2

        for check in advanced_checks:
            check_dict = check.to_dict()
            check_dict["weight"] *= 0.2

        return pre_exec_checks + signal_checks + extended_checks + advanced_checks

    def _get_recommendation(
        self, level: ConfidenceLevel, checks: list[ConfidenceCheck]
    ) -> str:
        """è·å–å»ºè®®æ“ä½œ.

        å‚æ•°:
            level: ç½®ä¿¡åº¦ç­‰çº§
            checks: æ£€æŸ¥ç»“æœåˆ—è¡¨

        è¿”å›:
            å»ºè®®æ“ä½œå­—ç¬¦ä¸²
        """
        if level == ConfidenceLevel.HIGH:
            return "âœ… é«˜ç½®ä¿¡åº¦ (â‰¥90%) - å¯ç›´æ¥æ‰§è¡Œ"

        failed = [c for c in checks if not c.passed]
        failed_names = ", ".join(c.name for c in failed[:3])

        if level == ConfidenceLevel.MEDIUM:
            return f"âš ï¸ ä¸­ç­‰ç½®ä¿¡åº¦ (70-89%) - å»ºè®®ç¡®è®¤: {failed_names}"

        return f"âŒ ä½ç½®ä¿¡åº¦ (<70%) - åœæ­¢å¹¶è°ƒæŸ¥: {failed_names}"

    def get_statistics(self) -> dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯."""
        total = self._assessment_count
        return {
            "total_assessments": total,
            "high_confidence_count": self._high_count,
            "medium_confidence_count": self._medium_count,
            "low_confidence_count": self._low_count,
            "high_rate": self._high_count / total if total > 0 else 0.0,
            "medium_rate": self._medium_count / total if total > 0 else 0.0,
            "low_rate": self._low_count / total if total > 0 else 0.0,
        }

    def reset_statistics(self) -> None:
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯."""
        self._assessment_count = 0
        self._high_count = 0
        self._medium_count = 0
        self._low_count = 0
        self._score_history.clear()

    def get_adaptive_thresholds(
        self, context: ConfidenceContext
    ) -> tuple[float, float]:
        """è·å–è‡ªé€‚åº”é˜ˆå€¼ (v4.3å¢å¼º).

        æ ¹æ®å¸‚åœºçŠ¶æ€åŠ¨æ€è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼:
        - é«˜æ³¢åŠ¨å¸‚åœº: æé«˜é˜ˆå€¼è¦æ±‚
        - ä½æµåŠ¨æ€§å¸‚åœº: æé«˜é˜ˆå€¼è¦æ±‚
        - æ­£å¸¸å¸‚åœº: ä½¿ç”¨é»˜è®¤é˜ˆå€¼

        å‚æ•°:
            context: è¯„ä¼°ä¸Šä¸‹æ–‡

        è¿”å›:
            (é«˜é˜ˆå€¼, ä¸­é˜ˆå€¼) å…ƒç»„
        """
        high_thresh = self._high_threshold
        medium_thresh = self._medium_threshold

        # æ³¢åŠ¨ç‡è°ƒæ•´ (é«˜æ³¢åŠ¨ +5%)
        if context.volatility > 0.3:
            adjustment = min(0.05, (context.volatility - 0.3) * 0.2)
            high_thresh = min(0.99, high_thresh + adjustment)
            medium_thresh = min(0.89, medium_thresh + adjustment)

        # æµåŠ¨æ€§è°ƒæ•´ (ä½æµåŠ¨æ€§ +3%)
        if context.liquidity_score < 0.6:
            adjustment = min(0.03, (0.6 - context.liquidity_score) * 0.1)
            high_thresh = min(0.99, high_thresh + adjustment)
            medium_thresh = min(0.89, medium_thresh + adjustment)

        # å¼‚å¸¸å¸‚åœºçŠ¶æ€è°ƒæ•´ (+5%)
        if context.market_condition in {"VOLATILE", "CRISIS", "LIMIT_UP", "LIMIT_DOWN"}:
            high_thresh = min(0.99, high_thresh + 0.05)
            medium_thresh = min(0.89, medium_thresh + 0.05)

        return (high_thresh, medium_thresh)

    def get_trend_analysis(self) -> dict[str, Any]:
        """è·å–ç½®ä¿¡åº¦è¶‹åŠ¿åˆ†æ (v4.3å¢å¼º).

        åˆ†æå†å²ç½®ä¿¡åº¦å˜åŒ–è¶‹åŠ¿ï¼Œæä¾›é¢„è­¦ä¿¡æ¯ã€‚

        è¿”å›:
            è¶‹åŠ¿åˆ†æç»“æœå­—å…¸
        """
        if len(self._score_history) < 3:
            return {
                "trend": "INSUFFICIENT_DATA",
                "message": "å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æè¶‹åŠ¿",
                "recent_avg": 0.0,
                "overall_avg": 0.0,
                "direction": "NEUTRAL",
                "alert": False,
            }

        overall_avg = sum(self._score_history) / len(self._score_history)

        # è¿‘æœŸå¹³å‡ (æœ€è¿‘5æ¬¡)
        recent = self._score_history[-5:]
        recent_avg = sum(recent) / len(recent)

        # è¶‹åŠ¿æ–¹å‘
        if recent_avg >= overall_avg + 0.05:
            direction = "UP"
            trend = "IMPROVING"
        elif recent_avg <= overall_avg - 0.05:
            direction = "DOWN"
            trend = "DECLINING"
        else:
            direction = "NEUTRAL"
            trend = "STABLE"

        # é¢„è­¦æ£€æµ‹
        alert = False
        alert_message = ""

        # è¿ç»­ä¸‹é™é¢„è­¦
        if len(self._score_history) >= 3:
            last_3 = self._score_history[-3:]
            if all(last_3[i] > last_3[i + 1] for i in range(len(last_3) - 1)):
                alert = True
                alert_message = "âš ï¸ ç½®ä¿¡åº¦è¿ç»­ä¸‹é™"

        # ä½ç½®ä¿¡åº¦é¢„è­¦
        if recent_avg < 0.70:
            alert = True
            alert_message = "âŒ è¿‘æœŸç½®ä¿¡åº¦æŒç»­åä½"

        return {
            "trend": trend,
            "message": f"è¶‹åŠ¿: {trend} | æ–¹å‘: {direction}",
            "recent_avg": round(recent_avg, 4),
            "overall_avg": round(overall_avg, 4),
            "direction": direction,
            "alert": alert,
            "alert_message": alert_message,
            "history_count": len(self._score_history),
        }

    def _record_score(self, score: float) -> None:
        """è®°å½•ç½®ä¿¡åº¦åˆ†æ•°åˆ°å†å²."""
        self._score_history.append(score)
        if len(self._score_history) > self._max_history:
            self._score_history.pop(0)


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================


def assess_pre_execution(
    task_name: str,
    *,
    duplicate_check: bool = False,
    architecture_verified: bool = False,
    has_docs: bool = False,
    has_oss: bool = False,
    root_cause: bool = False,
) -> ConfidenceResult:
    """å¿«é€Ÿé¢„æ‰§è¡Œç½®ä¿¡åº¦è¯„ä¼°.

    å‚æ•°:
        task_name: ä»»åŠ¡åç§°
        duplicate_check: æ˜¯å¦å®Œæˆé‡å¤æ£€æŸ¥
        architecture_verified: æ˜¯å¦éªŒè¯æ¶æ„
        has_docs: æ˜¯å¦æœ‰å®˜æ–¹æ–‡æ¡£
        has_oss: æ˜¯å¦æœ‰OSSå‚è€ƒ
        root_cause: æ˜¯å¦è¯†åˆ«æ ¹å› 

    è¿”å›:
        ç½®ä¿¡åº¦è¯„ä¼°ç»“æœ
    """
    assessor = ConfidenceAssessor()
    context = ConfidenceContext(
        task_type=TaskType.STRATEGY_EXECUTION,
        task_name=task_name,
        duplicate_check_complete=duplicate_check,
        architecture_verified=architecture_verified,
        has_official_docs=has_docs,
        has_oss_reference=has_oss,
        root_cause_identified=root_cause,
    )
    return assessor.assess(context)


def assess_signal(
    symbol: str,
    strategy_id: str,
    *,
    strength: float = 0.0,
    consistency: float = 0.0,
    market_condition: str = "NORMAL",
    risk_ok: bool = True,
) -> ConfidenceResult:
    """å¿«é€Ÿä¿¡å·ç½®ä¿¡åº¦è¯„ä¼°.

    å‚æ•°:
        symbol: åˆçº¦ä»£ç 
        strategy_id: ç­–ç•¥ID
        strength: ä¿¡å·å¼ºåº¦
        consistency: ä¿¡å·ä¸€è‡´æ€§
        market_condition: å¸‚åœºçŠ¶æ€
        risk_ok: é£é™©æ˜¯å¦åœ¨é™åˆ¶å†…

    è¿”å›:
        ç½®ä¿¡åº¦è¯„ä¼°ç»“æœ
    """
    assessor = ConfidenceAssessor()
    context = ConfidenceContext(
        task_type=TaskType.SIGNAL_GENERATION,
        symbol=symbol,
        strategy_id=strategy_id,
        signal_strength=strength,
        signal_consistency=consistency,
        market_condition=market_condition,
        risk_within_limits=risk_ok,
    )
    return assessor.assess(context)


def format_confidence_report(result: ConfidenceResult) -> str:
    """æ ¼å¼åŒ–ç½®ä¿¡åº¦æŠ¥å‘Š.

    å‚æ•°:
        result: ç½®ä¿¡åº¦è¯„ä¼°ç»“æœ

    è¿”å›:
        æ ¼å¼åŒ–çš„æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    lines = [
        "ğŸ“‹ ç½®ä¿¡åº¦è¯„ä¼°æŠ¥å‘Š",
        "=" * 40,
        "",
    ]

    for check in result.checks:
        lines.append(f"   {check.message}")

    lines.extend([
        "",
        f"ğŸ“Š ç½®ä¿¡åº¦: {result.score:.0%}",
        result.recommendation,
    ])

    return "\n".join(lines)
